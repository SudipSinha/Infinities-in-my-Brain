<!DOCTYPE html><html class=no-js lang=en> <head><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta content="Thoughts and prayers about mathematical objects" name=description><link href=https://SudipSinha.github.io/Infinities-in-my-Brain/functional-analysis/derivatives/ rel=canonical><meta content="Sudip Sinha" name=author><link href=https://www.math.lsu.edu/favicon.ico rel="shortcut icon"><meta content="mkdocs-1.1, mkdocs-material-5.1.7" name=generator><title>Demystifying derivatives - Infinities in my Brain</title><link href=../../assets/stylesheets/main.4c7052ca.min.css rel=stylesheet><link href=../../assets/stylesheets/palette.b79bcd20.min.css rel=stylesheet><meta content=#03a9f4 name=theme-color><link crossorigin href=https://fonts.gstatic.com rel=preconnect><link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback" rel=stylesheet><style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style><link href=../../stylesheets/mathenvironments.css rel=stylesheet><link href=https://www.google-analytics.com rel="preconnect dns-prefetch"><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-154154955-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview")})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body data-md-color-accent=cyan data-md-color-primary=light-blue dir=ltr> <input autocomplete=off class=md-toggle data-md-toggle=drawer id=__drawer type=checkbox> <input autocomplete=off class=md-toggle data-md-toggle=search id=__search type=checkbox> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a class=md-skip href=#demystifying-derivatives> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav aria-label=Header class="md-header-nav md-grid"> <a aria-label="Infinities in my Brain" class="md-header-nav__button md-logo" href=https://SudipSinha.github.io/Infinities-in-my-Brain title="Infinities in my Brain"> <svg viewbox="0 0 640 512" xmlns=http://www.w3.org/2000/svg><path d="M471.1 96C405 96 353.3 137.3 320 174.6 286.7 137.3 235 96 168.9 96 75.8 96 0 167.8 0 256s75.8 160 168.9 160c66.1 0 117.8-41.3 151.1-78.6 33.3 37.3 85 78.6 151.1 78.6 93.1 0 168.9-71.8 168.9-160S564.2 96 471.1 96zM168.9 320c-40.2 0-72.9-28.7-72.9-64s32.7-64 72.9-64c38.2 0 73.4 36.1 94 64-20.4 27.6-55.9 64-94 64zm302.2 0c-38.2 0-73.4-36.1-94-64 20.4-27.6 55.9-64 94-64 40.2 0 72.9 28.7 72.9 64s-32.7 64-72.9 64z"></path></svg> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"></path></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> Infinities in my Brain </span> <span class="md-header-nav__topic md-ellipsis"> Demystifying derivatives </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"></path></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input aria-label=Search autocapitalize=off autocomplete=off autocorrect=off class=md-search__input data-md-component=search-query data-md-state=active name=query placeholder=Search spellcheck=false type=text> <label class="md-search__icon md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"></path></svg> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg> </label> <button aria-label=Clear class="md-search__icon md-icon" data-md-component=search-reset tabindex=-1 type=reset> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"></path></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <a class=md-source href=https://github.com/SudipSinha/Infinities-in-my-Brain/ title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 496 512" xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg> </div> <div class=md-source__repository> SudipSinha/Infinities-in-my-Brain </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label=Navigation class="md-nav md-nav--primary" data-md-level=0> <label class=md-nav__title for=__drawer> <a aria-label="Infinities in my Brain" class="md-nav__button md-logo" href=https://SudipSinha.github.io/Infinities-in-my-Brain title="Infinities in my Brain"> <svg viewbox="0 0 640 512" xmlns=http://www.w3.org/2000/svg><path d="M471.1 96C405 96 353.3 137.3 320 174.6 286.7 137.3 235 96 168.9 96 75.8 96 0 167.8 0 256s75.8 160 168.9 160c66.1 0 117.8-41.3 151.1-78.6 33.3 37.3 85 78.6 151.1 78.6 93.1 0 168.9-71.8 168.9-160S564.2 96 471.1 96zM168.9 320c-40.2 0-72.9-28.7-72.9-64s32.7-64 72.9-64c38.2 0 73.4 36.1 94 64-20.4 27.6-55.9 64-94 64zm302.2 0c-38.2 0-73.4-36.1-94-64 20.4-27.6 55.9-64 94-64 40.2 0 72.9 28.7 72.9 64s-32.7 64-72.9 64z"></path></svg> </a> Infinities in my Brain </label> <div class=md-nav__source> <a class=md-source href=https://github.com/SudipSinha/Infinities-in-my-Brain/ title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 496 512" xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg> </div> <div class=md-source__repository> SudipSinha/Infinities-in-my-Brain </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=../.. title="Infinities in my Brain"> Infinities in my Brain </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc id=__toc type=checkbox> <label class="md-nav__link md-nav__link--active" for=__toc> Demystifying derivatives <span class="md-nav__icon md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"></path></svg> </span> </label> <a class="md-nav__link md-nav__link--active" href=./ title="Demystifying derivatives"> Demystifying derivatives </a> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg> </span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=#what-is-a-derivative-of-a-function> What is a derivative of a function? </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#derivative-in-1-dimensional-space> Derivative in \( 1 \)-dimensional space </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#higher-dimensions> Higher dimensions </a> <nav aria-label="Higher dimensions" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#vector-calculus> Vector calculus </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#generalizing> Generalizing </a> <nav aria-label=Generalizing class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#frechet-derivative> Fréchet derivative </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#gateaux-differential> Gâteaux differential </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#special-cases> Special cases </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#examples> Examples </a> <nav aria-label=Examples class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#finite-dimensional-spaces> Finite-dimensional spaces </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#hilbert-spaces> Hilbert spaces </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#summary> Summary </a> <nav aria-label=Summary class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#relationship-between-the-two-derivatives> Relationship between the two derivatives </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#application-ordinary-least-squares> Application: ordinary least squares </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 id=nav-3 type=checkbox> <label class=md-nav__link for=nav-3> Probability theory <span class="md-nav__icon md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg> </span> </label> <nav aria-label="Probability theory" class=md-nav data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg> </span> Probability theory </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=../../probability-theory/first-step-analysis/ title="First step analysis"> First step analysis </a> </li> <li class=md-nav__item> <a class=md-nav__link href=../../probability-theory/quick-probability-theory/ title="Probability theory in a nutshell"> Probability theory in a nutshell </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4 id=nav-4 type=checkbox> <label class=md-nav__link for=nav-4> Technical <span class="md-nav__icon md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg> </span> </label> <nav aria-label=Technical class=md-nav data-md-level=1> <label class=md-nav__title for=nav-4> <span class="md-nav__icon md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg> </span> Technical </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=../../technical/math-blog-setup/ title="Recipe for a markdown math blog"> Recipe for a markdown math blog </a> </li> <li class=md-nav__item> <a class=md-nav__link href=../../technical/chromebook-setup/ title="Setting up my Chromebook"> Setting up my Chromebook </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=../../zero/a-story-of-numbers/ title="A story of numbers"> A story of numbers </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg> </span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=#what-is-a-derivative-of-a-function> What is a derivative of a function? </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#derivative-in-1-dimensional-space> Derivative in \( 1 \)-dimensional space </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#higher-dimensions> Higher dimensions </a> <nav aria-label="Higher dimensions" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#vector-calculus> Vector calculus </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#generalizing> Generalizing </a> <nav aria-label=Generalizing class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#frechet-derivative> Fréchet derivative </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#gateaux-differential> Gâteaux differential </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#special-cases> Special cases </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#examples> Examples </a> <nav aria-label=Examples class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#finite-dimensional-spaces> Finite-dimensional spaces </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#hilbert-spaces> Hilbert spaces </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#summary> Summary </a> <nav aria-label=Summary class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#relationship-between-the-two-derivatives> Relationship between the two derivatives </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#application-ordinary-least-squares> Application: ordinary least squares </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <a class="md-content__button md-icon" href=https://github.com/SudipSinha/Infinities-in-my-Brain/edit/master/docs/functional-analysis/derivatives.md title="Edit this page"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg> </a> <h1 id=demystifying-derivatives>Demystifying derivatives<a class=headerlink href=#demystifying-derivatives title="Permanent link">¶</a></h1> <div class="admonition warning"> <p class=admonition-title>Warning</p> <p>This is still in draft mode. If you have any comments/suggestions, please email me so that I can improve on this.</p> </div> <div class="admonition abstract"> <p class=admonition-title>Abstract</p> <p>We see why there is no unique concept of a derivative for functions on spaces of dimension greater than one.</p> </div> <div class="admonition info"> <p class=admonition-title>Prerequisites</p> <p>Knowledge of elementary real analysis and linear algebra is essential, but some familiarity with functional analysis will greatly improve your experience.</p> </div> <h2 id=what-is-a-derivative-of-a-function>What is a derivative of a function?<a class=headerlink href=#what-is-a-derivative-of-a-function title="Permanent link">¶</a></h2> <p>We are introduced to derivatives as the rate of change of a function at a given point in the domain of the function. Is this the only way to think of the derivative? My thesis for this essay is that there is another way of looking at derivatives which allows us to generalize it to much general spaces.</p> <h2 id=derivative-in-1-dimensional-space>Derivative in <span class=arithmatex>\( 1 \)</span>-dimensional space<a class=headerlink href=#derivative-in-1-dimensional-space title="Permanent link">¶</a></h2> <p>First, we look at the simplest case — derivative of a function in a <span class=arithmatex>\( 1 \)</span>-dimensional space. Given a function <span class=arithmatex>\( f: G ⊆ ℝ → ℝ \)</span>, we say that the derivative of the function <span class=arithmatex>\( f \)</span> at a <em>fixed</em> point <span class=arithmatex>\( x ∈ G \)</span> is defined as</p> <div class=arithmatex>\[\begin{equation} \label{def:derivative-1dim} f'(x) = \lim_{h → 0} \frac{f(x + h) - f(x)}{h} , \end{equation}\]</div> <p>provided the limit exists.</p> <div class="admonition note"> <p class=admonition-title>Convention</p> <p>In what follows, whenever we write a definition in terms of a limit, we will assume that the limit exists.</p> </div> <p>Note that we can rewrite \eqref{def:derivative-1dim} as</p> <div class=arithmatex>\[\begin{equation} \label{def:derivative-1dim-linear} f(x + h) - f(x) - f'(x) h = o(h) , \end{equation}\]</div> <p>where <span class=arithmatex>\( \frac{o(k)}{k} → 0 \)</span> as <span class=arithmatex>\( k → 0 \)</span>.</p> <p>That is, the <em>linearization</em> of the function <span class=arithmatex>\( f \)</span> about the <em>fixed</em> point <span class=arithmatex>\( x \)</span> is given by <span class=arithmatex>\( l_x(h) = f(x) + f'(x) h \)</span>. One way to understand \eqref{def:derivative-1dim-linear} is to think that the difference between the function and the linearization is <em>small</em> as we get <em>close</em> to <span class=arithmatex>\( x \)</span>.</p> <p>Therefore, we could as easily have defined the derivative using \eqref{def:derivative-1dim-linear} instead of \eqref{def:derivative-1dim}. Are both the same, or should we prefer one over the other? As we saw, in <span class=arithmatex>\( 1 \)</span>-dimension, both are equivalent. But in higher dimensions, these two perspectives sometimes give different results, and so it is important to understand both sides of the picture. This will be the point of the article.</p> <!-- ### Properties of derivatives ==ToDo==

####    Product rule

\begin{equation}  \label{thm:product-rule-1dim}
    (f g)' = f' g + f g'
\end{equation}


####    Chain rule

\begin{equation}  \label{thm:chain-rule-1dim}
    (f ∘ g)' = (f' ∘ g) g'
\end{equation}
 --> <h2 id=higher-dimensions>Higher dimensions<a class=headerlink href=#higher-dimensions title="Permanent link">¶</a></h2> <p>Can we increase the dimension of the spaces we considered? Note that we have control over two spaces, the domain and the codomain. First, let us try to have a <span class=arithmatex>\( 2 \)</span>-dimensional codomain.</p> <p>Let <span class=arithmatex>\( f: U ⊆ ℝ → ℝ^2 \)</span>. How do we find the derivative of such a function?</p> <p>We can do a "coordinate-wise" differentiation here. Let <span class=arithmatex>\( f(x) = (f_1(x), f_2(x)) \)</span>. Note that we can always do this as for <span class=arithmatex>\( i ∈ \bcrl{1, 2} \)</span>, we can simply define <span class=arithmatex>\( f_i = f ∘ π_i \)</span>, where <span class=arithmatex>\( π_i \)</span> is the projection onto the <span class=arithmatex>\( i \)</span>th coordinate. Now, using \eqref{def:derivative-1dim}, we can define the derivative of <span class=arithmatex>\( f \)</span> at <span class=arithmatex>\( x \)</span> as</p> <div class=arithmatex>\[ f'(x) = (f_1'(x), f_2'(x)) . \]</div> <details class=example open=open><summary>Traversing the unit circle</summary><p>As an example of such function, let <span class=arithmatex>\( 𝕊^1 = \bcrl{(x_1, x_2) ∈ ℝ^2 : \norm{x}_2 = 1} \)</span> be the unit circle, and <span class=arithmatex>\( θ ∈ 𝕋 = [0, 2π) \)</span> represent anglular measures about the origin. Then there is a bijection between <span class=arithmatex>\( 𝕋 \)</span> and <span class=arithmatex>\( 𝕊^1 \)</span>, that is given by <span class=arithmatex>\( f: 𝕋 → 𝕊^1: θ ↦ (\cos(θ), \sin(θ)) \)</span>. To calculate the rate of change of a particle's position with respect to changing angles, we can simple calculate the derivative of <span class=arithmatex>\( f \)</span> at an angle <span class=arithmatex>\( θ \)</span>.</p> <div class=arithmatex>\[ f'(θ) = (\cos'(θ), \sin'(θ)) = (-\sin(θ), \cos(θ)) . \]</div> </details> <p>The moral of the above argument is that the dimension of the codomain does not affect us much, we can always differentiate each coordinate (at least for countable-dimensional codomains). Thus, we shall only focus on the domain from now on.</p> <p>So far, so good. Can we do the same if we have a <span class=arithmatex>\( 2 \)</span>-dimensional domain? Take a function <span class=arithmatex>\( f: ℝ^2 → ℝ \)</span>. How do we define the derivative of <span class=arithmatex>\( f \)</span>?</p> <p>The problem here is that there are two inputs. In the problems until now, there was only one input, so we could just increase or decrease it by <span class=arithmatex>\( h \)</span>. In other words, there were two ways of <span class=arithmatex>\( h \)</span> approaching <span class=arithmatex>\( 0 \)</span>, from the left and from the right. But now we have infinite possibilities as any point in a <span class=arithmatex>\( 2 \)</span>-dimensional space can be approached in infinite ways!</p> <h3 id=vector-calculus>Vector calculus<a class=headerlink href=#vector-calculus title="Permanent link">¶</a></h3> <p>One way to differentiate linear and quadratic functionals on a finite-dimensional vector space is to use a basis.</p> <p>In this section, let <span class=arithmatex>\( V \)</span> be a <span class=arithmatex>\( d \)</span>-dimensional real vector space. Fix a basis <span class=arithmatex>\( ℬ = \bcrl{e_1, …, e_d} \)</span> for <span class=arithmatex>\( V \)</span> so that we can express any <span class=arithmatex>\( x ∈ V \)</span> as <span class=arithmatex>\( x = ∑_{i = 1}^d x_i e_i \)</span> for some <span class=arithmatex>\( x_i ∈ ℝ \)</span> for each <span class=arithmatex>\( i ∈ [d] \)</span>. This gives us an identification of <span class=arithmatex>\( V \)</span> with <span class=arithmatex>\( ℝ^d \)</span>, and we can write the identification of <span class=arithmatex>\( x ∈ V \)</span> as the column vector <span class=arithmatex>\( (x_1, …, x_d) ∈ ℝ^d \)</span>. We shall use the notation <span class=arithmatex>\( ⋅^* \)</span> to represents the transpose operation, and denote <span class=arithmatex>\( [d] = \bcrl{1, …, d} \)</span>.</p> <details class=example open=open><summary>Linear functionals</summary><p>Let <span class=arithmatex>\( v ∈ V \)</span> be fixed and <span class=arithmatex>\( m_v: V → ℝ: x ↦ \inn{x, v} \)</span>. Using the identification, we write <span class=arithmatex>\( v = (v_1, …, v_d) ∈ ℝ^d \)</span>. So our definition of <span class=arithmatex>\( m_v \)</span> becomes <span class=arithmatex>\( m_v(x) = x^* v = ∑_{i = 1}^d x_i v_i \)</span>. Now, <span class=arithmatex>\( \frac{∂m_v(x)}{∂x_j} = v_j \)</span>, so writing this in the <a href=https://en.wikipedia.org/wiki/Matrix_calculus#Layout_conventions>numerator layout convention</a>, we get</p> <div class=arithmatex>\[ \frac{∂f(x)}{∂x} = \begin{bmatrix} v_1 &amp; ⋯ &amp; v_d \end{bmatrix} = v^* , \]</div> <p>so we can write <span class=arithmatex>\( \frac{∂f(x)}{∂x} = \inn{v, ⋅} \)</span>.</p> </details> <details class=example open=open><summary>Quadratic forms</summary><p>Let <span class=arithmatex>\( f: V → ℝ: x ↦ \inn{x, T x} \)</span>, where <span class=arithmatex>\( T: V → V \)</span> is a linear operator. In the basis <span class=arithmatex>\( ℬ \)</span>, the operator <span class=arithmatex>\( T \)</span> has a unique matrix representative, say <span class=arithmatex>\( A = (a_{ij})_{i, j ∈ [d]} \)</span>. Therefore, we can write</p> <div class=arithmatex>\[\begin{align*} f(x) &amp; = \inn{x, T x} \\ &amp; = x^* A x \\ &amp; = ∑_{i = 1}^d x_i ∑_{j = 1}^d a_{ij} x_j \\ &amp; = ∑_{i = 1}^d ∑_{j = 1}^d x_i a_{ij} x_j \\ &amp; = ∑_{j ≠ k} x_k a_{kj} x_j + ∑_{i ≠ k} x_i a_{ik} x_k \\ &amp; \quad + a_{kk} x_k^2 + ∑_{i ≠ k, j ≠ k} x_i a_{ij} x_j. \\ \end{align*}\]</div> <p>Taking partial derivatives with respect to <span class=arithmatex>\( x_k \)</span>, we get</p> <div class=arithmatex>\[\begin{align*} \frac{∂f(x)}{∂x_j} &amp; = ∑_{j ≠ k} a_{kj} x_j + ∑_{i ≠ k} x_i a_{ik} + 2 a_{kk} x_k + 0 \\ &amp; = ∑_{j = 1}^d a_{kj} x_j + ∑_{i = 1}^d x_i a_{ik} \\ &amp; = A_{k, ⋅} x + x^* A_{⋅, k} \\ &amp; = x^* A_{k, ⋅}^* + x^* A_{⋅, k} \\ &amp; = x^* \brnd{A_{⋅, k} + A_{k, ⋅}^*} . \\ \end{align*}\]</div> <p>Finally, writing in the <a href=https://en.wikipedia.org/wiki/Matrix_calculus#Layout_conventions>numerator layout convention</a>, we get</p> <div class=arithmatex>\[\begin{align*} \frac{∂f(x)}{∂x} &amp; = \begin{bmatrix} x^* \brnd{A_{⋅, 1} + A_{1, ⋅}^*} &amp; ⋯ &amp; x^* \brnd{A_{⋅, d} + A_{d, ⋅}^*} \\ \end{bmatrix} \\ &amp; = x^* \brnd{ \begin{bmatrix} A_{⋅, 1} &amp; ⋯ &amp; A_{⋅, d} \\ \end{bmatrix} + \begin{bmatrix} A_{1, ⋅}^* &amp; ⋯ &amp; A_{d, ⋅}^* \\ \end{bmatrix} } \\ &amp; = x^* (A^* + A) \\ &amp; = x^* \brnd{A + A^*}^* \\ &amp; = \brnd{(A + A^*) x}^* , \\ \end{align*}\]</div> <p>where in the penultimate steps we used the involution and anti-distributivity <a href=https://en.wikipedia.org/wiki/Hermitian_adjoint#Properties>properties of the adjoint</a>. Therefore, we can write <span class=arithmatex>\( \frac{∂f(x)}{∂x} = \inn{(A + A^*) x, ⋅} \)</span>.</p> </details> <p>Note that our final results in both cases do not depend on the choice of the basis. So our intuition says that there should be basis-free ways of deriving the same results. We shall soon see that this is true.</p> <h2 id=generalizing>Generalizing<a class=headerlink href=#generalizing title="Permanent link">¶</a></h2> <p>From now on, instead of looking at the Euclidean spaces <span class=arithmatex>\( ℝ^n \)</span>, we shall look at general real vector spaces. We will come back to Euclidean spaces, and see what happens in these special cases.</p> <p>We can look at the problem in two ways. In Fréchet's way, we do not care about the path of approach and try to get a <em>uniform linearization</em>. In Gâteaux's way, we fix a direction, so we can only talk about two ways of approaching as in our <span class=arithmatex>\( 1 \)</span>-dimensional case.</p> <h3 id=frechet-derivative>Fréchet derivative<a class=headerlink href=#frechet-derivative title="Permanent link">¶</a></h3> <div class="admonition definition"> <p class=admonition-title>Definition</p> <p>Let <span class=arithmatex>\( V, W \)</span> be <a href=https://en.wikipedia.org/wiki/Normed_vector_space>normed vector spaces</a>, and <span class=arithmatex>\( U ⊆ V \)</span>. A function <span class=arithmatex>\( f : U → W \)</span> is called <em>Fréchet differentiable</em> at <span class=arithmatex>\( x ∈ U \)</span> if there exists a bounded linear operator <span class=arithmatex>\( L_x: V → W \)</span> such that</p> <div class=arithmatex>\[\begin{equation} \label{def:Fréchet-derivative} \norm{f(x + h) - f(x) - L_x h}_W = o\brnd{\norm{h}_V} \text{ as } \norm{h}_V → 0 . \end{equation}\]</div> </div> <div class="admonition notes"> <p class=admonition-title>Notes</p> <ul> <li>This approach is similar to the one used in \eqref{def:derivative-1dim-linear}.</li> <li>It is customary to write the action of a linear operator <span class=arithmatex>\( T \)</span> on a vector <span class=arithmatex>\( v \)</span> by <span class=arithmatex>\( T v \)</span> instead of <span class=arithmatex>\( T(v) \)</span>. They are the same.</li> </ul> </div> <div class="admonition proposition"> <p class=admonition-title>Proposition</p> <p><span class=arithmatex>\( L_x \)</span> is unique.</p> </div> <details class=proof open=open><summary>Proof</summary><p>Suppose not. That is, suppose there exists two such linear operators, say <span class=arithmatex>\( L_x \)</span> and <span class=arithmatex>\( \tilde{L}_x \)</span> that satisfy \eqref{def:Fréchet-derivative}. Therefore, we have</p> <div class=arithmatex>\[\begin{align*} \norm{f(x + h) - f(x) - L_x h}_W = o\brnd{\norm{h}_V} \\ \norm{f(x + h) - f(x) - \tilde{L}_x h}_W = o\brnd{\norm{h}_V} \\ \end{align*}\]</div> <p>Now, using the triangle inequality of the norm, we get</p> <div class=arithmatex>\[\begin{align*} \norm{(\tilde{L}_x - L_x) h}_W &amp; = \norm{(-L_x h) - (-\tilde{L}_x h)}_W \\ &amp; = \norm{(f(x + h) - f(x) - L_x h) - (f(x + h) - f(x) - \tilde{L}_x h)}_W \\ &amp; ≤ \norm{f(x + h) - f(x) - L_x h}_W + \norm{f(x + h) - f(x) - \tilde{L}_x h}_W \\ &amp; = o\brnd{\norm{h}_V} + o\brnd{\norm{h}_V} = o\brnd{\norm{h}_V} . \\ \end{align*}\]</div> <p>This gives us</p> <div class=arithmatex>\[ \norm{\tilde{L}_x - L_x}_∞ = \sup_{\norm{h}_V ≤ 1} \frac{\norm{(\tilde{L}_x - L_x) h}_W}{\norm{h}_V} = \sup_{\norm{h}_V ≤ 1} \frac{o\brnd{\norm{h}_V}}{\norm{h}_V} → 0 \text{ as } \norm{h}_V → 0 . \]</div> <p>Therefore, <span class=arithmatex>\( \tilde{L}_x = L_x \)</span>, and we are done.</p> </details> <p>Since such an operator <span class=arithmatex>\( L_x \)</span> is unique (if it exists), we write <span class=arithmatex>\( Df(x) = L_x \)</span> and call it the <em>Fréchet derivative</em> of <span class=arithmatex>\( f \)</span> at <span class=arithmatex>\( x \)</span>.</p> <h3 id=gateaux-differential>Gâteaux differential<a class=headerlink href=#gateaux-differential title="Permanent link">¶</a></h3> <div class="admonition definition"> <p class=admonition-title>Definition</p> <p>Let <span class=arithmatex>\( V, W \)</span> be <a href=https://en.wikipedia.org/wiki/Normed_vector_space>normed vector spaces</a>, and <span class=arithmatex>\( U ⊆ V \)</span>. The <em>Gâteaux differential</em> of a function <span class=arithmatex>\( f : U → W \)</span> at <span class=arithmatex>\( x ∈ U \)</span> in the direction <span class=arithmatex>\( v \)</span> is defined as</p> <div class=arithmatex>\[\begin{equation} \label{def:Gâteaux-differential} d_h f(x) = \lim_{t → 0} \frac{f(x + t v) - f(x)}{t} = \left. \frac{d}{d t} \right|_{t = 0} f(x + t v) . \end{equation}\]</div> <p>If the limit exists for all <span class=arithmatex>\( v ∈ V \)</span>, then we say that <span class=arithmatex>\( f \)</span> is <em>Gâteaux differentiable</em> at <span class=arithmatex>\( x \)</span>.</p> </div> <div class="admonition note"> <p class=admonition-title>Note</p> <ul> <li>This approach is similar to the one used in \eqref{def:derivative-1dim}.</li> <li>The Gâteaux differential is unique if it exists, since the limit in the definition is unique if it exists.</li> <li>Existence of the Gâteaux differential does not guarantee continuity. See examples <a href=https://en.wikipedia.org/wiki/Gateaux_derivative#Linearity_and_continuity>here</a>.</li> <li>The Gâteaux differential is related to the Fréchet derivative by <span class=arithmatex>\( d_h f(x) = Df(x) h \)</span> (when both exist).</li> <li>There is a Gâteaux differential for each direction. So in <span class=arithmatex>\( 1 \)</span>-dimension real vector space, there are two (<em>left</em> and <em>right</em>) such derivatives, but in two or more dimensions or in any complex vector space, there are infinitely (uncountably) many.</li> <li>The Gâteaux differential is a <span class=arithmatex>\( 1 \)</span>-dimensional calculation along a specified direction <span class=arithmatex>\( h \)</span>, so we can use our ordinary <span class=arithmatex>\( 1 \)</span>-dimensional calculus to compute it. This makes computability much easier.</li> <li>The fundamental theorem of calculus for Gâteaux differentials is <span class=arithmatex>\( f(x + h) - f(x) = ∫_0^1 d_h f(x + t h) d t \)</span>.</li> </ul> </div> <h2 id=special-cases>Special cases<a class=headerlink href=#special-cases title="Permanent link">¶</a></h2> <p>In Euclidean spaces</p> <ul> <li>Directional derivatives are basically Gâteaux differentials</li> <li>The total derivative or the gradient are basically the Fréchet derivative.</li> </ul> <h2 id=examples>Examples<a class=headerlink href=#examples title="Permanent link">¶</a></h2> <h3 id=finite-dimensional-spaces>Finite-dimensional spaces<a class=headerlink href=#finite-dimensional-spaces title="Permanent link">¶</a></h3> <details class=example open=open><summary>The absolute value function on ℝ</summary><p>Let <span class=arithmatex>\( f: ℝ → ℝ: x ↦ \abs{x} \)</span>. If <span class=arithmatex>\( x = 0 \)</span>, then we have <span class=arithmatex>\( \lim_{t → 0} \frac{\abs{t h}}{t} \)</span>. If <span class=arithmatex>\( h &gt; 0 \)</span> then the limit is <span class=arithmatex>\( h \)</span>, and if <span class=arithmatex>\( h &lt; 0 \)</span> then the limit is <span class=arithmatex>\( -h \)</span>, which we combine to get the limit as <span class=arithmatex>\( \abs{h} \)</span>. Now, if <span class=arithmatex>\( x ≠ 0 \)</span>, then in the limit <span class=arithmatex>\( x + th \)</span> will have the same sign as <span class=arithmatex>\( x \)</span>. Following the same logic as for <span class=arithmatex>\( x = 0 \)</span>, we get the derivative as <span class=arithmatex>\( h \frac{x}{\abs{x}} \)</span>. Therefore,</p> <div class=arithmatex>\[ d_h f(x) = \begin{cases} h \frac{x}{\abs{x}} &amp; \text{if } x ≠ 0 \\ \abs{h} &amp; \text{if } x = 0 \\ \end{cases} . \]</div> <p>It might be surprising to find out that the Gâteaux differential of the absolute value function exists at <span class=arithmatex>\( 0 \)</span>. In ordinary derivatives, the limit for the derivative does not exist at <span class=arithmatex>\( 0 \)</span> because we approach it from both sides. But in Gâteaux differentials, we specify a direction (<span class=arithmatex>\( h \)</span>), so we do not have the same problem. But note that the Gâteaux differential depends on <span class=arithmatex>\( h \)</span> in a nonlinear way, and therefore there is no Fréchet derivative.</p> </details> <h3 id=hilbert-spaces>Hilbert spaces<a class=headerlink href=#hilbert-spaces title="Permanent link">¶</a></h3> <p>In what follows, <span class=arithmatex>\( V \)</span> is a real Hilbert space.</p> <details class=example open=open><summary>Linear functionals</summary><p>Let <span class=arithmatex>\( v ∈ V \)</span> be fixed and <span class=arithmatex>\( m_v: V → ℝ: x ↦ \inn{x, v} \)</span>. Then</p> <p><em>Gâteaux differential</em></p> <div class=arithmatex>\[\begin{align*} d_h m_v(x) &amp; = \lim_{t → 0} \frac{m_v(x + t h) - m_v(x)}{t} \\ &amp; = \lim_{t → 0} \frac{\inn{\cancel{x} + \bcancel{t} h, v} - \cancel{\inn{x, v}}}{\bcancel{t}} \\ &amp; = \inn{h, v} . \\ \end{align*}\]</div> <p><em>Fréchet derivative</em>: Since the Gâteaux differential is linear in <span class=arithmatex>\( h \)</span>, the Fréchet derivative is the same as the Gâteaux differential. That is, <span class=arithmatex>\( Df(x): V → ℝ: h ↦ \inn{h, v} \)</span>. The proof is simply writing out the definition of the Fréchet derivative. Note that the derivative is independent of <span class=arithmatex>\( x \)</span>, as we should have expected.</p> </details> <details class=example open=open><summary>Quadratic forms</summary><p>Let <span class=arithmatex>\( f: V → ℝ: x ↦ \inn{x, T x} \)</span>, where <span class=arithmatex>\( T: V → V \)</span> is a bounded linear operator.</p> <p><em>Gâteaux differential</em></p> <div class=arithmatex>\[\begin{align*} d_h f(x) &amp; = \lim_{t → 0} \frac{f(x + t h) - f(x)}{t} \\ &amp; = \lim_{t → 0} \frac{\inn{x + t h, T (x + t h)} - \inn{x, Tx}}{t} \\ &amp; = \lim_{t → 0} \frac{\cancel{\inn{x, T x}} + \bcancel{t} \inn{x, T h} + \bcancel{t} \inn{h, T x} + t^\bcancel{2} \inn{h, T h} - \cancel{\inn{x, T x}}}{\bcancel{t}} \\ &amp; = \inn{x, T h} + \inn{h, T x} \\ &amp; = \inn{T^* x, h} + \inn{h, T x} \\ &amp; = \inn{h, T^* x} + \inn{h, T x} \\ &amp; = \inn{h, (T + T^*) x} , \\ \end{align*}\]</div> <p>where in the third last step, we have used the definition of <a href=https://en.wikipedia.org/wiki/Hermitian_adjoint>adjoint of an operator</a>.</p> <p><em>Fréchet derivative</em>: The linearity of the Gâteaux differential shows us that the Fréchet derivative is the same. In this case, <span class=arithmatex>\( Df(x): V → ℝ: h ↦ \inn{h, (T + T^*) x} \)</span>. Note the analogy with <span class=arithmatex>\( \frac{d (a x^2)}{d x} h = h (a + a) x \)</span>.</p> </details> <h2 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">¶</a></h2> <h3 id=relationship-between-the-two-derivatives>Relationship between the two derivatives<a class=headerlink href=#relationship-between-the-two-derivatives title="Permanent link">¶</a></h3> <div class="admonition proposition"> <p class=admonition-title>Implications</p> <p>Fréchet differentiability implies Gâteaux differentiability.</p> </div> <details class=proof open=open><summary>Proof</summary><p>Assume <span class=arithmatex>\( f: V → W \)</span> has Fréchet derivative <span class=arithmatex>\( Df(x) \)</span> at <span class=arithmatex>\( x ∈ V \)</span>. Now,</p> <div class=arithmatex>\[\begin{align*} &amp; \norm{\frac{f(x + t v) - f(x)}{t} - Df(x)(v)}_W \\ = &amp; \frac{\norm{f(x + t v) - f(x) - Df(x)(v) t}_W}{\abs{t} \norm{v}_V} \norm{v}_V \\ = &amp; \frac{\norm{f(x + t v) - f(x) - Df(x)(tv)}_W}{\norm{t v}_V} \norm{v}_V → 0 \\ \end{align*}\]</div> <p>as <span class=arithmatex>\( t → 0 \)</span> since <span class=arithmatex>\( \norm{t v}_V → 0 \)</span> as <span class=arithmatex>\( t → 0 \)</span> and <span class=arithmatex>\( f \)</span> is Fréchet differentiable.</p> </details> <div class="admonition note"> <p class=admonition-title>Note</p> <p>The converse of the above proposition is not true, as is shown by the counterexample.</p> <div class=arithmatex>\[ f(x, y) = \frac{x^3}{x^2 + y^2} 𝟙_{(x, y) ≠ (0, 0)}(x, y) . \]</div> </div> <p>The Fréchet differentiability is a stronger notion. The Fréchet derivative contains information about the rate of change of <em>the norm of the function</em> about a particular point independent of direction. It is true to the spirit of the original derivative in the sense that it is still linear. Its existence guarantees the existence of the Gâteaux differential.</p> <p>The Gâteaux differentiability is a strictly weaker notion. The Gâteaux differential need not be linear, and its existence does not imply the existence of the Fréchet derivative. In fact, its existence at a point does not even guarantee the continuity of the function at that point. It gives us the rate of change of a function only in a particular direction. This rate of change is not just of the norm, but of the vector output itself. The Gâteaux differential only requires that the difference quotients converge along each direction individually, without making requirements about the rates of convergence for different directions. Thus, in order for a linear Gâteaux differential to imply the existence of the Fréchet derivative, the difference quotients have to converge <em>uniformly</em> for all directions.</p> <p>In general, in the infinite dimensional spaces, there are usually reasonably satisfactory results on the existence of Gâteaux differentials of Lipschitz functions. On the other hand, similar results on existence of Fréchet derivatives are rare and usually very hard to prove.</p> <p>Therefore, there are significant differences in the two derivates, and it seems to have its own pros and cons. In life, and even more so in mathematics, there is no free lunch. The choice among the two then depends on the requirement. In many applications, we <em>require</em> Fréchet derivatives as they provide genuine local linear approximations unlike the Gâteaux differentials.</p> <p>It is important to remember that if a function is Fréchet differentiable, then it is also Gâteaux differentiable, and the two derivatives are equal.</p> <p>The following table highlights some of the differences.</p> <table> <thead> <tr> <th align=left>property</th> <th align=left>Gâteaux differentials</th> <th align=left>Fréchet derivative</th> </tr> </thead> <tbody> <tr> <td align=left>strength</td> <td align=left>weaker</td> <td align=left>stronger</td> </tr> <tr> <td align=left>computability</td> <td align=left>direct; ordinary differentiation rules</td> <td align=left>indirect; only verification possible</td> </tr> <tr> <td align=left>direction</td> <td align=left>dependent</td> <td align=left>independent</td> </tr> <tr> <td align=left>linear</td> <td align=left>not necessarily</td> <td align=left>yes</td> </tr> <tr> <td align=left>in ℝ^d</td> <td align=left>directional derivatives</td> <td align=left>total derivative / Jacobian</td> </tr> </tbody> </table> <!-- # ToDo

*   Chain rule
*   Product rule
*   More examples
*   FTC
 --> <h2 id=application-ordinary-least-squares>Application: ordinary least squares<a class=headerlink href=#application-ordinary-least-squares title="Permanent link">¶</a></h2> <p>In this section, we shall use what we learned to derive the normal equations in the <a href=https://en.wikipedia.org/wiki/Ordinary_least_squares>ordinary least squares method</a>.</p> <p>The problem setup is as follows. Our data consists of <span class=arithmatex>\( n \)</span> observations, <span class=arithmatex>\( \bcrl{(x_i, y_i): i ∈ [n]} \)</span>, where <span class=arithmatex>\( y_i \)</span> is the scalar <em>output</em> and <span class=arithmatex>\( x_i \)</span> is a <span class=arithmatex>\( p \)</span>-dimensional vector of <em>input</em> values. In a <a href=https://en.wikipedia.org/wiki/Linear_regression>linear regression model</a>, the output variable is a linear function of the input variables, so</p> <div class=arithmatex>\[ y_i = x_i^* β + ε_i , \]</div> <p>where <span class=arithmatex>\( β \)</span> is a <span class=arithmatex>\( p \)</span>-dimensional vector assigning weightages to each variable according to their importance in predicting the output, and the scalars <span class=arithmatex>\( ε_i \)</span> represent the errors. This model can be written in matrix notation as</p> <div class=arithmatex>\[ y = X β + ε , \]</div> <p>where <span class=arithmatex>\( y \)</span> and <span class=arithmatex>\( ε \)</span> are <span class=arithmatex>\( n \)</span>-dimensional vectors of the values of the output and the errors for the various observations, and <span class=arithmatex>\( X \)</span> is an <span class=arithmatex>\( n × p \)</span> matrix of the inputs.</p> <p>Our goal is to get <span class=arithmatex>\( \hat{β} \)</span> which minimizes the squared errors (<span class=arithmatex>\( ℓ^2 \)</span>-norm). That is, we want to minimize</p> <div class=arithmatex>\[\begin{align*} e(β) &amp; = \frac12 \norm{ε}_2^2 \\ &amp; = \frac12 \inn{ε, ε} \\ &amp; = \frac12 \inn{X β - y, X β - y} \\ &amp; = \frac12 \brnd{\inn{X β, X β} - 2 \inn{X β, y} + \inn{y, y}} \\ &amp; = \frac12 \inn{β, X^* X β} - \inn{β, X^* y} + \frac12 \inn{y, y} \\ \end{align*}\]</div> <p>First, notice that <span class=arithmatex>\( X^* X \)</span> is self-adjoint, that is, <span class=arithmatex>\( (X^* X)^* = X^* X \)</span>. Now, using the examples of linear and quadratic forms, we get the Fréchet derivative</p> <div class=arithmatex>\[\begin{align*} De(β) h &amp; = \frac12 \inn{h, (X^* X + (X^* X)^*) β} - \inn{h, X^* y} \\ &amp; = \frac{1}{\cancel2} \inn{h, \cancel2 X^* X β} - \inn{h, X^* y} \\ &amp; = \inn{h, X^* (X β - y)} , \\ \end{align*}\]</div> <p>where we used the fact that an inner product in a real vector space is linear also in the second argument.</p> <p>For a minimum, we want <span class=arithmatex>\( De(\hat{β}) h = 0 \)</span> for any <span class=arithmatex>\( h \)</span>. This is only possible if <span class=arithmatex>\( X^* (X \hat{β} - y) = 0 \)</span>, which gives us our optimality condition</p> <div class=arithmatex>\[\begin{equation} \hat{β} = (X^* X)^{-1} X^* y . \end{equation}\]</div> <!-- ##  References

Derivatives

*   [Kevin Long's notes](http://www.math.ttu.edu/~klong/5311-spr09/diff.pdf)
*   https://mathoverflow.net/questions/22255/usefulness-of-frechet-versus-Gâteaux-differentiability-or-something-in-between
*   https://faculty.arts.ubc.ca/pschrimpf/526/calculus-526.pdf
*   http://individual.utoronto.ca/jordanbell/notes/frechetderivatives.pdf
*   https://en.wikipedia.org/wiki/Derivative
*   https://en.wikipedia.org/wiki/Directional_derivative
*   https://en.wikipedia.org/wiki/Generalizations_of_the_derivative
*   https://en.wikipedia.org/wiki/Fréchet_derivative
*   https://en.wikipedia.org/wiki/Gâteaux_derivative
*   https://en.wikipedia.org/wiki/Jacobi_operator

Matrix calculus

*   https://en.wikipedia.org/wiki/Matrix_calculus
*   https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf
*   https://ccrma.stanford.edu/~dattorro/matrixcalc.pdf
*   http://www.matrixcalculus.org/
*   https://explained.ai/matrix-calculus/
*   https://atmos.washington.edu/~dennis/MatrixCalculus.pdf

Calculus in Banach spaces

*   https://www.johndcook.com/Differentiation_in_Banach_spaces.pdf
*   https://math.stackexchange.com/questions/291318/derivative-of-the-2-norm-of-a-multivariate-function
*   https://math.stackexchange.com/questions/659712/derivative-on-hilbert-space
*   http://www.math.ucsd.edu/~bdriver/231-02-03/Lecture_Notes/chap22.pdf
https://www.math.ucdavis.edu/~hunter/book/ch13.pdf
*   http://www.math.ntu.edu.tw/~dragon/Lecture%20Notes/Banach%20Calculus%202012.pdf
*   https://math.byu.edu/~bakker/Math634/Math634Lectures/Lec19.pdf
 --> <hr> <div class=md-source-date> <small> Last update: 2020-05-29 20:03:43 </small> </div> <h2 id=__comments>Comments</h2> <div id=disqus_thread></div> <script>var disqus_config=function(){this.page.url="https://SudipSinha.github.io/Infinities-in-my-Brain/functional-analysis/derivatives/",this.page.identifier="/functional-analysis/derivatives/"};!function(){var e=document,i=e.createElement("script");i.src="//SudipSinha.disqus.com/embed.js",i.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(i)}()</script> </article> </div> </div> </main> <footer class=md-footer> <div class=md-footer-nav> <nav aria-label=Footer class="md-footer-nav__inner md-grid"> <a class="md-footer-nav__link md-footer-nav__link--prev" href=../.. rel=prev title="Infinities in my Brain"> <div class="md-footer-nav__button md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg> </div> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Previous </span> Infinities in my Brain </div> </div> </a> <a class="md-footer-nav__link md-footer-nav__link--next" href=../../probability-theory/first-step-analysis/ rel=next title="First step analysis"> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Next </span> First step analysis </div> </div> <div class="md-footer-nav__button md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"></path></svg> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> <a href=http://github.com/SudipSinha>Sudip Sinha</a> © 2020 onwards </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ rel=noopener target=_blank> Material for MkDocs </a> </div> <div class=md-footer-social> <a class=md-footer-social__link href=https://github.com/SudipSinha rel=noopener target=_blank title=github.com> <svg viewbox="0 0 496 512" xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg> </a> <a class=md-footer-social__link href=https://www.linkedin.com/in/sudipsinha rel=noopener target=_blank title=www.linkedin.com> <svg viewbox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg> </a> <a class=md-footer-social__link href=https://www.facebook.com/SudipSinha rel=noopener target=_blank title=www.facebook.com> <svg viewbox="0 0 512 512" xmlns=http://www.w3.org/2000/svg><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"></path></svg> </a> <a class=md-footer-social__link href=https://twitter.com/SudipSinha rel=noopener target=_blank title=twitter.com> <svg viewbox="0 0 512 512" xmlns=http://www.w3.org/2000/svg><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg> </a> <a class=md-footer-social__link href=https://orcid.org/0000-0001-5188-1336 rel=noopener target=_blank title=orcid.org> <svg viewbox="0 0 512 512" xmlns=http://www.w3.org/2000/svg><path d="M294.75 188.19h-45.92V342h47.47c67.62 0 83.12-51.34 83.12-76.91 0-41.64-26.54-76.9-84.67-76.9zM256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm-80.79 360.76h-29.84v-207.5h29.84zm-14.92-231.14a19.57 19.57 0 1119.57-19.57 19.64 19.64 0 01-19.57 19.57zM300 369h-81V161.26h80.6c76.73 0 110.44 54.83 110.44 103.85C410 318.39 368.38 369 300 369z"></path></svg> </a> <a class=md-footer-social__link href=mailto:SudipSinha.Bappa@Gmail.com rel=noopener target=_blank title> <svg viewbox="0 0 512 512" xmlns=http://www.w3.org/2000/svg><path d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"></path></svg> </a> </div> </div> </div> </footer> </div> <script src=../../assets/javascripts/vendor.22b62ea4.min.js></script> <script src=../../assets/javascripts/bundle.5f27aba8.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script> <script>
        app = initialize({
          base: "../..",
          features: [],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.f6ebf1dc.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> <script src=../../javascripts/macros4mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=https://unpkg.com/mermaid@8.4.5/dist/mermaid.min.js></script> <script src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script> </body> </html>