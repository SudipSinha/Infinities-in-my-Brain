{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Infinities in my Brain \u00b6 Introduction \u00b6 Hello! I am a student in mathematics at Louisiana State University. This is my blog, in which I try to write notes on simple topics in mathematics that is dumbed down so that I can understand them. Hopefully you will find them interesting and helpful. I would love to have feedback, so please do not hesitate to contact me. My website is sites.google.com/view/sudip-sinha . Motivation \u00b6 It happens quite frequently to me that I understand an idea and later forget it. This makes me keep coming back to the same things over and over again, which became frustrating. So I have decided to write down some of the topics that I understand in my own words, so that I can use these notes to teach myself and others in the future. Philosophy \u00b6 My understanding of mathematics is incremental and based on examples. By this, I mean that I like to see simple examples, and then like to see a generalization of an idea, as opposed to proving an abstract idea and seeing its restriction to simpler cases. I will try to stick to this way in my writings. Thanks \u00b6 This website is designed using the following. MkDocs for static site generation. Material for MkDocs for the material theme. MathJax for rendering \\( \\LaTeX \\) .","title":"Infinities in my Brain"},{"location":"#infinities-in-my-brain","text":"","title":"Infinities in my Brain"},{"location":"#introduction","text":"Hello! I am a student in mathematics at Louisiana State University. This is my blog, in which I try to write notes on simple topics in mathematics that is dumbed down so that I can understand them. Hopefully you will find them interesting and helpful. I would love to have feedback, so please do not hesitate to contact me. My website is sites.google.com/view/sudip-sinha .","title":"Introduction"},{"location":"#motivation","text":"It happens quite frequently to me that I understand an idea and later forget it. This makes me keep coming back to the same things over and over again, which became frustrating. So I have decided to write down some of the topics that I understand in my own words, so that I can use these notes to teach myself and others in the future.","title":"Motivation"},{"location":"#philosophy","text":"My understanding of mathematics is incremental and based on examples. By this, I mean that I like to see simple examples, and then like to see a generalization of an idea, as opposed to proving an abstract idea and seeing its restriction to simpler cases. I will try to stick to this way in my writings.","title":"Philosophy"},{"location":"#thanks","text":"This website is designed using the following. MkDocs for static site generation. Material for MkDocs for the material theme. MathJax for rendering \\( \\LaTeX \\) .","title":"Thanks"},{"location":"functional-analysis/multidimensional-derivatives/","text":"Demystifying multidimensional derivatives \u00b6 Warning This is still in draft mode. If you have any comments/suggestions, please email me so that I can improve on this. Abstract We see why there is no unique concept of a derivative for functions on spaces of dimension greater than one. Prerequisites Knowledge of elementary real analysis and linear algebra is essential, but some familiarity with functional analysis will greatly improve your experience. What is a derivative of a function? \u00b6 We are introduced to derivatives as the rate of change of a function at a given point in the domain of the function. Is this the only way to think of the derivative? My thesis for this essay is that there is another way of looking at derivatives which allows us to generalize it to much general spaces. Derivative in \\( 1 \\) -dimensional space \u00b6 First, we look at the simplest case \u2014 derivative of a function in a \\( 1 \\) -dimensional space. Given a function \\( f: G \u2286 \u211d \u2192 \u211d \\) , we say that the derivative of the function \\( f \\) at a fixed point \\( x \u2208 G \\) is defined as \\[\\begin{equation} \\label{def:derivative-1dim} f'(x) = \\lim_{h \u2192 0} \\frac{f(x + h) - f(x)}{h} , \\end{equation}\\] provided the limit exists. Convention In what follows, whenever we write a definition in terms of a limit, we will assume that the limit exists. Note that we can rewrite \\eqref{def:derivative-1dim} as \\[\\begin{equation} \\label{def:derivative-1dim-linear} f(x + h) - f(x) - f'(x) h = o(h) , \\end{equation}\\] where \\( \\frac{o(k)}{k} \u2192 0 \\) as \\( k \u2192 0 \\) . See Landau notations for more details. That is, the linearization of the function \\( f \\) about the fixed point \\( x \\) is given by \\( l_x(h) = f(x) + f'(x) h \\) . An informal way to understand \\eqref{def:derivative-1dim-linear} is to think that the difference between the function and the linearization is small as we get close to \\( x \\) . Therefore, we could as easily have defined the derivative using \\eqref{def:derivative-1dim-linear} instead of \\eqref{def:derivative-1dim}. Are both the same, or should we prefer one over the other? As we saw, in \\( 1 \\) -dimension, both are equivalent. But in higher dimensions, these two perspectives sometimes give different results, and so it is important to understand both sides of the picture. This will be the point of the article. Higher dimensions \u00b6 TODO Can we increase the dimension of the spaces we considered? Note that we have control over two spaces, the domain and the codomain. First, let us try to have a \\( 2 \\) -dimensional codomain. Let \\( f: U \u2286 \u211d \u2192 \u211d^2 \\) . How do we find the derivative of such a function? We can do a \"coordinate-wise\" differentiation here. Let \\( f(x) = (f_1(x), f_2(x)) \\) . Note that we can always do this as for \\( i \u2208 \\bcrl{1, 2} \\) , we can simply define \\( f_i = f \u2218 \u03c0_i \\) , where \\( \u03c0_i \\) is the projection onto the \\( i \\) th coordinate. Now, using \\eqref{def:derivative-1dim}, we can define the derivative of \\( f \\) at \\( x \\) as \\[ f'(x) = (f_1'(x), f_2'(x)) . \\] Traversing the unit circle As an example of such function, let \\( \ud835\udd4a^1 = \\bcrl{(x_1, x_2) \u2208 \u211d^2 : \\norm{x}_2 = 1} \\) be the unit circle, and \\( \u03b8 \u2208 \ud835\udd4b = [0, 2\u03c0) \\) represent anglular measures about the origin. Then there is a bijection between \\( \ud835\udd4b \\) and \\( \ud835\udd4a^1 \\) , that is given by \\( f: \ud835\udd4b \u2192 \ud835\udd4a^1: \u03b8 \u21a6 (\\cos(\u03b8), \\sin(\u03b8)) \\) . To calculate the rate of change of a particle's position with respect to changing angles, we can simple calculate the derivative of \\( f \\) at an angle \\( \u03b8 \\) . \\[ f'(\u03b8) = (\\cos'(\u03b8), \\sin'(\u03b8)) = (-\\sin(\u03b8), \\cos(\u03b8)) . \\] The moral of the above argument is that the dimension of the codomain does not affect us much, we can always differentiate each coordinate (at least for countable-dimensional codomains). Thus, we shall only focus on the domain from now on. So far, so good. Can we do the same if we have a \\( 2 \\) -dimensional domain? Take a function \\( f: \u211d^2 \u2192 \u211d \\) . How do we define the derivative of \\( f \\) ? The problem here is that there are two inputs. In the problems until now, there was only one input, so we could just increase or decrease it by \\( h \\) . In other words, there were two ways of \\( h \\) approaching \\( 0 \\) , from the left and from the right. But now we have infinite possibilities as any point in a \\( 2 \\) -dimensional space can be approached in infinite ways! Vector calculus \u00b6 One way to differentiate linear and quadratic functionals on a finite-dimensional vector space is to use a basis. In this section, let \\( V \\) be a \\( d \\) -dimensional real vector space. Fix a basis \\( \u212c = \\bcrl{e_1, \u2026, e_d} \\) for \\( V \\) so that we can express any \\( x \u2208 V \\) as \\( x = \u2211_{i = 1}^d x_i e_i \\) for some \\( x_i \u2208 \u211d \\) for each \\( i \u2208 [d] \\) . This gives us an identification of \\( V \\) with \\( \u211d^d \\) , and we can write the identification of \\( x \u2208 V \\) as the column vector \\( (x_1, \u2026, x_d) \u2208 \u211d^d \\) . We shall use the notation \\( \u22c5^* \\) to represents the transpose operation, and denote \\( [d] = \\bcrl{1, \u2026, d} \\) . TODO Give motivation behind linear and quadratic forms. Linear functionals Let \\( v \u2208 V \\) be fixed and \\( m_v: V \u2192 \u211d: x \u21a6 \\inn{x, v} \\) . Using the identification, we write \\( v = (v_1, \u2026, v_d) \u2208 \u211d^d \\) . So our definition of \\( m_v \\) becomes \\( m_v(x) = x^* v = \u2211_{i = 1}^d x_i v_i \\) . Now, \\( \\frac{\u2202m_v(x)}{\u2202x_j} = v_j \\) , so writing this in the numerator layout convention , we get \\[ \\frac{\u2202m_v(x)}{\u2202x} = \\begin{bmatrix} v_1 & \u22ef & v_d \\end{bmatrix} = v^* , \\] so we can write \\( \\frac{\u2202m_v(x)}{\u2202x} = \\inn{\u22c5, v} \\) . Quadratic functionals Let \\( f: V \u2192 \u211d: x \u21a6 \\inn{x, T x} \\) , where \\( T: V \u2192 V \\) is a linear operator. In the basis \\( \u212c \\) , the operator \\( T \\) has a unique matrix representative, say \\( A = (a_{ij})_{i, j \u2208 [d]} \\) . Therefore, we can write \\[\\begin{align*} f(x) & = \\inn{x, T x} \\\\ & = x^* A x \\\\ & = \u2211_{i = 1}^d x_i \u2211_{j = 1}^d a_{ij} x_j \\\\ & = \u2211_{i = 1}^d \u2211_{j = 1}^d x_i a_{ij} x_j \\\\ & = \u2211_{j \u2260 k} x_k a_{kj} x_j + \u2211_{i \u2260 k} x_i a_{ik} x_k \\\\ & \\quad + a_{kk} x_k^2 + \u2211_{i \u2260 k, j \u2260 k} x_i a_{ij} x_j. \\\\ \\end{align*}\\] Taking partial derivatives with respect to \\( x_k \\) , we get \\[\\begin{align*} \\frac{\u2202f(x)}{\u2202x_j} & = \u2211_{j \u2260 k} a_{kj} x_j + \u2211_{i \u2260 k} x_i a_{ik} + 2 a_{kk} x_k + 0 \\\\ & = \u2211_{j = 1}^d a_{kj} x_j + \u2211_{i = 1}^d x_i a_{ik} \\\\ & = A_{k, \u22c5} x + x^* A_{\u22c5, k} \\\\ & = x^* A_{k, \u22c5}^* + x^* A_{\u22c5, k} \\\\ & = x^* \\brnd{A_{\u22c5, k} + A_{k, \u22c5}^*} . \\\\ \\end{align*}\\] Finally, writing in the numerator layout convention , we get \\[\\begin{align*} \\frac{\u2202f(x)}{\u2202x} & = \\begin{bmatrix} x^* \\brnd{A_{\u22c5, 1} + A_{1, \u22c5}^*} & \u22ef & x^* \\brnd{A_{\u22c5, d} + A_{d, \u22c5}^*} \\\\ \\end{bmatrix} \\\\ & = x^* \\brnd{ \\begin{bmatrix} A_{\u22c5, 1} & \u22ef & A_{\u22c5, d} \\\\ \\end{bmatrix} + \\begin{bmatrix} A_{1, \u22c5}^* & \u22ef & A_{d, \u22c5}^* \\\\ \\end{bmatrix} } \\\\ & = x^* (A^* + A) \\\\ & = x^* \\brnd{A + A^*}^* \\\\ & = \\brnd{(A + A^*) x}^* , \\\\ \\end{align*}\\] where in the penultimate steps we used the involution and anti-distributivity properties of the adjoint . Therefore, we can write \\( \\frac{\u2202f(x)}{\u2202x} = \\inn{\u22c5, (A + A^*) x} \\) . Note that our final results in both cases do not depend on the choice of the basis. So our intuition says that there should be basis-free ways of deriving the same results. We shall soon see that this is true. Generalizing \u00b6 From now on, instead of looking at the Euclidean spaces \\( \u211d^n \\) , we shall look at general real vector spaces. We will come back to Euclidean spaces, and see what happens in these special cases. We can look at the problem in two ways. In Fr\u00e9chet's way, we do not care about the path of approach and try to get a uniform linearization . In G\u00e2teaux's way, we fix a direction, so we can only talk about two ways of approaching as in our \\( 1 \\) -dimensional case. Fr\u00e9chet derivative \u00b6 Definition Let \\( V, W \\) be normed vector spaces , and \\( U \u2286 V \\) . A function \\( f : U \u2192 W \\) is called Fr\u00e9chet differentiable at \\( x \u2208 U \\) if there exists a bounded linear operator \\( L_x: V \u2192 W \\) such that \\[\\begin{equation} \\label{def:Fr\u00e9chet-derivative} \\norm{f(x + h) - f(x) - L_x h}_W = o\\brnd{\\norm{h}_V} \\text{ as } \\norm{h}_V \u2192 0 . \\end{equation}\\] Notes This approach is similar to the one used in \\eqref{def:derivative-1dim-linear}. It is customary to write the action of a linear operator \\( T \\) on a vector \\( v \\) by \\( T v \\) instead of \\( T(v) \\) . They are the same. Proposition \\( L_x \\) is unique. Proof Suppose not. That is, suppose there exists two such linear operators, say \\( L_x \\) and \\( \\tilde{L}_x \\) that satisfy \\eqref{def:Fr\u00e9chet-derivative}. Therefore, we have \\[\\begin{align*} \\norm{f(x + h) - f(x) - L_x h}_W = o\\brnd{\\norm{h}_V} \\\\ \\norm{f(x + h) - f(x) - \\tilde{L}_x h}_W = o\\brnd{\\norm{h}_V} \\\\ \\end{align*}\\] Now, using the triangle inequality of the norm, we get \\[\\begin{align*} \\norm{(\\tilde{L}_x - L_x) h}_W & = \\norm{(-L_x h) - (-\\tilde{L}_x h)}_W \\\\ & = \\norm{(f(x + h) - f(x) - L_x h) - (f(x + h) - f(x) - \\tilde{L}_x h)}_W \\\\ & \u2264 \\norm{f(x + h) - f(x) - L_x h}_W + \\norm{f(x + h) - f(x) - \\tilde{L}_x h}_W \\\\ & = o\\brnd{\\norm{h}_V} + o\\brnd{\\norm{h}_V} = o\\brnd{\\norm{h}_V} . \\\\ \\end{align*}\\] This gives us \\[ \\norm{\\tilde{L}_x - L_x}_\u221e = \\sup_{\\norm{h}_V \u2264 1} \\frac{\\norm{(\\tilde{L}_x - L_x) h}_W}{\\norm{h}_V} = \\sup_{\\norm{h}_V \u2264 1} \\frac{o\\brnd{\\norm{h}_V}}{\\norm{h}_V} \u2192 0 \\text{ as } \\norm{h}_V \u2192 0 . \\] Therefore, \\( \\tilde{L}_x = L_x \\) , and we are done. Since such an operator \\( L_x \\) is unique (if it exists), we write \\( \\D f(x) = L_x \\) and call it the Fr\u00e9chet derivative of \\( f \\) at \\( x \\) . G\u00e2teaux differential \u00b6 Definition Let \\( V, W \\) be normed vector spaces , and \\( U \u2286 V \\) . The G\u00e2teaux differential of a function \\( f : U \u2192 W \\) at \\( x \u2208 U \\) in the direction \\( v \\) is defined as \\[\\begin{equation} \\label{def:G\u00e2teaux-differential} \\d_h f(x) = \\lim_{t \u2192 0} \\frac{f(x + t v) - f(x)}{t} = \\left. \\frac{d}{d t} \\right|_{t = 0} f(x + t v) . \\end{equation}\\] If the limit exists for all \\( v \u2208 V \\) , then we say that \\( f \\) is G\u00e2teaux differentiable at \\( x \\) . Note This approach is similar to the one used in \\eqref{def:derivative-1dim}. The G\u00e2teaux differential is unique if it exists, since the limit in the definition is unique if it exists. Existence of the G\u00e2teaux differential does not guarantee continuity. See examples here . The G\u00e2teaux differential is related to the Fr\u00e9chet derivative by \\( \\d_h f(x) = \\D f(x) h \\) (when both exist). There is a G\u00e2teaux differential for each direction. So in \\( 1 \\) -dimension real vector space, there are two ( left and right ) such derivatives, but in two or more dimensions or in any complex vector space, there are infinitely (uncountably) many. The G\u00e2teaux differential is a \\( 1 \\) -dimensional calculation along a specified direction \\( h \\) , so we can use our ordinary \\( 1 \\) -dimensional calculus to compute it. This makes computability much easier. The fundamental theorem of calculus for G\u00e2teaux differentials is \\( f(x + h) - f(x) = \u222b_0^1 \\d_h f(x + t h) \\d t \\) . Special cases \u00b6 In Euclidean spaces Directional derivatives are basically G\u00e2teaux differentials The total derivative or the gradient are basically the Fr\u00e9chet derivative. Examples \u00b6 Finite-dimensional spaces \u00b6 The absolute value function on \u211d Let \\( f: \u211d \u2192 \u211d: x \u21a6 \\abs{x} \\) . If \\( x = 0 \\) , then we have \\( \\lim_{t \u2192 0} \\frac{\\abs{t h}}{t} \\) . If \\( h > 0 \\) then the limit is \\( h \\) , and if \\( h < 0 \\) then the limit is \\( -h \\) , which we combine to get the limit as \\( \\abs{h} \\) . Now, if \\( x \u2260 0 \\) , then in the limit \\( x + th \\) will have the same sign as \\( x \\) . Following the same logic as for \\( x = 0 \\) , we get the derivative as \\( h \\frac{x}{\\abs{x}} \\) . Therefore, \\[ \\d_h f(x) = \\begin{cases} h \\frac{x}{\\abs{x}} & \\text{if } x \u2260 0 \\\\ \\abs{h} & \\text{if } x = 0 \\\\ \\end{cases} . \\] It might be surprising to find out that the G\u00e2teaux differential of the absolute value function exists at \\( 0 \\) . In ordinary derivatives, the limit for the derivative does not exist at \\( 0 \\) because we approach it from both sides. But in G\u00e2teaux differentials, we specify a direction ( \\( h \\) ), so we do not have the same problem. But note that the G\u00e2teaux differential depends on \\( h \\) in a nonlinear way, and therefore there is no Fr\u00e9chet derivative. Hilbert spaces \u00b6 In what follows, \\( V \\) is a real Hilbert space. Linear functionals Let \\( v \u2208 V \\) be fixed and \\( m_v: V \u2192 \u211d: x \u21a6 \\inn{x, v} \\) . Then G\u00e2teaux differential \\[\\begin{align*} \\d_h m_v(x) & = \\lim_{t \u2192 0} \\frac{m_v(x + t h) - m_v(x)}{t} \\\\ & = \\lim_{t \u2192 0} \\frac{\\inn{\\cancel{x} + \\bcancel{t} h, v} - \\cancel{\\inn{x, v}}}{\\bcancel{t}} \\\\ & = \\inn{h, v} . \\\\ \\end{align*}\\] Fr\u00e9chet derivative : Since the G\u00e2teaux differential is linear in \\( h \\) , the Fr\u00e9chet derivative is the same as the G\u00e2teaux differential. That is, \\( \\D f(x): V \u2192 \u211d: h \u21a6 \\inn{h, v} \\) . The proof is simply writing out the definition of the Fr\u00e9chet derivative. Note that the derivative is independent of \\( x \\) , as we should have expected. Quadratic functionals Let \\( f: V \u2192 \u211d: x \u21a6 \\inn{x, T x} \\) , where \\( T: V \u2192 V \\) is a bounded linear operator. G\u00e2teaux differential \\[\\begin{align*} \\d_h f(x) & = \\lim_{t \u2192 0} \\frac{f(x + t h) - f(x)}{t} \\\\ & = \\lim_{t \u2192 0} \\frac{\\inn{x + t h, T (x + t h)} - \\inn{x, Tx}}{t} \\\\ & = \\lim_{t \u2192 0} \\frac{\\cancel{\\inn{x, T x}} + \\bcancel{t} \\inn{x, T h} + \\bcancel{t} \\inn{h, T x} + t^\\bcancel{2} \\inn{h, T h} - \\cancel{\\inn{x, T x}}}{\\bcancel{t}} \\\\ & = \\inn{x, T h} + \\inn{h, T x} \\\\ & = \\inn{T^* x, h} + \\inn{h, T x} \\\\ & = \\inn{h, T^* x} + \\inn{h, T x} \\\\ & = \\inn{h, (T + T^*) x} , \\\\ \\end{align*}\\] where in the third last step, we have used the definition of adjoint of an operator . Fr\u00e9chet derivative : The linearity of the G\u00e2teaux differential shows us that the Fr\u00e9chet derivative is the same. In this case, \\( \\D f(x): V \u2192 \u211d: h \u21a6 \\inn{h, (T + T^*) x} \\) . Note the analogy with \\( \\frac{d (a x^2)}{d x} h = h (a + a) x \\) . Summary \u00b6 Relationship between the two derivatives \u00b6 Implications Fr\u00e9chet differentiability implies G\u00e2teaux differentiability. Proof Assume \\( f: V \u2192 W \\) has Fr\u00e9chet derivative \\( \\D f(x) \\) at \\( x \u2208 V \\) . Now, \\[\\begin{align*} & \\norm{\\frac{f(x + t v) - f(x)}{t} - \\D f(x)(v)}_W \\\\ = & \\frac{\\norm{f(x + t v) - f(x) - \\D f(x)(v) t}_W}{\\abs{t} \\norm{v}_V} \\norm{v}_V \\\\ = & \\frac{\\norm{f(x + t v) - f(x) - \\D f(x)(tv)}_W}{\\norm{t v}_V} \\norm{v}_V \u2192 0 \\\\ \\end{align*}\\] as \\( t \u2192 0 \\) since \\( \\norm{t v}_V \u2192 0 \\) as \\( t \u2192 0 \\) and \\( f \\) is Fr\u00e9chet differentiable. Note The converse of the above proposition is not true, as is shown by the counterexample. \\[ f(x, y) = \\frac{x^3}{x^2 + y^2} \ud835\udfd9_{(x, y) \u2260 (0, 0)}(x, y) . \\] The Fr\u00e9chet differentiability is a stronger notion. The Fr\u00e9chet derivative contains information about the rate of change of the norm of the function about a particular point independent of direction. It is true to the spirit of the original derivative in the sense that it is still linear. Its existence guarantees the existence of the G\u00e2teaux differential. The G\u00e2teaux differentiability is a strictly weaker notion. The G\u00e2teaux differential need not be linear, and its existence does not imply the existence of the Fr\u00e9chet derivative. In fact, its existence at a point does not even guarantee the continuity of the function at that point. It gives us the rate of change of a function only in a particular direction. This rate of change is not just of the norm, but of the vector output itself. The G\u00e2teaux differential only requires that the difference quotients converge along each direction individually, without making requirements about the rates of convergence for different directions. Thus, in order for a linear G\u00e2teaux differential to imply the existence of the Fr\u00e9chet derivative, the difference quotients have to converge uniformly for all directions. So even though G\u00e2teaux differentiability is closer to the definition of the deriviative in \\( 1 \\) -dimensional spaces, the Fr\u00e9chet derivative is closer to the true sprit of the derivative as it gives us a local linear approximation of the function. In general, in the infinite dimensional spaces, there are usually reasonably satisfactory results on the existence of G\u00e2teaux differentials of Lipschitz functions. On the other hand, similar results on existence of Fr\u00e9chet derivatives are rare and usually very hard to prove. Therefore, there are significant differences in the two derivates, and it seems to have its own pros and cons. In life, and even more so in mathematics, there is no free lunch. The choice among the two then depends on the requirement. In many applications, we require Fr\u00e9chet derivatives as they provides a genuine local linear approximations unlike the G\u00e2teaux differentials. It is important to remember that if a function is Fr\u00e9chet differentiable, then it is also G\u00e2teaux differentiable, and the two derivatives are equal. The following table highlights some of the differences. property G\u00e2teaux differentials Fr\u00e9chet derivative strength weaker stronger computability direct; ordinary differentiation rules indirect; only verification possible direction dependent independent linear not necessarily yes in \\( \u211d^d \\) directional derivatives total derivative / Jacobian Application: ordinary least squares \u00b6 In this section, we shall use what we learned to derive the normal equations in the ordinary least squares method . The problem setup is as follows. Our data consists of \\( n \\) observations, \\( \\bcrl{(x_i, y_i): i \u2208 [n]} \\) , where \\( y_i \\) is the scalar output and \\( x_i \\) is a \\( p \\) -dimensional vector of input values. In a linear regression model , the output variable is a linear function of the input variables, so \\[ y_i = x_i^* \u03b2 + \u03b5_i , \\] where \\( \u03b2 \\) is a \\( p \\) -dimensional vector assigning weightages to each variable according to their importance in predicting the output, and the scalars \\( \u03b5_i \\) represent the errors. This model can be written in matrix notation as \\[ y = X \u03b2 + \u03b5 , \\] where \\( y \\) and \\( \u03b5 \\) are \\( n \\) -dimensional vectors of the values of the output and the errors for the various observations, and \\( X \\) is an \\( n \u00d7 p \\) matrix of the inputs. Our goal is to get \\( \\hat{\u03b2} \\) which minimizes the squared errors ( \\( \u2113^2 \\) -norm). That is, we want to minimize \\[\\begin{align*} e(\u03b2) & = \\frac12 \\norm{\u03b5}_2^2 \\\\ & = \\frac12 \\inn{\u03b5, \u03b5} \\\\ & = \\frac12 \\inn{X \u03b2 - y, X \u03b2 - y} \\\\ & = \\frac12 \\brnd{\\inn{X \u03b2, X \u03b2} - 2 \\inn{X \u03b2, y} + \\inn{y, y}} \\\\ & = \\frac12 \\inn{\u03b2, X^* X \u03b2} - \\inn{\u03b2, X^* y} + \\frac12 \\inn{y, y} \\\\ \\end{align*}\\] First, notice that \\( X^* X \\) is self-adjoint, that is, \\( (X^* X)^* = X^* X \\) . Now, using the examples of linear and quadratic functionals, we get the Fr\u00e9chet derivative \\[\\begin{align*} De(\u03b2) h & = \\frac12 \\inn{h, (X^* X + (X^* X)^*) \u03b2} - \\inn{h, X^* y} \\\\ & = \\frac{1}{\\cancel2} \\inn{h, \\cancel2 X^* X \u03b2} - \\inn{h, X^* y} \\\\ & = \\inn{h, X^* (X \u03b2 - y)} , \\\\ \\end{align*}\\] where we used the fact that an inner product in a real vector space is linear also in the second argument. For a minimum, we want \\( De(\\hat{\u03b2}) h = 0 \\) for any \\( h \\) . This is only possible if \\( X^* (X \\hat{\u03b2} - y) = 0 \\) , which gives us our optimality condition \\[\\begin{equation} \\hat{\u03b2} = (X^* X)^{-1} X^* y . \\end{equation}\\]","title":"Demystifying multidimensional derivatives"},{"location":"functional-analysis/multidimensional-derivatives/#demystifying-multidimensional-derivatives","text":"Warning This is still in draft mode. If you have any comments/suggestions, please email me so that I can improve on this. Abstract We see why there is no unique concept of a derivative for functions on spaces of dimension greater than one. Prerequisites Knowledge of elementary real analysis and linear algebra is essential, but some familiarity with functional analysis will greatly improve your experience.","title":"Demystifying multidimensional derivatives"},{"location":"functional-analysis/multidimensional-derivatives/#what-is-a-derivative-of-a-function","text":"We are introduced to derivatives as the rate of change of a function at a given point in the domain of the function. Is this the only way to think of the derivative? My thesis for this essay is that there is another way of looking at derivatives which allows us to generalize it to much general spaces.","title":"What is a derivative of a function?"},{"location":"functional-analysis/multidimensional-derivatives/#derivative-in-1-dimensional-space","text":"First, we look at the simplest case \u2014 derivative of a function in a \\( 1 \\) -dimensional space. Given a function \\( f: G \u2286 \u211d \u2192 \u211d \\) , we say that the derivative of the function \\( f \\) at a fixed point \\( x \u2208 G \\) is defined as \\[\\begin{equation} \\label{def:derivative-1dim} f'(x) = \\lim_{h \u2192 0} \\frac{f(x + h) - f(x)}{h} , \\end{equation}\\] provided the limit exists. Convention In what follows, whenever we write a definition in terms of a limit, we will assume that the limit exists. Note that we can rewrite \\eqref{def:derivative-1dim} as \\[\\begin{equation} \\label{def:derivative-1dim-linear} f(x + h) - f(x) - f'(x) h = o(h) , \\end{equation}\\] where \\( \\frac{o(k)}{k} \u2192 0 \\) as \\( k \u2192 0 \\) . See Landau notations for more details. That is, the linearization of the function \\( f \\) about the fixed point \\( x \\) is given by \\( l_x(h) = f(x) + f'(x) h \\) . An informal way to understand \\eqref{def:derivative-1dim-linear} is to think that the difference between the function and the linearization is small as we get close to \\( x \\) . Therefore, we could as easily have defined the derivative using \\eqref{def:derivative-1dim-linear} instead of \\eqref{def:derivative-1dim}. Are both the same, or should we prefer one over the other? As we saw, in \\( 1 \\) -dimension, both are equivalent. But in higher dimensions, these two perspectives sometimes give different results, and so it is important to understand both sides of the picture. This will be the point of the article.","title":"Derivative in \\( 1 \\)-dimensional space"},{"location":"functional-analysis/multidimensional-derivatives/#higher-dimensions","text":"TODO Can we increase the dimension of the spaces we considered? Note that we have control over two spaces, the domain and the codomain. First, let us try to have a \\( 2 \\) -dimensional codomain. Let \\( f: U \u2286 \u211d \u2192 \u211d^2 \\) . How do we find the derivative of such a function? We can do a \"coordinate-wise\" differentiation here. Let \\( f(x) = (f_1(x), f_2(x)) \\) . Note that we can always do this as for \\( i \u2208 \\bcrl{1, 2} \\) , we can simply define \\( f_i = f \u2218 \u03c0_i \\) , where \\( \u03c0_i \\) is the projection onto the \\( i \\) th coordinate. Now, using \\eqref{def:derivative-1dim}, we can define the derivative of \\( f \\) at \\( x \\) as \\[ f'(x) = (f_1'(x), f_2'(x)) . \\] Traversing the unit circle As an example of such function, let \\( \ud835\udd4a^1 = \\bcrl{(x_1, x_2) \u2208 \u211d^2 : \\norm{x}_2 = 1} \\) be the unit circle, and \\( \u03b8 \u2208 \ud835\udd4b = [0, 2\u03c0) \\) represent anglular measures about the origin. Then there is a bijection between \\( \ud835\udd4b \\) and \\( \ud835\udd4a^1 \\) , that is given by \\( f: \ud835\udd4b \u2192 \ud835\udd4a^1: \u03b8 \u21a6 (\\cos(\u03b8), \\sin(\u03b8)) \\) . To calculate the rate of change of a particle's position with respect to changing angles, we can simple calculate the derivative of \\( f \\) at an angle \\( \u03b8 \\) . \\[ f'(\u03b8) = (\\cos'(\u03b8), \\sin'(\u03b8)) = (-\\sin(\u03b8), \\cos(\u03b8)) . \\] The moral of the above argument is that the dimension of the codomain does not affect us much, we can always differentiate each coordinate (at least for countable-dimensional codomains). Thus, we shall only focus on the domain from now on. So far, so good. Can we do the same if we have a \\( 2 \\) -dimensional domain? Take a function \\( f: \u211d^2 \u2192 \u211d \\) . How do we define the derivative of \\( f \\) ? The problem here is that there are two inputs. In the problems until now, there was only one input, so we could just increase or decrease it by \\( h \\) . In other words, there were two ways of \\( h \\) approaching \\( 0 \\) , from the left and from the right. But now we have infinite possibilities as any point in a \\( 2 \\) -dimensional space can be approached in infinite ways!","title":"Higher dimensions"},{"location":"functional-analysis/multidimensional-derivatives/#vector-calculus","text":"One way to differentiate linear and quadratic functionals on a finite-dimensional vector space is to use a basis. In this section, let \\( V \\) be a \\( d \\) -dimensional real vector space. Fix a basis \\( \u212c = \\bcrl{e_1, \u2026, e_d} \\) for \\( V \\) so that we can express any \\( x \u2208 V \\) as \\( x = \u2211_{i = 1}^d x_i e_i \\) for some \\( x_i \u2208 \u211d \\) for each \\( i \u2208 [d] \\) . This gives us an identification of \\( V \\) with \\( \u211d^d \\) , and we can write the identification of \\( x \u2208 V \\) as the column vector \\( (x_1, \u2026, x_d) \u2208 \u211d^d \\) . We shall use the notation \\( \u22c5^* \\) to represents the transpose operation, and denote \\( [d] = \\bcrl{1, \u2026, d} \\) . TODO Give motivation behind linear and quadratic forms. Linear functionals Let \\( v \u2208 V \\) be fixed and \\( m_v: V \u2192 \u211d: x \u21a6 \\inn{x, v} \\) . Using the identification, we write \\( v = (v_1, \u2026, v_d) \u2208 \u211d^d \\) . So our definition of \\( m_v \\) becomes \\( m_v(x) = x^* v = \u2211_{i = 1}^d x_i v_i \\) . Now, \\( \\frac{\u2202m_v(x)}{\u2202x_j} = v_j \\) , so writing this in the numerator layout convention , we get \\[ \\frac{\u2202m_v(x)}{\u2202x} = \\begin{bmatrix} v_1 & \u22ef & v_d \\end{bmatrix} = v^* , \\] so we can write \\( \\frac{\u2202m_v(x)}{\u2202x} = \\inn{\u22c5, v} \\) . Quadratic functionals Let \\( f: V \u2192 \u211d: x \u21a6 \\inn{x, T x} \\) , where \\( T: V \u2192 V \\) is a linear operator. In the basis \\( \u212c \\) , the operator \\( T \\) has a unique matrix representative, say \\( A = (a_{ij})_{i, j \u2208 [d]} \\) . Therefore, we can write \\[\\begin{align*} f(x) & = \\inn{x, T x} \\\\ & = x^* A x \\\\ & = \u2211_{i = 1}^d x_i \u2211_{j = 1}^d a_{ij} x_j \\\\ & = \u2211_{i = 1}^d \u2211_{j = 1}^d x_i a_{ij} x_j \\\\ & = \u2211_{j \u2260 k} x_k a_{kj} x_j + \u2211_{i \u2260 k} x_i a_{ik} x_k \\\\ & \\quad + a_{kk} x_k^2 + \u2211_{i \u2260 k, j \u2260 k} x_i a_{ij} x_j. \\\\ \\end{align*}\\] Taking partial derivatives with respect to \\( x_k \\) , we get \\[\\begin{align*} \\frac{\u2202f(x)}{\u2202x_j} & = \u2211_{j \u2260 k} a_{kj} x_j + \u2211_{i \u2260 k} x_i a_{ik} + 2 a_{kk} x_k + 0 \\\\ & = \u2211_{j = 1}^d a_{kj} x_j + \u2211_{i = 1}^d x_i a_{ik} \\\\ & = A_{k, \u22c5} x + x^* A_{\u22c5, k} \\\\ & = x^* A_{k, \u22c5}^* + x^* A_{\u22c5, k} \\\\ & = x^* \\brnd{A_{\u22c5, k} + A_{k, \u22c5}^*} . \\\\ \\end{align*}\\] Finally, writing in the numerator layout convention , we get \\[\\begin{align*} \\frac{\u2202f(x)}{\u2202x} & = \\begin{bmatrix} x^* \\brnd{A_{\u22c5, 1} + A_{1, \u22c5}^*} & \u22ef & x^* \\brnd{A_{\u22c5, d} + A_{d, \u22c5}^*} \\\\ \\end{bmatrix} \\\\ & = x^* \\brnd{ \\begin{bmatrix} A_{\u22c5, 1} & \u22ef & A_{\u22c5, d} \\\\ \\end{bmatrix} + \\begin{bmatrix} A_{1, \u22c5}^* & \u22ef & A_{d, \u22c5}^* \\\\ \\end{bmatrix} } \\\\ & = x^* (A^* + A) \\\\ & = x^* \\brnd{A + A^*}^* \\\\ & = \\brnd{(A + A^*) x}^* , \\\\ \\end{align*}\\] where in the penultimate steps we used the involution and anti-distributivity properties of the adjoint . Therefore, we can write \\( \\frac{\u2202f(x)}{\u2202x} = \\inn{\u22c5, (A + A^*) x} \\) . Note that our final results in both cases do not depend on the choice of the basis. So our intuition says that there should be basis-free ways of deriving the same results. We shall soon see that this is true.","title":"Vector calculus"},{"location":"functional-analysis/multidimensional-derivatives/#generalizing","text":"From now on, instead of looking at the Euclidean spaces \\( \u211d^n \\) , we shall look at general real vector spaces. We will come back to Euclidean spaces, and see what happens in these special cases. We can look at the problem in two ways. In Fr\u00e9chet's way, we do not care about the path of approach and try to get a uniform linearization . In G\u00e2teaux's way, we fix a direction, so we can only talk about two ways of approaching as in our \\( 1 \\) -dimensional case.","title":"Generalizing"},{"location":"functional-analysis/multidimensional-derivatives/#frechet-derivative","text":"Definition Let \\( V, W \\) be normed vector spaces , and \\( U \u2286 V \\) . A function \\( f : U \u2192 W \\) is called Fr\u00e9chet differentiable at \\( x \u2208 U \\) if there exists a bounded linear operator \\( L_x: V \u2192 W \\) such that \\[\\begin{equation} \\label{def:Fr\u00e9chet-derivative} \\norm{f(x + h) - f(x) - L_x h}_W = o\\brnd{\\norm{h}_V} \\text{ as } \\norm{h}_V \u2192 0 . \\end{equation}\\] Notes This approach is similar to the one used in \\eqref{def:derivative-1dim-linear}. It is customary to write the action of a linear operator \\( T \\) on a vector \\( v \\) by \\( T v \\) instead of \\( T(v) \\) . They are the same. Proposition \\( L_x \\) is unique. Proof Suppose not. That is, suppose there exists two such linear operators, say \\( L_x \\) and \\( \\tilde{L}_x \\) that satisfy \\eqref{def:Fr\u00e9chet-derivative}. Therefore, we have \\[\\begin{align*} \\norm{f(x + h) - f(x) - L_x h}_W = o\\brnd{\\norm{h}_V} \\\\ \\norm{f(x + h) - f(x) - \\tilde{L}_x h}_W = o\\brnd{\\norm{h}_V} \\\\ \\end{align*}\\] Now, using the triangle inequality of the norm, we get \\[\\begin{align*} \\norm{(\\tilde{L}_x - L_x) h}_W & = \\norm{(-L_x h) - (-\\tilde{L}_x h)}_W \\\\ & = \\norm{(f(x + h) - f(x) - L_x h) - (f(x + h) - f(x) - \\tilde{L}_x h)}_W \\\\ & \u2264 \\norm{f(x + h) - f(x) - L_x h}_W + \\norm{f(x + h) - f(x) - \\tilde{L}_x h}_W \\\\ & = o\\brnd{\\norm{h}_V} + o\\brnd{\\norm{h}_V} = o\\brnd{\\norm{h}_V} . \\\\ \\end{align*}\\] This gives us \\[ \\norm{\\tilde{L}_x - L_x}_\u221e = \\sup_{\\norm{h}_V \u2264 1} \\frac{\\norm{(\\tilde{L}_x - L_x) h}_W}{\\norm{h}_V} = \\sup_{\\norm{h}_V \u2264 1} \\frac{o\\brnd{\\norm{h}_V}}{\\norm{h}_V} \u2192 0 \\text{ as } \\norm{h}_V \u2192 0 . \\] Therefore, \\( \\tilde{L}_x = L_x \\) , and we are done. Since such an operator \\( L_x \\) is unique (if it exists), we write \\( \\D f(x) = L_x \\) and call it the Fr\u00e9chet derivative of \\( f \\) at \\( x \\) .","title":"Fr\u00e9chet derivative"},{"location":"functional-analysis/multidimensional-derivatives/#gateaux-differential","text":"Definition Let \\( V, W \\) be normed vector spaces , and \\( U \u2286 V \\) . The G\u00e2teaux differential of a function \\( f : U \u2192 W \\) at \\( x \u2208 U \\) in the direction \\( v \\) is defined as \\[\\begin{equation} \\label{def:G\u00e2teaux-differential} \\d_h f(x) = \\lim_{t \u2192 0} \\frac{f(x + t v) - f(x)}{t} = \\left. \\frac{d}{d t} \\right|_{t = 0} f(x + t v) . \\end{equation}\\] If the limit exists for all \\( v \u2208 V \\) , then we say that \\( f \\) is G\u00e2teaux differentiable at \\( x \\) . Note This approach is similar to the one used in \\eqref{def:derivative-1dim}. The G\u00e2teaux differential is unique if it exists, since the limit in the definition is unique if it exists. Existence of the G\u00e2teaux differential does not guarantee continuity. See examples here . The G\u00e2teaux differential is related to the Fr\u00e9chet derivative by \\( \\d_h f(x) = \\D f(x) h \\) (when both exist). There is a G\u00e2teaux differential for each direction. So in \\( 1 \\) -dimension real vector space, there are two ( left and right ) such derivatives, but in two or more dimensions or in any complex vector space, there are infinitely (uncountably) many. The G\u00e2teaux differential is a \\( 1 \\) -dimensional calculation along a specified direction \\( h \\) , so we can use our ordinary \\( 1 \\) -dimensional calculus to compute it. This makes computability much easier. The fundamental theorem of calculus for G\u00e2teaux differentials is \\( f(x + h) - f(x) = \u222b_0^1 \\d_h f(x + t h) \\d t \\) .","title":"G\u00e2teaux differential"},{"location":"functional-analysis/multidimensional-derivatives/#special-cases","text":"In Euclidean spaces Directional derivatives are basically G\u00e2teaux differentials The total derivative or the gradient are basically the Fr\u00e9chet derivative.","title":"Special cases"},{"location":"functional-analysis/multidimensional-derivatives/#examples","text":"","title":"Examples"},{"location":"functional-analysis/multidimensional-derivatives/#finite-dimensional-spaces","text":"The absolute value function on \u211d Let \\( f: \u211d \u2192 \u211d: x \u21a6 \\abs{x} \\) . If \\( x = 0 \\) , then we have \\( \\lim_{t \u2192 0} \\frac{\\abs{t h}}{t} \\) . If \\( h > 0 \\) then the limit is \\( h \\) , and if \\( h < 0 \\) then the limit is \\( -h \\) , which we combine to get the limit as \\( \\abs{h} \\) . Now, if \\( x \u2260 0 \\) , then in the limit \\( x + th \\) will have the same sign as \\( x \\) . Following the same logic as for \\( x = 0 \\) , we get the derivative as \\( h \\frac{x}{\\abs{x}} \\) . Therefore, \\[ \\d_h f(x) = \\begin{cases} h \\frac{x}{\\abs{x}} & \\text{if } x \u2260 0 \\\\ \\abs{h} & \\text{if } x = 0 \\\\ \\end{cases} . \\] It might be surprising to find out that the G\u00e2teaux differential of the absolute value function exists at \\( 0 \\) . In ordinary derivatives, the limit for the derivative does not exist at \\( 0 \\) because we approach it from both sides. But in G\u00e2teaux differentials, we specify a direction ( \\( h \\) ), so we do not have the same problem. But note that the G\u00e2teaux differential depends on \\( h \\) in a nonlinear way, and therefore there is no Fr\u00e9chet derivative.","title":"Finite-dimensional spaces"},{"location":"functional-analysis/multidimensional-derivatives/#hilbert-spaces","text":"In what follows, \\( V \\) is a real Hilbert space. Linear functionals Let \\( v \u2208 V \\) be fixed and \\( m_v: V \u2192 \u211d: x \u21a6 \\inn{x, v} \\) . Then G\u00e2teaux differential \\[\\begin{align*} \\d_h m_v(x) & = \\lim_{t \u2192 0} \\frac{m_v(x + t h) - m_v(x)}{t} \\\\ & = \\lim_{t \u2192 0} \\frac{\\inn{\\cancel{x} + \\bcancel{t} h, v} - \\cancel{\\inn{x, v}}}{\\bcancel{t}} \\\\ & = \\inn{h, v} . \\\\ \\end{align*}\\] Fr\u00e9chet derivative : Since the G\u00e2teaux differential is linear in \\( h \\) , the Fr\u00e9chet derivative is the same as the G\u00e2teaux differential. That is, \\( \\D f(x): V \u2192 \u211d: h \u21a6 \\inn{h, v} \\) . The proof is simply writing out the definition of the Fr\u00e9chet derivative. Note that the derivative is independent of \\( x \\) , as we should have expected. Quadratic functionals Let \\( f: V \u2192 \u211d: x \u21a6 \\inn{x, T x} \\) , where \\( T: V \u2192 V \\) is a bounded linear operator. G\u00e2teaux differential \\[\\begin{align*} \\d_h f(x) & = \\lim_{t \u2192 0} \\frac{f(x + t h) - f(x)}{t} \\\\ & = \\lim_{t \u2192 0} \\frac{\\inn{x + t h, T (x + t h)} - \\inn{x, Tx}}{t} \\\\ & = \\lim_{t \u2192 0} \\frac{\\cancel{\\inn{x, T x}} + \\bcancel{t} \\inn{x, T h} + \\bcancel{t} \\inn{h, T x} + t^\\bcancel{2} \\inn{h, T h} - \\cancel{\\inn{x, T x}}}{\\bcancel{t}} \\\\ & = \\inn{x, T h} + \\inn{h, T x} \\\\ & = \\inn{T^* x, h} + \\inn{h, T x} \\\\ & = \\inn{h, T^* x} + \\inn{h, T x} \\\\ & = \\inn{h, (T + T^*) x} , \\\\ \\end{align*}\\] where in the third last step, we have used the definition of adjoint of an operator . Fr\u00e9chet derivative : The linearity of the G\u00e2teaux differential shows us that the Fr\u00e9chet derivative is the same. In this case, \\( \\D f(x): V \u2192 \u211d: h \u21a6 \\inn{h, (T + T^*) x} \\) . Note the analogy with \\( \\frac{d (a x^2)}{d x} h = h (a + a) x \\) .","title":"Hilbert spaces"},{"location":"functional-analysis/multidimensional-derivatives/#summary","text":"","title":"Summary"},{"location":"functional-analysis/multidimensional-derivatives/#relationship-between-the-two-derivatives","text":"Implications Fr\u00e9chet differentiability implies G\u00e2teaux differentiability. Proof Assume \\( f: V \u2192 W \\) has Fr\u00e9chet derivative \\( \\D f(x) \\) at \\( x \u2208 V \\) . Now, \\[\\begin{align*} & \\norm{\\frac{f(x + t v) - f(x)}{t} - \\D f(x)(v)}_W \\\\ = & \\frac{\\norm{f(x + t v) - f(x) - \\D f(x)(v) t}_W}{\\abs{t} \\norm{v}_V} \\norm{v}_V \\\\ = & \\frac{\\norm{f(x + t v) - f(x) - \\D f(x)(tv)}_W}{\\norm{t v}_V} \\norm{v}_V \u2192 0 \\\\ \\end{align*}\\] as \\( t \u2192 0 \\) since \\( \\norm{t v}_V \u2192 0 \\) as \\( t \u2192 0 \\) and \\( f \\) is Fr\u00e9chet differentiable. Note The converse of the above proposition is not true, as is shown by the counterexample. \\[ f(x, y) = \\frac{x^3}{x^2 + y^2} \ud835\udfd9_{(x, y) \u2260 (0, 0)}(x, y) . \\] The Fr\u00e9chet differentiability is a stronger notion. The Fr\u00e9chet derivative contains information about the rate of change of the norm of the function about a particular point independent of direction. It is true to the spirit of the original derivative in the sense that it is still linear. Its existence guarantees the existence of the G\u00e2teaux differential. The G\u00e2teaux differentiability is a strictly weaker notion. The G\u00e2teaux differential need not be linear, and its existence does not imply the existence of the Fr\u00e9chet derivative. In fact, its existence at a point does not even guarantee the continuity of the function at that point. It gives us the rate of change of a function only in a particular direction. This rate of change is not just of the norm, but of the vector output itself. The G\u00e2teaux differential only requires that the difference quotients converge along each direction individually, without making requirements about the rates of convergence for different directions. Thus, in order for a linear G\u00e2teaux differential to imply the existence of the Fr\u00e9chet derivative, the difference quotients have to converge uniformly for all directions. So even though G\u00e2teaux differentiability is closer to the definition of the deriviative in \\( 1 \\) -dimensional spaces, the Fr\u00e9chet derivative is closer to the true sprit of the derivative as it gives us a local linear approximation of the function. In general, in the infinite dimensional spaces, there are usually reasonably satisfactory results on the existence of G\u00e2teaux differentials of Lipschitz functions. On the other hand, similar results on existence of Fr\u00e9chet derivatives are rare and usually very hard to prove. Therefore, there are significant differences in the two derivates, and it seems to have its own pros and cons. In life, and even more so in mathematics, there is no free lunch. The choice among the two then depends on the requirement. In many applications, we require Fr\u00e9chet derivatives as they provides a genuine local linear approximations unlike the G\u00e2teaux differentials. It is important to remember that if a function is Fr\u00e9chet differentiable, then it is also G\u00e2teaux differentiable, and the two derivatives are equal. The following table highlights some of the differences. property G\u00e2teaux differentials Fr\u00e9chet derivative strength weaker stronger computability direct; ordinary differentiation rules indirect; only verification possible direction dependent independent linear not necessarily yes in \\( \u211d^d \\) directional derivatives total derivative / Jacobian","title":"Relationship between the two derivatives"},{"location":"functional-analysis/multidimensional-derivatives/#application-ordinary-least-squares","text":"In this section, we shall use what we learned to derive the normal equations in the ordinary least squares method . The problem setup is as follows. Our data consists of \\( n \\) observations, \\( \\bcrl{(x_i, y_i): i \u2208 [n]} \\) , where \\( y_i \\) is the scalar output and \\( x_i \\) is a \\( p \\) -dimensional vector of input values. In a linear regression model , the output variable is a linear function of the input variables, so \\[ y_i = x_i^* \u03b2 + \u03b5_i , \\] where \\( \u03b2 \\) is a \\( p \\) -dimensional vector assigning weightages to each variable according to their importance in predicting the output, and the scalars \\( \u03b5_i \\) represent the errors. This model can be written in matrix notation as \\[ y = X \u03b2 + \u03b5 , \\] where \\( y \\) and \\( \u03b5 \\) are \\( n \\) -dimensional vectors of the values of the output and the errors for the various observations, and \\( X \\) is an \\( n \u00d7 p \\) matrix of the inputs. Our goal is to get \\( \\hat{\u03b2} \\) which minimizes the squared errors ( \\( \u2113^2 \\) -norm). That is, we want to minimize \\[\\begin{align*} e(\u03b2) & = \\frac12 \\norm{\u03b5}_2^2 \\\\ & = \\frac12 \\inn{\u03b5, \u03b5} \\\\ & = \\frac12 \\inn{X \u03b2 - y, X \u03b2 - y} \\\\ & = \\frac12 \\brnd{\\inn{X \u03b2, X \u03b2} - 2 \\inn{X \u03b2, y} + \\inn{y, y}} \\\\ & = \\frac12 \\inn{\u03b2, X^* X \u03b2} - \\inn{\u03b2, X^* y} + \\frac12 \\inn{y, y} \\\\ \\end{align*}\\] First, notice that \\( X^* X \\) is self-adjoint, that is, \\( (X^* X)^* = X^* X \\) . Now, using the examples of linear and quadratic functionals, we get the Fr\u00e9chet derivative \\[\\begin{align*} De(\u03b2) h & = \\frac12 \\inn{h, (X^* X + (X^* X)^*) \u03b2} - \\inn{h, X^* y} \\\\ & = \\frac{1}{\\cancel2} \\inn{h, \\cancel2 X^* X \u03b2} - \\inn{h, X^* y} \\\\ & = \\inn{h, X^* (X \u03b2 - y)} , \\\\ \\end{align*}\\] where we used the fact that an inner product in a real vector space is linear also in the second argument. For a minimum, we want \\( De(\\hat{\u03b2}) h = 0 \\) for any \\( h \\) . This is only possible if \\( X^* (X \\hat{\u03b2} - y) = 0 \\) , which gives us our optimality condition \\[\\begin{equation} \\hat{\u03b2} = (X^* X)^{-1} X^* y . \\end{equation}\\]","title":"Application: ordinary least squares"},{"location":"probability-theory/first-step-analysis/","text":"First step analysis \u00b6 Abstract We use first step analysis to understand the exit probability and mean exit time of a binomial random variable. Prerequisites I expect you to know elementary (measure-theoretic) probability theory and some Markov chain theory. If you do not know measure-theoretic probability, you should still be able to follow the argument, but will have to \"believe\" some of the things that I and going to write. First step analysis is a general strategy for solving many Markov chain problems by conditioning on the first step of the Markov chain. We understand this from the first example of the book Stochastic Calculus and Financial Applications 1 . We will derive a recurrence 4 relationship of the probability of a gambler winning before he goes bankrupt, and find the expected time taken for the game to end. Problem setup \u00b6 A gambler starts with a principal of \\( 0 \\) , and he can borrow a maximum of \\( b \\) . He stops playing if his net value is \\( a \\) at any point of time. At each instant \\( i \\) , his wealth \\( S_i \\) either increases or decreases by one amount depending on the output of the Bernoulli random variable \\( X_i \\) with up probability \\( p \\) . This gives rise to the finite state space \\( \ud835\udcae = \\bcrl{-b, -b + 1, \u2026, 0, \u2026, a - 1, a} \\) . Note that \\( (S_n) \\) is a time-homogeneous Markov chain on \\( \ud835\udcae \\) with transition probabilities as follows: \\( P_{-b, j} = P_{a, j} = 0 \\) (absorbing barriers), \\( P_{i, i + 1} = p \\) and \\( P_{i, i - 1} = q \\) with \\( q = 1 - p \\) , and \\( P_{i, j} = 0 \\) in all other cases. Some interesting questions are as follows. What is the probability that the gambler wins ? What is the expected time for the game to finish? In order to answer these questions, we define the following. \\( \u03c4 = \\inf\\bcrl{n \u2265 0 \u2223 S_n = a \\text{ or } S_n = -b} \\) is the exit time . \\( f(k) = \u2119\\bcrl{S_\u03c4 = a \u2223 S_0 = k} \\) for \\( k \u2208 \ud835\udcae \\) is the probability that the gambler wins if they start with a principal of \\( k \\) . \\( g(k) = \ud835\udd3c\\brnd{\u03c4 \u2223 S_0 = k} \\) for \\( k \u2208 \ud835\udcae \\) is the mean exit time if the gambler start with a principal of \\( k \\) . Note that we can write \\( f(k) = \u2119\\bcrl{S_\u03c4 = a \u2223 S_0 = k} = \u2119_{\\bcrl{S_0 = k}} \\bcrl{S_\u03c4 = a} \\) , where \\( \u2119_{\\bcrl{S_0 = k}} \\) is the conditional probability measure. Aim 1: Calculate the winning probabilities \u00b6 Aim 1a: Obtain a recursive formula for \\( f \\) \u00b6 Note that \\( f(-b) = 0 \\) and \\( f(a) = 1 \\) ; these serve as our boundary conditions. Now \\[\\begin{align*} \\bcrl{S_\u03c4 = A} & = \\bcrl{S_\u03c4 = A} \u2229 \u03a9 \\\\ & = \\bcrl{S_\u03c4 = A} \u2229 \u2a06_{l \u2208 \ud835\udcae} \\bcrl{S_1 = l} \\\\ & = \u2a06_{l \u2208 \ud835\udcae} \\bcrl{S_\u03c4 = A} \u2229 \\bcrl{S_1 = l} , \\\\ \\end{align*}\\] and so \\[\\begin{align*} f(k) & = \u2119_\\bcrl{S_0 = k} \\bcrl{S_\u03c4 = A} \\\\ & = \u2211_{l \u2208 \ud835\udcae} \u2119_\\bcrl{S_0 = k} \\brnd{\\bcrl{S_\u03c4 = A} \u2229 \\bcrl{S_1 = l}} \\\\ & = \u2211_{l \u2208 \ud835\udcae} \u2119_\\bcrl{S_0 = k} \\bcrl{S_\u03c4 = A \u2223 S_1 = l} \u2119_\\bcrl{S_0 = k} \\bcrl{S_1 = l} \\\\ & = \u2211_{l \u2208 \ud835\udcae} \u2119_\\bcrl{S_1 = l} \\bcrl{S_\u03c4 = A} P_{k, l} \\\\ & = \u2211_{l \u2208 \ud835\udcae} P_{k, l} f(l) , \\\\ \\end{align*}\\] where we have used the Markov property in the penultimate step and time-homogenity in the ultimate step. Since \\( P_{k, l} = 0 \\) for all \\( l \\) except for \\( k \u00b1 1 \\) , we obtain the recursive formula \\[\\begin{equation} \\label{eq:f-recursive} f(k) = f(k + 1) p + f(k - 1) q ; \\quad f(-b) = 0 , \\; f(a) = 1 . \\end{equation}\\] Aim 1b: Obtain a closed-form formula for \\( f \\) \u00b6 The difference operator and the difference quotient Let \\( f: \u211d \u2192 \u211d \\) be a function. Define the (first-order) forward difference operator as \\( \u0394_h f(x) = f(x + h) - f(x) \\) . Then the difference quotient is the quantity \\( \\frac{\u0394_h f(x)}{h} \\) . Taking limit as \\( h \u2192 0 \\) , we get the derivative of \\( f \\) at \\( x \\) . We write \\( \u0394f(x) \\) to denote \\( \u0394_1 f(x) \\) . Similarly, we can define the second-order forward difference operator by \\( \u0394_h^2 f(x) = \u0394_h (\u0394_h f(x)) = f(x + 2 h) - 2 f(x + h) + f(x) \\) . Let us denote by the odds of a down movement \\( o_- = \\frac{q}{p} \\) . Then using the fact that \\( p + q = 1 \\) , the recursive formula \\eqref{eq:f-recursive} gives \\( (p + q) f(k) = p f(k + 1) + q f(k - 1) \\) , which is equivalent to \\[ \u0394f(k) = o_- \u0394f(k - 1) , \\] and gives us the useful relation \\[\\begin{equation} \\label{eq:\u0394f-recursive} \u0394f(k + j) = o_-^j \u0394f(k) . \\end{equation}\\] Let \\( \u03b1 = \u0394f(-b) \\) . Then \\( \u0394f(-b + j) = o_-^j \u0394f(-b) \\) . Now using the lower boundary conditions, we get \\[\\begin{align*} f(k) & = \u2211_{i = -b}^{k - 1} \u0394 f(i) \\\\ & = \u2211_{j = 0}^{k + b - 1} \u0394 f(- b + j) \\\\ & = \u2211_{j = 0}^{k + b - 1} o_-^j \u0394 f(- b) \\\\ & = \u03b1 \u2211_{j = 0}^{k + b - 1} o_-^j , \\\\ \\end{align*}\\] where we substituted \\( j = b + i \\) in the second step. Therefore, we have \\[\\begin{equation} \\label{eq:f-prelim} f(k) = \\begin{cases} (k + b) \u03b1 & \\text{if } p = q \\\\ \\frac{o_-^{k + b} - 1}{o_- - 1} \u03b1 & \\text{if } p \u2260 q \\\\ \\end{cases} . \\end{equation}\\] Using the upper boundary condition \\( f(a) = 1 \\) , we determine \\( \u03b1 \\) to be the inverse of the coefficent of \\( \u03b1 \\) in \\eqref{eq:f-prelim} with \\( k = a \\) in both cases. Combine this with \\eqref{eq:f-prelim} to finally obtain \\[\\begin{equation} \\label{eq:f} f(k) = \\begin{cases} \\frac{k + b}{a + b} & \\text{if } p = q \\\\ \\frac{o_-^{k + b} - 1}{o_-^{a + b} - 1} \u03b1 & \\text{if } p \u2260 q \\\\ \\end{cases} . \\end{equation}\\] Aim 2: Calculate the mean exit times \u00b6 Aim 2a: Obtain a recursive formula for \\( g \\) \u00b6 Since \\( g(-b) = g(a) = 0 \\) , we can ignore those cases as they will not contribute to the expectation. These also serve as our boundary conditions. So we assume \\( k \u2209 \\bcrl{-b, a} \\) , and take one step. Just like in the case of \\( f \\) , we have \\[\\begin{align*} g(k) & = \ud835\udd3c_{\u2119_\\bcrl{S_0 = k}} \\brnd{\u03c4} \\\\ & = 1 + \u2211_{l \u2208 \ud835\udcae} \ud835\udd3c_{\u2119_\\bcrl{S_0 = k}} \\brnd{\u03c4 \u2223 S_1 = l} \u2119_\\bcrl{S_0 = k} \\bcrl{S_1 = l} \\\\ & = 1 + \u2211_{l \u2208 \ud835\udcae} \ud835\udd3c_{\u2119_\\bcrl{S_0 = k}} \\brnd{\u03c4 \u2223 S_1 = l} \u2119_\\bcrl{S_0 = k} \\bcrl{S_1 = l} \\\\ & = 1 + \u2211_{l \u2208 \ud835\udcae} \ud835\udd3c_{\u2119_\\bcrl{S_1 = l}} \\brnd{\u03c4} P_{k, l} \\\\ & = 1 + \u2211_{l \u2208 \ud835\udcae} P_{k, l} g(l) . \\\\ \\end{align*}\\] In our particular case, this gives the recursive formula \\[\\begin{equation} \\label{eq:g-recursive} g(k) = 1 + g(k + 1) p + g(k - 1) q ; \\quad g(-b) = g(a) = 0 . \\end{equation}\\] Aim 2b: Obtain a closed-form formula for \\( g \\) \u00b6 Let us try to apply the same idea as we had used for \\( f \\) . We get \\[ \\frac1p + \u0394 g(k) = o_- \u0394 g(k - 1) . \\] This does not look as simple as the last time. What can we do? Since we have a constant term, let us try to apply the difference operator again to remove it. <!-- We get \\[ \u0394^2 g(k) = o_- \u0394^2 g(k - 1) , \\] which is exactly the kind of formula that we were looking for. --> References \u00b6 This note is partially based on the following resources. J. Michael Steele, Stochastic Calculus and Financial Applications, 2001, \u00a71.1 \u21a9 Yen-Chi Chen's notes, \u00a73.5 \u21a9 Rachel Fewster's notes, \u00a78.12 \u21a9 Still not sure what I should call this. See MathSx931035 . \u21a9","title":"First step analysis"},{"location":"probability-theory/first-step-analysis/#first-step-analysis","text":"Abstract We use first step analysis to understand the exit probability and mean exit time of a binomial random variable. Prerequisites I expect you to know elementary (measure-theoretic) probability theory and some Markov chain theory. If you do not know measure-theoretic probability, you should still be able to follow the argument, but will have to \"believe\" some of the things that I and going to write. First step analysis is a general strategy for solving many Markov chain problems by conditioning on the first step of the Markov chain. We understand this from the first example of the book Stochastic Calculus and Financial Applications 1 . We will derive a recurrence 4 relationship of the probability of a gambler winning before he goes bankrupt, and find the expected time taken for the game to end.","title":"First step analysis"},{"location":"probability-theory/first-step-analysis/#problem-setup","text":"A gambler starts with a principal of \\( 0 \\) , and he can borrow a maximum of \\( b \\) . He stops playing if his net value is \\( a \\) at any point of time. At each instant \\( i \\) , his wealth \\( S_i \\) either increases or decreases by one amount depending on the output of the Bernoulli random variable \\( X_i \\) with up probability \\( p \\) . This gives rise to the finite state space \\( \ud835\udcae = \\bcrl{-b, -b + 1, \u2026, 0, \u2026, a - 1, a} \\) . Note that \\( (S_n) \\) is a time-homogeneous Markov chain on \\( \ud835\udcae \\) with transition probabilities as follows: \\( P_{-b, j} = P_{a, j} = 0 \\) (absorbing barriers), \\( P_{i, i + 1} = p \\) and \\( P_{i, i - 1} = q \\) with \\( q = 1 - p \\) , and \\( P_{i, j} = 0 \\) in all other cases. Some interesting questions are as follows. What is the probability that the gambler wins ? What is the expected time for the game to finish? In order to answer these questions, we define the following. \\( \u03c4 = \\inf\\bcrl{n \u2265 0 \u2223 S_n = a \\text{ or } S_n = -b} \\) is the exit time . \\( f(k) = \u2119\\bcrl{S_\u03c4 = a \u2223 S_0 = k} \\) for \\( k \u2208 \ud835\udcae \\) is the probability that the gambler wins if they start with a principal of \\( k \\) . \\( g(k) = \ud835\udd3c\\brnd{\u03c4 \u2223 S_0 = k} \\) for \\( k \u2208 \ud835\udcae \\) is the mean exit time if the gambler start with a principal of \\( k \\) . Note that we can write \\( f(k) = \u2119\\bcrl{S_\u03c4 = a \u2223 S_0 = k} = \u2119_{\\bcrl{S_0 = k}} \\bcrl{S_\u03c4 = a} \\) , where \\( \u2119_{\\bcrl{S_0 = k}} \\) is the conditional probability measure.","title":"Problem setup"},{"location":"probability-theory/first-step-analysis/#aim-1-calculate-the-winning-probabilities","text":"","title":"Aim 1: Calculate the winning probabilities"},{"location":"probability-theory/first-step-analysis/#aim-1a-obtain-a-recursive-formula-for-f","text":"Note that \\( f(-b) = 0 \\) and \\( f(a) = 1 \\) ; these serve as our boundary conditions. Now \\[\\begin{align*} \\bcrl{S_\u03c4 = A} & = \\bcrl{S_\u03c4 = A} \u2229 \u03a9 \\\\ & = \\bcrl{S_\u03c4 = A} \u2229 \u2a06_{l \u2208 \ud835\udcae} \\bcrl{S_1 = l} \\\\ & = \u2a06_{l \u2208 \ud835\udcae} \\bcrl{S_\u03c4 = A} \u2229 \\bcrl{S_1 = l} , \\\\ \\end{align*}\\] and so \\[\\begin{align*} f(k) & = \u2119_\\bcrl{S_0 = k} \\bcrl{S_\u03c4 = A} \\\\ & = \u2211_{l \u2208 \ud835\udcae} \u2119_\\bcrl{S_0 = k} \\brnd{\\bcrl{S_\u03c4 = A} \u2229 \\bcrl{S_1 = l}} \\\\ & = \u2211_{l \u2208 \ud835\udcae} \u2119_\\bcrl{S_0 = k} \\bcrl{S_\u03c4 = A \u2223 S_1 = l} \u2119_\\bcrl{S_0 = k} \\bcrl{S_1 = l} \\\\ & = \u2211_{l \u2208 \ud835\udcae} \u2119_\\bcrl{S_1 = l} \\bcrl{S_\u03c4 = A} P_{k, l} \\\\ & = \u2211_{l \u2208 \ud835\udcae} P_{k, l} f(l) , \\\\ \\end{align*}\\] where we have used the Markov property in the penultimate step and time-homogenity in the ultimate step. Since \\( P_{k, l} = 0 \\) for all \\( l \\) except for \\( k \u00b1 1 \\) , we obtain the recursive formula \\[\\begin{equation} \\label{eq:f-recursive} f(k) = f(k + 1) p + f(k - 1) q ; \\quad f(-b) = 0 , \\; f(a) = 1 . \\end{equation}\\]","title":"Aim 1a: Obtain a recursive formula for \\( f \\)"},{"location":"probability-theory/first-step-analysis/#aim-1b-obtain-a-closed-form-formula-for-f","text":"The difference operator and the difference quotient Let \\( f: \u211d \u2192 \u211d \\) be a function. Define the (first-order) forward difference operator as \\( \u0394_h f(x) = f(x + h) - f(x) \\) . Then the difference quotient is the quantity \\( \\frac{\u0394_h f(x)}{h} \\) . Taking limit as \\( h \u2192 0 \\) , we get the derivative of \\( f \\) at \\( x \\) . We write \\( \u0394f(x) \\) to denote \\( \u0394_1 f(x) \\) . Similarly, we can define the second-order forward difference operator by \\( \u0394_h^2 f(x) = \u0394_h (\u0394_h f(x)) = f(x + 2 h) - 2 f(x + h) + f(x) \\) . Let us denote by the odds of a down movement \\( o_- = \\frac{q}{p} \\) . Then using the fact that \\( p + q = 1 \\) , the recursive formula \\eqref{eq:f-recursive} gives \\( (p + q) f(k) = p f(k + 1) + q f(k - 1) \\) , which is equivalent to \\[ \u0394f(k) = o_- \u0394f(k - 1) , \\] and gives us the useful relation \\[\\begin{equation} \\label{eq:\u0394f-recursive} \u0394f(k + j) = o_-^j \u0394f(k) . \\end{equation}\\] Let \\( \u03b1 = \u0394f(-b) \\) . Then \\( \u0394f(-b + j) = o_-^j \u0394f(-b) \\) . Now using the lower boundary conditions, we get \\[\\begin{align*} f(k) & = \u2211_{i = -b}^{k - 1} \u0394 f(i) \\\\ & = \u2211_{j = 0}^{k + b - 1} \u0394 f(- b + j) \\\\ & = \u2211_{j = 0}^{k + b - 1} o_-^j \u0394 f(- b) \\\\ & = \u03b1 \u2211_{j = 0}^{k + b - 1} o_-^j , \\\\ \\end{align*}\\] where we substituted \\( j = b + i \\) in the second step. Therefore, we have \\[\\begin{equation} \\label{eq:f-prelim} f(k) = \\begin{cases} (k + b) \u03b1 & \\text{if } p = q \\\\ \\frac{o_-^{k + b} - 1}{o_- - 1} \u03b1 & \\text{if } p \u2260 q \\\\ \\end{cases} . \\end{equation}\\] Using the upper boundary condition \\( f(a) = 1 \\) , we determine \\( \u03b1 \\) to be the inverse of the coefficent of \\( \u03b1 \\) in \\eqref{eq:f-prelim} with \\( k = a \\) in both cases. Combine this with \\eqref{eq:f-prelim} to finally obtain \\[\\begin{equation} \\label{eq:f} f(k) = \\begin{cases} \\frac{k + b}{a + b} & \\text{if } p = q \\\\ \\frac{o_-^{k + b} - 1}{o_-^{a + b} - 1} \u03b1 & \\text{if } p \u2260 q \\\\ \\end{cases} . \\end{equation}\\]","title":"Aim 1b: Obtain a closed-form formula for \\( f \\)"},{"location":"probability-theory/first-step-analysis/#aim-2-calculate-the-mean-exit-times","text":"","title":"Aim 2: Calculate the mean exit times"},{"location":"probability-theory/first-step-analysis/#aim-2a-obtain-a-recursive-formula-for-g","text":"Since \\( g(-b) = g(a) = 0 \\) , we can ignore those cases as they will not contribute to the expectation. These also serve as our boundary conditions. So we assume \\( k \u2209 \\bcrl{-b, a} \\) , and take one step. Just like in the case of \\( f \\) , we have \\[\\begin{align*} g(k) & = \ud835\udd3c_{\u2119_\\bcrl{S_0 = k}} \\brnd{\u03c4} \\\\ & = 1 + \u2211_{l \u2208 \ud835\udcae} \ud835\udd3c_{\u2119_\\bcrl{S_0 = k}} \\brnd{\u03c4 \u2223 S_1 = l} \u2119_\\bcrl{S_0 = k} \\bcrl{S_1 = l} \\\\ & = 1 + \u2211_{l \u2208 \ud835\udcae} \ud835\udd3c_{\u2119_\\bcrl{S_0 = k}} \\brnd{\u03c4 \u2223 S_1 = l} \u2119_\\bcrl{S_0 = k} \\bcrl{S_1 = l} \\\\ & = 1 + \u2211_{l \u2208 \ud835\udcae} \ud835\udd3c_{\u2119_\\bcrl{S_1 = l}} \\brnd{\u03c4} P_{k, l} \\\\ & = 1 + \u2211_{l \u2208 \ud835\udcae} P_{k, l} g(l) . \\\\ \\end{align*}\\] In our particular case, this gives the recursive formula \\[\\begin{equation} \\label{eq:g-recursive} g(k) = 1 + g(k + 1) p + g(k - 1) q ; \\quad g(-b) = g(a) = 0 . \\end{equation}\\]","title":"Aim 2a: Obtain a recursive formula for \\( g \\)"},{"location":"probability-theory/first-step-analysis/#aim-2b-obtain-a-closed-form-formula-for-g","text":"Let us try to apply the same idea as we had used for \\( f \\) . We get \\[ \\frac1p + \u0394 g(k) = o_- \u0394 g(k - 1) . \\] This does not look as simple as the last time. What can we do? Since we have a constant term, let us try to apply the difference operator again to remove it. <!-- We get \\[ \u0394^2 g(k) = o_- \u0394^2 g(k - 1) , \\] which is exactly the kind of formula that we were looking for. -->","title":"Aim 2b: Obtain a closed-form formula for \\( g \\)"},{"location":"probability-theory/first-step-analysis/#references","text":"This note is partially based on the following resources. J. Michael Steele, Stochastic Calculus and Financial Applications, 2001, \u00a71.1 \u21a9 Yen-Chi Chen's notes, \u00a73.5 \u21a9 Rachel Fewster's notes, \u00a78.12 \u21a9 Still not sure what I should call this. See MathSx931035 . \u21a9","title":"References"},{"location":"probability-theory/quick-probability-theory/","text":"Probability theory in a nutshell \u00b6 This is not meant to teach anyone probability theory. It is meant for a quick and dirty reference when required. I have followed the convention that anything with a subscript of \\( n \\) implies that the index set is \\( \u2115 \\) . Basic Theory \u00b6 Disclaimer: Many of the ideas and examples have been taken from Manjunath Krishnapur's probability theory notes , which I would highly recommend for a thorough understanding of the subject. Discrete probability spaces (countable outcomes) \u00b6 Let \\( \u03a9 \\) be a countable set and \\( \ud835\udd61: \u03a9 \u2192 [0, 1] \\) such that \\( \u2211_{\u03c9 \u2208 \u03a9} \ud835\udd61(\u03c9) = 1 \\) . Then we call \\( (\u03a9, \ud835\udd61) \\) a discrete probability space. For any \\( E \u2286 \u03a9 \\) , define the probability of \\( E \\) as \\( \u2119(E) = \u2211_{\u03c9 \u2208 E} \ud835\udd61(\u03c9) \\) . probability of selecting a prime Draw a random integer from 1 to 100. What is the chance that it is a prime number? Here \\( \u03a9 = \\bcrl{1, 2 , \u2026, 100}, E = \\bcrl{2, 3, \u2026, 97} \\) , so \\( \u2119(E) = \\frac14 \\) . !!! \"Moral\" * Simple to set up the theory. * Actual computations may still be difficult. Continuous probability spaces (uncountable outcomes) \u00b6 Problems \u00b6 Example. Breaking a stick at random : Here \\( \u03a9 = [0, 1] \\) . But clearly \" \\( \u2119[0.25, 0.5] = \u2211_{\u03c9 \u2208 [0.25, 0.5]} \ud835\udd61(\u03c9) \\) \" makes no sense! (Singletons have zero probability, so adding uncountable zeros to get a positive number sounds weird.) Example. Toss a fair coin infinitely many times : Here \\( \u03a9 = \\{ 0, 1 \\}^\u2115 \\) (uncountable). Let \\( E \\) be the event that the first two tosses are heads. Clearly, \\( \u2119(E) = 2^{-2} \\) . But how do we sum up (uncountably many) zeros to get this number? Example. Throw a dart at a dart-board : Same as the \u201cbreaking a stick\u201d example, but in two dimensions. Solution: use measure theory \u00b6 Abandon the idea that every subset of the sample space can be assigned a probability (there exists non-measurable sets). Assume probabilities of certain (simple) events, and compute probabilities of more complicated events using them (start with a probability measure on an algebra , and use the Carath\u00e9odory extension theorem to extend it to a \u03c3-algebra containing the algebra). Measure-theoretic probability \u00b6 Probability space : A triple \\( (\u03a9, \u2131, \u2119) \\) , where \\( \u03a9 \\) is a set containing the elementary outcomes. \\( \u2131 \u2286 2^\u03a9 \\) is a \u03c3-algebra on \\( \u03a9 \\) , i.e. i. \\( \u2205 \u2208 \u2131 \\) , ii. \\( E \u2208 \u2131 \u27f9 E^\u2201 \u2208 \u2131 \\) , and iii. \\( (E_n)_{n \u2208 \u2115} \u2282 \u2131 \u27f9 \u22c3 E_n \u2208 \u2131 \\) . \\( \u2119: \u2131 \u2192 [0, 1] \\) is the probability measure on the measurable space \\( (\u03a9, \u2131) \\) , i.e. i. \\( \u2119(\u2205) = 0 \\) , ii. (\u03c3-additivity) If \\( (E_n)_{n \u2208 \u2115} \u2282 \u2131 \\) are a disjoint sequence of sets in \\( \u2131 \\) , then \\( \u2119(\u2a06 E_n) = \u2211 P(E_n) \\) , and iii. ( probability measure) \\( \u2119(\u03a9) = 1 \\) . \u03c3-algebras \u00b6 Elements of \\( \u2131 \\) are called events . A \u03c3-algebra contains all subsets of \\( \u03a9 \\) that are measurable. Essentially, these are the events to which we can assign a probability in a meaningful way. Thus, in probability theory, we understand the \u03c3-algebra to contain \" information \" about the system. The finer the \u03c3-algebra, the more information we have. ( Embedding discrete probability spaces within the framework ) Since all events are measurable in a discrete probability space, we model it as \\( (\u03a9, 2^\u03a9, \u2119) \\) , where we define \\( \u2119(E) = \u2211_{\u03c9 \u2208 E} \ud835\udd61(\u03c9) \\) for any \\( E \u2286 \u03a9 \\) . An increasing sequence of \u03c3-algebras ( \\( (\u2131_n) \\) such that \\( \u2131_n \u2286 \u2131_{n+1} \u2200n \\) ) is called a filtration , and the quadruple \\( (\u03a9, \u2131, (\u2131_n), \u2119) \\) is called a filtered probability space . Filtered probability spaces are used to model systems that evolve in time. The \u03c3-algebra generated by a class of events \\( \u2130 \\) , denoted \\( \u03c3(\u2130) \\) , is the smallest \u03c3-algebra containing \\( \u2130 \\) . It is easy to see that \\( \u03c3(\u2130) = \u22c2 \\{ \u2131 : \u2131 \\text{ is a \u03c3-algebra}, \u2131 \u2287 \u2130 \\} \\) . An event \\( E \\) is said to happen almost surely (denoted \" \\( E \\) a.s.\") if \\( \u2119(E^\u2201) = 0 \\) . Random variables \u00b6 A random variable (\"RV\") is a measurable function \\( X: (\u03a9, \u2131, \u2119) \u2192 (\\bar{\u03a9}, \\bar{\u2131}) \\) , i.e., \\( \u2200 \\bar{E} \u2208 \\bar{\u2131}, X^{-1}(\\bar{E}) \u2208 \u2131 \\) . The most common example of \\( (\\bar{\u03a9}, \\bar{\u2131}) \\) is \\( (\u211d, \u212c) \\) (and their higher finite-dimensional equivalents), where \\( \u212c \\) , called the Borel \u03c3-algebra on \\( \u211d \\) is the \u03c3-algebra generated by the open sets (or equivalently closed and half-open sets). From now on, we will assume \\( (\\bar{\u03a9}, \\bar{\u2131}) = (\u211d, \u212c) \\) . A RV \\( X \\) is called integrable , or \\( X \u2208 L^1(\u03a9, \u2131, \u2119) \\) , if \\( \u222b|X| d\u2119 < \u221e \\) . We denote \\( \ud835\udd3c(X) = \u222bX d\u2119 = \u222bX(\u03c9) \u2119(d\u03c9) \\) and call it the expectation of \\( X \\) . If \\( X \u2208 L^2(\u03a9, \u2131, \u2119) \\) , then we denote \\( \ud835\udd4d(X) = \ud835\udd3c((X - \ud835\udd3c(X))^2) \\) and call it the variance of \\( X \\) . The \u03c3-algebra generated by a RV \\( X \\) , denoted \\( \u03c3(X) \\) , is the smallest \u03c3-algebra that makes \\( X \\) measurable. Again, it can be shown that \\( \u03c3(X) = X^{-1}(\u212c) \\) . The Pushforward of a measure w.r.t. a RV Let \\( X: (\u03a9, \u2131, \u2119) \u2192 (\\bar{\u03a9}, \\bar{\u2131}) \\) . Then \\( \u2119_X := \u2119 \u2218 X^{-1} \\) is a measure on \\( (\\bar{\u03a9}, \\bar{\u2131}) \\) . The distribution of a RV \\( X \\) is defined by \\( F_X(x) = \u2119\\{ X \u2264 x \\} = \u2119\\{ X \u2208 (-\u221e, x] \\} = \u2119_X(-\u221e, x] \\) . If \\( \u2119_X \u226a \u03bb \\) ( \\( \u2119_X \\) is absolutely continuous w.r.t. the Lebesgue measure \\( \u03bb \\) ), then the density of a RV \\( X \\) is defined by the Radon-Nikodym derivative \\( f_X = \\frac{d \u2119_X}{d \u03bb} = \\frac{d \u2119_X}{d x} \\) . In layman's terms, \\( f_X = \\frac{d F_X}{d x} \\) (when the derivative exists). From now on, whenever we write \\( f_X \\) , we assume that it exists. Theorem: \\( \ud835\udd3c(\u03d5(X)) = \u222b_\u211d \u03d5(x) d \u2119_X(d x) \\) . Examples of events in terms of RVs \\( \\{ X \u2208 (a, b] \\} = \\{ \u03c9 \u2208 \u03a9 : X(\u03c9) \u2208 (a, b] \\} = \u2119_X(a, b] = F_X(b) - F_X(a) = \u222b_a^b f_X(x) dx \\) . Independence \u00b6 A sequence of \u03c3-algebras \\( (\u2131_n) \\) of \\( \u03a9 \\) are called (mutually) independent if \\( \u2200 E_i \u2208 \u2131_i, i \u2208 \\{1, 2, \\dots, n \\}, n \u2208 \u2115 \\) , we have \\( \u2119(\u22c2_{i = 1}^n E_i) = \u220f_{i = 1}^n \u2119(E_i) \\) . A sequence of events are called independent if the \u03c3-algebras generated by them are independent. A sequence of RVs are called independent if the \u03c3-algebras generated by them are independent. A sequence of RVs are called independent and identically distributed (\"IID\"), if they have the same measure and are independent. Some common probability measures on \u211d \u00b6 Discrete \u00b6 \\( \\text{Binomial}(n, p) \\) : \\( \ud835\udd61(k) = \\binom{n}{k} p^k (1 - p)^{n - k} \\) . \\( \\text{Poisson}(\u03bb) \\) , \\( \u03bb \u2265 0 \\) : \\( \ud835\udd61(k) = e^{-\u03bb} \\frac{\u03bb^k}{k!} \\) . Continuous \u00b6 \\( \\text{Uniform}(a, b) \\) : same as the scaled Lebesgue measure, i.e. \\( \\frac{d u}{d x} = \\frac{1}{b - a} \\) . \\( \\text{Gaussian} \\ \ud835\udca9(\u03bc, \u03c3) \\) : \\( \\frac{d \u03b3}{d x} = \\frac{1}{\\sqrt{2 \u03c0 \u03c3^2}} \\exp \\left( -\\frac{(x - \u03bc)^2}{2 \u03c3^2} \\right) \\) . \\( \\text{Exponential}(\u03bb) \\) : \\( \\frac{d \u03b7}{d x}(x) = \u03bb e^{-\u03bbx} \ud835\udfd9_{x \u2265 0}(x) \\) . The Borel-Cantelli Lemmas \u00b6 Let \\( (E_n) \u2282 \u2131 \\) be a sequence of events. We define the following tail events \\( \\liminf_{n \u2192 \u221e} E_n = \u22c3_{n \u2208 \u2115} \u22c2_{m \u2265 n} E_m = \\{ E_n \\text{ ev} \\} \u2208 \u2131 \\) , where ev = eventually, and \\( \\limsup_{n \u2192 \u221e} E_n = \u22c2_{n \u2208 \u2115} \u22c3_{m \u2265 n} E_m = \\{ E_n \\text{ i.o.} \\} \u2208 \u2131 \\) , where i.o. = infinitely often. By De Morgan's laws, \\( \\{ E_n \\text{ i.o.} \\}^\u2201 = \\{ E_n^\u2201 \\text{ ev} \\} \\) . Borel-Cantelli Lemmas (BC1) If \\( \u2211 \u2119(E_n) < \u221e \\) , then \\( \u2119\\{ E_n \\text{ i.o.} \\} = 0 \\) . (BC2) If \\( (E_n) \\) are independent and \\( \u2211 \u2119(E_n) = \u221e \\) , then \\( \u2119\\{ E_n \\text{ i.o.} \\} = 1 \\) . Example. (Infinite Monkey Theorem) Shakespeare's complete works consist of a total of [ \\( 884,421 \\) ][ www.opensourceshakespeare.org/stats/ ] words. Assume that the average English word length is 5.1 characters . So total number of characters = \\( 4510547 \\) . Let a monkey be typing on a keyboard randomly (independent keystrokes). The keyboard has \\( 30 \\) characters, and the event that in the n\\text{th} \\( 4510547 \\) characters replicate Shakespeare's works is denoted \\( E_n \\) . Clearly, \\( \u2119(E_n) = 30^{-4510547} \\) , which is a constant. Then \\( \u2211 \u2119(E_n) = \u221e \\) , and by BC1, \\( \u2119\\{ E_n \\text{ i.o.} \\} = 1 \\) . That is, the monkey will replicate Shakespeare's works infinitely often! Modes of convergence \u00b6 Sure convergence or pointwise convergence (pointless!) Complete convergence A.s. convergence \\( L^p \\) convergence Convergence in probability Weak* convergence, or convergence in distribution Vague convergence Important theorems \u00b6 Markov inequality. Borel-Cantelli Lemmas (see above). ( Laws of Large Numbers ) Let \\( (X_n) \\) be a sequence of IID RVs, and \\( S_n = \u2211_{i = 1}^n X_i \\) . Then ( WLLN ) \\( S_n \u2192 \ud835\udd3c(X_1) \\) in probability as \\( n \u2192 \u221e \\) . ( SLLN ) \\( S_n \u2192 \ud835\udd3c(X_1) \\) a.s. as \\( n \u2192 \u221e \\) . Example. of WLLN: Bernstein polynomials uniformly approximate continuous functions (probabilistic proof of the Weierstrass Approximation Theorem) ( Kolmogorov's 0-1 Law ): Let \\( (X_n) \\) be a sequence of independent RVs. If \\( E_T \\) is a tail event \\( (E_T \u2208 \u2131_T = \u22c2_{n \u2208 \u2115} \u03c3(X_n)) \\) , then \\( \u2119(E_T) = 0 \\) or \\( \u2119(E_T) = 1 \\) . ( Central Limit Theorem ) Let \\( (X_n) \\) be a sequence of IID RVs with \\( \ud835\udd3c(X_1) = \u03bc, \ud835\udd4d(X_1) = \u03c3^2 \\) , and let \\( S_n = \u2211_{i = 1}^n X_i \\) . Then \\( \\sqrt{n} \\frac{S_n - \u03bc}{\u03c3} \u2192 N(0, 1) \\) in distribution as \\( n \u2192 \u221e \\) . Conditioning \u00b6 Motivation: \\( \u2119(B | A) = \\frac{\u2119(B \u2229 A)}{\u2119(A)} \\) . But \\( \u2119(A) \\) may be zero! ( Conditional expectation ) Let \\( (\u03a9, \u2131, \u2119) \\) a complete probability space (complete means that all sets of measure \\( 0 \\) are in \\( \u2131 \\) ), \\( X \u2208 L_+^1(\u03a9, \u2131, \u2119) \\) be a positive integrable random variable and \\( \ud835\udca2 \u2286 \u2131 \\) be a sub \u03c3\u2212algebra. On \\( \ud835\udca2 \\) , we define the measure induced by \\( X \\) as \\( \u211a(A) = \ud835\udd3c(X \ud835\udfd9_A) \\ \u2200 A \u2208 \ud835\udca2 \\) . Then \\( \u211a \u226a \u2119 \\) , and so by Radon-Nikodym\u2019s theorem, there exists (a.s.) a \\( \ud835\udca2 \\) -measurable function \\( Y \\) such that \\( \ud835\udd3c(Y \ud835\udfd9_A) = \ud835\udd3c(X \ud835\udfd9_A) \\ \u2200 A \u2208 \ud835\udca2 \\) . We denote \\( \ud835\udd3c(X | \ud835\udca2) = Y \\) . The general case \\( X \u2208 L_+^1(\u03a9, \u2131, \u2119) \\) can be handled by writing \\( X = X_+ - X_- \\) . ( Conditional probability ) Define \\( \u2119(E | \ud835\udca2) = \ud835\udd3c(\ud835\udfd9_E | \ud835\udca2) \\) . Note: the conditional expectation (and hence the conditional probability) is a RV. Heuristically, it is the RV \u201cclosest\u201d to the original RV. In this sense, the conditional expectation is like a projection. This can be seen by the property: \\( \ud835\udd3c(\ud835\udd3c(X | \ud835\udca2) | \ud835\udca2) = \ud835\udd3c(X | \ud835\udca2) \\) . In fact, if \\( X \u2208 L^2(\u03a9, \u2131, \u2119) \\) , then \\( \ud835\udd3c(X | \ud835\udca2) \\) is indeed the orthogonal projection onto the subspace \\( L^2(\u03a9, \ud835\udca2, \u2119) \\) . Stochastic processes \u00b6 A set of RVs, indexed by an ordered set (Example. \\( \u2115, \u211d \\) ), is called a stochastic process. Martingale: Let \\( (\u03a9, \u2131, (\u2131_n), \u2119) \\) is called a filtered probability space , and \\( (X_n) \\) be a stochastic processes such that \\( X_n \\) is \\( \u2131_n \\) -measurable \\( \u2200n \\) . Then the stochastic processes \\( (X_n) \\) is called a martingale if \\( \u2200n, X_n \u2208 L^1 \\) and \\( \ud835\udd3c(X_{n+1} | \u2131_n) = X_n \\) .","title":"Probability theory in a nutshell"},{"location":"probability-theory/quick-probability-theory/#probability-theory-in-a-nutshell","text":"This is not meant to teach anyone probability theory. It is meant for a quick and dirty reference when required. I have followed the convention that anything with a subscript of \\( n \\) implies that the index set is \\( \u2115 \\) .","title":"Probability theory in a nutshell"},{"location":"probability-theory/quick-probability-theory/#basic-theory","text":"Disclaimer: Many of the ideas and examples have been taken from Manjunath Krishnapur's probability theory notes , which I would highly recommend for a thorough understanding of the subject.","title":"Basic Theory"},{"location":"probability-theory/quick-probability-theory/#discrete-probability-spaces-countable-outcomes","text":"Let \\( \u03a9 \\) be a countable set and \\( \ud835\udd61: \u03a9 \u2192 [0, 1] \\) such that \\( \u2211_{\u03c9 \u2208 \u03a9} \ud835\udd61(\u03c9) = 1 \\) . Then we call \\( (\u03a9, \ud835\udd61) \\) a discrete probability space. For any \\( E \u2286 \u03a9 \\) , define the probability of \\( E \\) as \\( \u2119(E) = \u2211_{\u03c9 \u2208 E} \ud835\udd61(\u03c9) \\) . probability of selecting a prime Draw a random integer from 1 to 100. What is the chance that it is a prime number? Here \\( \u03a9 = \\bcrl{1, 2 , \u2026, 100}, E = \\bcrl{2, 3, \u2026, 97} \\) , so \\( \u2119(E) = \\frac14 \\) . !!! \"Moral\" * Simple to set up the theory. * Actual computations may still be difficult.","title":"Discrete probability spaces (countable outcomes)"},{"location":"probability-theory/quick-probability-theory/#continuous-probability-spaces-uncountable-outcomes","text":"","title":"Continuous probability spaces (uncountable outcomes)"},{"location":"probability-theory/quick-probability-theory/#problems","text":"Example. Breaking a stick at random : Here \\( \u03a9 = [0, 1] \\) . But clearly \" \\( \u2119[0.25, 0.5] = \u2211_{\u03c9 \u2208 [0.25, 0.5]} \ud835\udd61(\u03c9) \\) \" makes no sense! (Singletons have zero probability, so adding uncountable zeros to get a positive number sounds weird.) Example. Toss a fair coin infinitely many times : Here \\( \u03a9 = \\{ 0, 1 \\}^\u2115 \\) (uncountable). Let \\( E \\) be the event that the first two tosses are heads. Clearly, \\( \u2119(E) = 2^{-2} \\) . But how do we sum up (uncountably many) zeros to get this number? Example. Throw a dart at a dart-board : Same as the \u201cbreaking a stick\u201d example, but in two dimensions.","title":"Problems"},{"location":"probability-theory/quick-probability-theory/#solution-use-measure-theory","text":"Abandon the idea that every subset of the sample space can be assigned a probability (there exists non-measurable sets). Assume probabilities of certain (simple) events, and compute probabilities of more complicated events using them (start with a probability measure on an algebra , and use the Carath\u00e9odory extension theorem to extend it to a \u03c3-algebra containing the algebra).","title":"Solution: use measure theory"},{"location":"probability-theory/quick-probability-theory/#measure-theoretic-probability","text":"Probability space : A triple \\( (\u03a9, \u2131, \u2119) \\) , where \\( \u03a9 \\) is a set containing the elementary outcomes. \\( \u2131 \u2286 2^\u03a9 \\) is a \u03c3-algebra on \\( \u03a9 \\) , i.e. i. \\( \u2205 \u2208 \u2131 \\) , ii. \\( E \u2208 \u2131 \u27f9 E^\u2201 \u2208 \u2131 \\) , and iii. \\( (E_n)_{n \u2208 \u2115} \u2282 \u2131 \u27f9 \u22c3 E_n \u2208 \u2131 \\) . \\( \u2119: \u2131 \u2192 [0, 1] \\) is the probability measure on the measurable space \\( (\u03a9, \u2131) \\) , i.e. i. \\( \u2119(\u2205) = 0 \\) , ii. (\u03c3-additivity) If \\( (E_n)_{n \u2208 \u2115} \u2282 \u2131 \\) are a disjoint sequence of sets in \\( \u2131 \\) , then \\( \u2119(\u2a06 E_n) = \u2211 P(E_n) \\) , and iii. ( probability measure) \\( \u2119(\u03a9) = 1 \\) .","title":"Measure-theoretic probability"},{"location":"probability-theory/quick-probability-theory/#-algebras","text":"Elements of \\( \u2131 \\) are called events . A \u03c3-algebra contains all subsets of \\( \u03a9 \\) that are measurable. Essentially, these are the events to which we can assign a probability in a meaningful way. Thus, in probability theory, we understand the \u03c3-algebra to contain \" information \" about the system. The finer the \u03c3-algebra, the more information we have. ( Embedding discrete probability spaces within the framework ) Since all events are measurable in a discrete probability space, we model it as \\( (\u03a9, 2^\u03a9, \u2119) \\) , where we define \\( \u2119(E) = \u2211_{\u03c9 \u2208 E} \ud835\udd61(\u03c9) \\) for any \\( E \u2286 \u03a9 \\) . An increasing sequence of \u03c3-algebras ( \\( (\u2131_n) \\) such that \\( \u2131_n \u2286 \u2131_{n+1} \u2200n \\) ) is called a filtration , and the quadruple \\( (\u03a9, \u2131, (\u2131_n), \u2119) \\) is called a filtered probability space . Filtered probability spaces are used to model systems that evolve in time. The \u03c3-algebra generated by a class of events \\( \u2130 \\) , denoted \\( \u03c3(\u2130) \\) , is the smallest \u03c3-algebra containing \\( \u2130 \\) . It is easy to see that \\( \u03c3(\u2130) = \u22c2 \\{ \u2131 : \u2131 \\text{ is a \u03c3-algebra}, \u2131 \u2287 \u2130 \\} \\) . An event \\( E \\) is said to happen almost surely (denoted \" \\( E \\) a.s.\") if \\( \u2119(E^\u2201) = 0 \\) .","title":"\u03c3-algebras"},{"location":"probability-theory/quick-probability-theory/#random-variables","text":"A random variable (\"RV\") is a measurable function \\( X: (\u03a9, \u2131, \u2119) \u2192 (\\bar{\u03a9}, \\bar{\u2131}) \\) , i.e., \\( \u2200 \\bar{E} \u2208 \\bar{\u2131}, X^{-1}(\\bar{E}) \u2208 \u2131 \\) . The most common example of \\( (\\bar{\u03a9}, \\bar{\u2131}) \\) is \\( (\u211d, \u212c) \\) (and their higher finite-dimensional equivalents), where \\( \u212c \\) , called the Borel \u03c3-algebra on \\( \u211d \\) is the \u03c3-algebra generated by the open sets (or equivalently closed and half-open sets). From now on, we will assume \\( (\\bar{\u03a9}, \\bar{\u2131}) = (\u211d, \u212c) \\) . A RV \\( X \\) is called integrable , or \\( X \u2208 L^1(\u03a9, \u2131, \u2119) \\) , if \\( \u222b|X| d\u2119 < \u221e \\) . We denote \\( \ud835\udd3c(X) = \u222bX d\u2119 = \u222bX(\u03c9) \u2119(d\u03c9) \\) and call it the expectation of \\( X \\) . If \\( X \u2208 L^2(\u03a9, \u2131, \u2119) \\) , then we denote \\( \ud835\udd4d(X) = \ud835\udd3c((X - \ud835\udd3c(X))^2) \\) and call it the variance of \\( X \\) . The \u03c3-algebra generated by a RV \\( X \\) , denoted \\( \u03c3(X) \\) , is the smallest \u03c3-algebra that makes \\( X \\) measurable. Again, it can be shown that \\( \u03c3(X) = X^{-1}(\u212c) \\) . The Pushforward of a measure w.r.t. a RV Let \\( X: (\u03a9, \u2131, \u2119) \u2192 (\\bar{\u03a9}, \\bar{\u2131}) \\) . Then \\( \u2119_X := \u2119 \u2218 X^{-1} \\) is a measure on \\( (\\bar{\u03a9}, \\bar{\u2131}) \\) . The distribution of a RV \\( X \\) is defined by \\( F_X(x) = \u2119\\{ X \u2264 x \\} = \u2119\\{ X \u2208 (-\u221e, x] \\} = \u2119_X(-\u221e, x] \\) . If \\( \u2119_X \u226a \u03bb \\) ( \\( \u2119_X \\) is absolutely continuous w.r.t. the Lebesgue measure \\( \u03bb \\) ), then the density of a RV \\( X \\) is defined by the Radon-Nikodym derivative \\( f_X = \\frac{d \u2119_X}{d \u03bb} = \\frac{d \u2119_X}{d x} \\) . In layman's terms, \\( f_X = \\frac{d F_X}{d x} \\) (when the derivative exists). From now on, whenever we write \\( f_X \\) , we assume that it exists. Theorem: \\( \ud835\udd3c(\u03d5(X)) = \u222b_\u211d \u03d5(x) d \u2119_X(d x) \\) . Examples of events in terms of RVs \\( \\{ X \u2208 (a, b] \\} = \\{ \u03c9 \u2208 \u03a9 : X(\u03c9) \u2208 (a, b] \\} = \u2119_X(a, b] = F_X(b) - F_X(a) = \u222b_a^b f_X(x) dx \\) .","title":"Random variables"},{"location":"probability-theory/quick-probability-theory/#independence","text":"A sequence of \u03c3-algebras \\( (\u2131_n) \\) of \\( \u03a9 \\) are called (mutually) independent if \\( \u2200 E_i \u2208 \u2131_i, i \u2208 \\{1, 2, \\dots, n \\}, n \u2208 \u2115 \\) , we have \\( \u2119(\u22c2_{i = 1}^n E_i) = \u220f_{i = 1}^n \u2119(E_i) \\) . A sequence of events are called independent if the \u03c3-algebras generated by them are independent. A sequence of RVs are called independent if the \u03c3-algebras generated by them are independent. A sequence of RVs are called independent and identically distributed (\"IID\"), if they have the same measure and are independent.","title":"Independence"},{"location":"probability-theory/quick-probability-theory/#some-common-probability-measures-on-r","text":"","title":"Some common probability measures on \u211d"},{"location":"probability-theory/quick-probability-theory/#discrete","text":"\\( \\text{Binomial}(n, p) \\) : \\( \ud835\udd61(k) = \\binom{n}{k} p^k (1 - p)^{n - k} \\) . \\( \\text{Poisson}(\u03bb) \\) , \\( \u03bb \u2265 0 \\) : \\( \ud835\udd61(k) = e^{-\u03bb} \\frac{\u03bb^k}{k!} \\) .","title":"Discrete"},{"location":"probability-theory/quick-probability-theory/#continuous","text":"\\( \\text{Uniform}(a, b) \\) : same as the scaled Lebesgue measure, i.e. \\( \\frac{d u}{d x} = \\frac{1}{b - a} \\) . \\( \\text{Gaussian} \\ \ud835\udca9(\u03bc, \u03c3) \\) : \\( \\frac{d \u03b3}{d x} = \\frac{1}{\\sqrt{2 \u03c0 \u03c3^2}} \\exp \\left( -\\frac{(x - \u03bc)^2}{2 \u03c3^2} \\right) \\) . \\( \\text{Exponential}(\u03bb) \\) : \\( \\frac{d \u03b7}{d x}(x) = \u03bb e^{-\u03bbx} \ud835\udfd9_{x \u2265 0}(x) \\) .","title":"Continuous"},{"location":"probability-theory/quick-probability-theory/#the-borel-cantelli-lemmas","text":"Let \\( (E_n) \u2282 \u2131 \\) be a sequence of events. We define the following tail events \\( \\liminf_{n \u2192 \u221e} E_n = \u22c3_{n \u2208 \u2115} \u22c2_{m \u2265 n} E_m = \\{ E_n \\text{ ev} \\} \u2208 \u2131 \\) , where ev = eventually, and \\( \\limsup_{n \u2192 \u221e} E_n = \u22c2_{n \u2208 \u2115} \u22c3_{m \u2265 n} E_m = \\{ E_n \\text{ i.o.} \\} \u2208 \u2131 \\) , where i.o. = infinitely often. By De Morgan's laws, \\( \\{ E_n \\text{ i.o.} \\}^\u2201 = \\{ E_n^\u2201 \\text{ ev} \\} \\) . Borel-Cantelli Lemmas (BC1) If \\( \u2211 \u2119(E_n) < \u221e \\) , then \\( \u2119\\{ E_n \\text{ i.o.} \\} = 0 \\) . (BC2) If \\( (E_n) \\) are independent and \\( \u2211 \u2119(E_n) = \u221e \\) , then \\( \u2119\\{ E_n \\text{ i.o.} \\} = 1 \\) . Example. (Infinite Monkey Theorem) Shakespeare's complete works consist of a total of [ \\( 884,421 \\) ][ www.opensourceshakespeare.org/stats/ ] words. Assume that the average English word length is 5.1 characters . So total number of characters = \\( 4510547 \\) . Let a monkey be typing on a keyboard randomly (independent keystrokes). The keyboard has \\( 30 \\) characters, and the event that in the n\\text{th} \\( 4510547 \\) characters replicate Shakespeare's works is denoted \\( E_n \\) . Clearly, \\( \u2119(E_n) = 30^{-4510547} \\) , which is a constant. Then \\( \u2211 \u2119(E_n) = \u221e \\) , and by BC1, \\( \u2119\\{ E_n \\text{ i.o.} \\} = 1 \\) . That is, the monkey will replicate Shakespeare's works infinitely often!","title":"The Borel-Cantelli Lemmas"},{"location":"probability-theory/quick-probability-theory/#modes-of-convergence","text":"Sure convergence or pointwise convergence (pointless!) Complete convergence A.s. convergence \\( L^p \\) convergence Convergence in probability Weak* convergence, or convergence in distribution Vague convergence","title":"Modes of convergence"},{"location":"probability-theory/quick-probability-theory/#important-theorems","text":"Markov inequality. Borel-Cantelli Lemmas (see above). ( Laws of Large Numbers ) Let \\( (X_n) \\) be a sequence of IID RVs, and \\( S_n = \u2211_{i = 1}^n X_i \\) . Then ( WLLN ) \\( S_n \u2192 \ud835\udd3c(X_1) \\) in probability as \\( n \u2192 \u221e \\) . ( SLLN ) \\( S_n \u2192 \ud835\udd3c(X_1) \\) a.s. as \\( n \u2192 \u221e \\) . Example. of WLLN: Bernstein polynomials uniformly approximate continuous functions (probabilistic proof of the Weierstrass Approximation Theorem) ( Kolmogorov's 0-1 Law ): Let \\( (X_n) \\) be a sequence of independent RVs. If \\( E_T \\) is a tail event \\( (E_T \u2208 \u2131_T = \u22c2_{n \u2208 \u2115} \u03c3(X_n)) \\) , then \\( \u2119(E_T) = 0 \\) or \\( \u2119(E_T) = 1 \\) . ( Central Limit Theorem ) Let \\( (X_n) \\) be a sequence of IID RVs with \\( \ud835\udd3c(X_1) = \u03bc, \ud835\udd4d(X_1) = \u03c3^2 \\) , and let \\( S_n = \u2211_{i = 1}^n X_i \\) . Then \\( \\sqrt{n} \\frac{S_n - \u03bc}{\u03c3} \u2192 N(0, 1) \\) in distribution as \\( n \u2192 \u221e \\) .","title":"Important theorems"},{"location":"probability-theory/quick-probability-theory/#conditioning","text":"Motivation: \\( \u2119(B | A) = \\frac{\u2119(B \u2229 A)}{\u2119(A)} \\) . But \\( \u2119(A) \\) may be zero! ( Conditional expectation ) Let \\( (\u03a9, \u2131, \u2119) \\) a complete probability space (complete means that all sets of measure \\( 0 \\) are in \\( \u2131 \\) ), \\( X \u2208 L_+^1(\u03a9, \u2131, \u2119) \\) be a positive integrable random variable and \\( \ud835\udca2 \u2286 \u2131 \\) be a sub \u03c3\u2212algebra. On \\( \ud835\udca2 \\) , we define the measure induced by \\( X \\) as \\( \u211a(A) = \ud835\udd3c(X \ud835\udfd9_A) \\ \u2200 A \u2208 \ud835\udca2 \\) . Then \\( \u211a \u226a \u2119 \\) , and so by Radon-Nikodym\u2019s theorem, there exists (a.s.) a \\( \ud835\udca2 \\) -measurable function \\( Y \\) such that \\( \ud835\udd3c(Y \ud835\udfd9_A) = \ud835\udd3c(X \ud835\udfd9_A) \\ \u2200 A \u2208 \ud835\udca2 \\) . We denote \\( \ud835\udd3c(X | \ud835\udca2) = Y \\) . The general case \\( X \u2208 L_+^1(\u03a9, \u2131, \u2119) \\) can be handled by writing \\( X = X_+ - X_- \\) . ( Conditional probability ) Define \\( \u2119(E | \ud835\udca2) = \ud835\udd3c(\ud835\udfd9_E | \ud835\udca2) \\) . Note: the conditional expectation (and hence the conditional probability) is a RV. Heuristically, it is the RV \u201cclosest\u201d to the original RV. In this sense, the conditional expectation is like a projection. This can be seen by the property: \\( \ud835\udd3c(\ud835\udd3c(X | \ud835\udca2) | \ud835\udca2) = \ud835\udd3c(X | \ud835\udca2) \\) . In fact, if \\( X \u2208 L^2(\u03a9, \u2131, \u2119) \\) , then \\( \ud835\udd3c(X | \ud835\udca2) \\) is indeed the orthogonal projection onto the subspace \\( L^2(\u03a9, \ud835\udca2, \u2119) \\) .","title":"Conditioning"},{"location":"probability-theory/quick-probability-theory/#stochastic-processes","text":"A set of RVs, indexed by an ordered set (Example. \\( \u2115, \u211d \\) ), is called a stochastic process. Martingale: Let \\( (\u03a9, \u2131, (\u2131_n), \u2119) \\) is called a filtered probability space , and \\( (X_n) \\) be a stochastic processes such that \\( X_n \\) is \\( \u2131_n \\) -measurable \\( \u2200n \\) . Then the stochastic processes \\( (X_n) \\) is called a martingale if \\( \u2200n, X_n \u2208 L^1 \\) and \\( \ud835\udd3c(X_{n+1} | \u2131_n) = X_n \\) .","title":"Stochastic processes"},{"location":"stochastic-analysis/motivating-large-deviations/","text":"Motivating large deviations \u00b6 Abstract We would like to understand why we need large deviation results. We shall first attempt to get such a result from the central limit theorem, see why it is not enough, and then go on to motivate Cram\u00e9r's theorem using the Markov inequality. Prerequisites I expect you to know elementary probability theory. Knowledge of law of large numbers, central limit theorem, moment generating function, and Markov inequality is recommended, but can be looked up in the provided Wikipedia links. Problem setup and the law of large numbers \u00b6 Suppose we have a sequence of independent and identically distributed real-valued random variables, \\( \\bcrl{X_i: i \u2208 \u2115} \\) , with mean \\( \ud835\udd3c(X_1) < \u221e \\) and variance \\( \ud835\udd4d(X_1) = \u03c3^2 < \u221e \\) . Since we can always subtract the mean from the original random variables to get a new set of random variables with \\( 0 \\) mean, we henceforth assume that \\( \ud835\udd3c(X_1) = 0 \\) without any loss of generality. Denote the sample mean by \\( \\overline{X}_n = \\frac1n \u2211_{i = 1}^n X_i \\) . Our goal is to find the probability of deviation of \\( \\overline{X}_n \\) from \\( \\overline{X} \\) as \\( n \u2192 \u221e \\) . In particular, for some \\( \u03b5 > 0 \\) , we would like to calculate rate of convergence of the limit \\[\\begin{equation} \\label{eq:goal} \\lim_{n \u2192 \u221e} \u2119\\bcrl{\\overline{X}_n > \u03b5} . \\end{equation}\\] For a fixed \\( \u03b5 \\) , the weak law of large numbers gives us \\( \\lim_{n \u2192 \u221e} \u2119\\bcrl{\\abs{\\overline{X}_n} > \u03b5} = 0 \\) . But it does not say how fast the probability converges to zero as a function of \\( \u03b5 \\) . Our intuition should suggest that the rate of convergence should be much faster when \\( \u03b5 = 2 \\) as compared to \\( \u03b5 = 1 \\) , which should in turn be faster as compared to when \\( \u03b5 = \\frac12 \\) . In fact, it is natural to expect the rate to be slower as \\( \u03b5 \\) gets closer to \\( 0 \\) , and faster as \\( \u03b5 \\) gets farther away from \\( 0 \\) . So the question is, can we get a more informative estimate? It might be beneficial to look at some real-life examples at this point. Measuring length using a ruler Suppose we want to measure a physical quantity. If we perform one measurement, there is a good possibility that our observation is incorrect to some degree. Instead, if we repeat the process a number of times and average the measured values, we intuitively understand that our measurement is more accurate. The law of large numbers gives a mathematical foundation for this intuition, and tells us why we must repeat our observations a number of times and average the values in order to get good estimates. Now, suppose we are measuring a thread which has a true length of 39mm. Consider the following situations. We get a mean observed length of 40mm after 8 observations. We get a mean observed length of 50mm after 8 observations. It is intuitively clear to us that situation 1 is much more probable as compared to situation 2. But the law of large numbers does not give us any idea of this. Convergence rate in computing Suppose \\( X_i \\) denotes the number of iterations required for a machine learning routine to converge with a certain degree of accuracy for the \\( i \\) th cross-validation dataset. If we want to get a good estimate of the distribution of the \\( X_i \\) s, we should look at the average values. Suppose the true mean for particular algorithm is 40 iterations. It would be more likely for us to observe a mean of 50 as compared to 100 if we run a lot of simulations. Again, the law of large numbers does not give us any indications in this direction. Small deviations and the central limit theorem \u00b6 Our first attempt would be to try use the central limit theorem . This theorem tells us how the limit \\eqref{eq:goal} behaves for a certain class of deviations. In particular the theorem says that we can estimate the probability of deviations from the mean when the deviations scale as an order of \\( n^{-\\frac12} \\) , that is, \\( \u03b5 \u223c \\frac{1}{\\sqrt{n}} \\) . To keep matters simple, let us see a stunted version of the central limit theorem. This version requires the existence of the moment generating function of \\( X_1 \\) . Central limit theorem In the problem setup described above, \\[ \\lim_{n \u2192 \u221e} \u2119\\bcrl{\\sqrt{n} \\overline{X}_n \u2264 z} = \ud835\udca9_{\u03c3^2}(z) , \\] where \\( \ud835\udca9_{\u03c3^2} \\) denotes the distribution function of the Gaussian measure with mean 0 and variance \\( \u03c3^2 \\) . Proof Let \\( Z = \\sqrt{n} \\overline{X}_n \\) and \\( M(\u03bb) = \ud835\udd3c\\brnd{e^{\u03bb X_1}} \\) . Then, expanding the Taylor series of \\( M \\) around \\( 0 \\) , we get \\[ M(\u03bb) = 1 + M'(0) \u03bb + \\frac12 M''(0) \u03bb^2 + o(\u03bb^2) . \\] Now, \\( M'(0) = \ud835\udd3c(X_1) = 0 \\) and \\( M''(0) = \ud835\udd3c(X_1)^2 = \u03c3^2 \\) , we have \\[ M(\u03bb) = 1 + \\frac12 \u03c3^2 \u03bb^2 + o(\u03bb^2) . \\] Now, we calculate the moment generating function of \\( \\overline{X}_n \\) . \\[\\begin{align*} M_{\\overline{X}_n}(\u03bb) & = \ud835\udd3c \\brnd{e^{\u03bb \\overline{X}_n}} \\\\ & = \ud835\udd3c \\brnd{e^{\u2211_{i = 1}^n \\frac\u03bbn X_i}} \\\\ & = \ud835\udd3c \\brnd{\u220f_{i = 1}^n e^{\\frac\u03bbn X_i}} \\\\ & = \u220f_{i = 1}^n \ud835\udd3c \\brnd{e^{\\frac\u03bbn X_i}} \\\\ & = \u220f_{i = 1}^n \ud835\udd3c \\brnd{e^{\\frac\u03bbn X_1}} = \\brnd{M\\brnd{\\frac\u03bbn}}^n , \\\\ \\end{align*}\\] where we used the independence of \\( X_i \\) s to interchange the expectation and the product, and used the indentical distribution assumption to get the same moment generating function for each. Using the above, we get \\( M_Z(\u03bb) = \ud835\udd3c\\brnd{e^{\u03bb Z}} = \ud835\udd3c\\brnd{e^{\\sqrt{n} \u03bb \\overline{X}_n}} = M_{\\overline{X}_n}(\\sqrt{n} \u03bb) = \\brnd{M\\brnd{\\frac{\u03bb}{\\sqrt{n}}}}^n \\) . Finally, putting it all together, we get \\[ M_Z(\u03bb) = \\brnd{1 + \\frac12 \\frac{\u03c3^2 \u03bb^2}{n} + o\\brnd{\\frac{\u03bb^2}{n}}}^n \u2192 e^{\\frac12 \u03bb^2 \u03c3^2} . \\] Now since \\( e^{\\frac12 \u03bb^2 \u03c3^2} \\) is the moment generating function of a Gaussian measure, and convergence of moment generating functions imply convergence of distribution, our proof is complete. On the word stunted We are calling the above version of the central limit theorem as stunted because we are stating and proving a strictly weaker version of the result. The general result can be written for any distribution, that is, there is no requirement for the moment generating function to exist. The proof of the general version uses a complex analytic version of the moment generating function called the characteristic function or Fourier transform . Using the central limit theorem, we can write \\[ \\lim_{n \u2192 \u221e} \u2119\\bcrl{\\overline{X}_n \u2265 \\frac{z}{\\sqrt{n}}} = 1 - \ud835\udca9_{\u03c3^2}\\brnd{\\frac{z}{\\sqrt{n}}} , \\qquad z \u2208 \u211d . \\] But can we use the central limit theorem to get the result we were looking for in the first place? The answer is no, because the central limit theorem only talks about the asymptotics when the deviations are of the order of \\( n^{-\\frac12} \\) , which go to \\( 0 \\) as \\( n \u2192 \u221e \\) . Therefore, this is not going to be helpful when we have a constant deviation. In this sense, the central limit theorem only works for small deviations . Large deviations \u00b6 What we can do, instead, is to use Markov's inequality to obtain exponential tail bounds. Let us see how. For an arbitrary tuning parameter \\( \u03bb > 0 \\) , we have \\[\\begin{align*} \u2119\\bcrl{\\overline{X}_n > \u03b5} & = \u2119\\bcrl{e^{n \u03bb \\overline{X}_n} > e^{n \u03bb \u03b5}} \\\\ & \u2264 e^{-n \u03bb \u03b5} \ud835\udd3c\\brnd{e^{n \u03bb \\overline{X}_n}} \\\\ & = e^{-n \u03bb \u03b5} M_{\\overline{X}_n}(n \u03bb) \\\\ & = \\brnd{e^{-\u03bb \u03b5} M(\u03bb)}^n , \\\\ \\end{align*}\\] so \\[ \\frac1n \\log \u2119\\bcrl{\\overline{X}_n > \u03b5} \u2264 -\u03bb \u03b5 + \\log M(\u03bb) . \\] Now, since \\( \u03bb > 0 \\) was arbitrary, it is true that \\[\\begin{align*} \\frac1n \\log \u2119\\bcrl{\\overline{X}_n > \u03b5} & \u2264 \\inf_{\u03bb > 0} \\bcrl{-\u03bb \u03b5 + \\log M(\u03bb)} \\\\ & = -\\sup_{\u03bb > 0} \\bcrl{\u03bb \u03b5 - \\log M(\u03bb)} . \\\\ \\end{align*}\\] Infimum and supremum If you do not know what \\( \\inf \\) and \\( \\sup \\) is, think of them as \\( \\min \\) and \\( \\max \\) , respectively. Therefore, we obtained bounds of the form of an exponential decay in probabilities as a function of the deviation \\( \u03b5 \\) . We essentially derived an intuition behind the famous Cram\u00e9r's theorem , which states the following. Cram\u00e9r (1938) The stochastic process \\( (\\overline{X}_n) \\) follows a large deviation principle with rate function \\( \u039b^*(\u03b5) := \\sup_{\u03bb > 0} \\bcrl{\u03bb \u03b5 - \\log M(\u03bb)} \\) . That is, the following hold. ( upper bound ) For every closed set \\( F \\) , we have \\[ \\limsup_{n \u2192 \u221e} \\frac1n \\log \u2119\\bcrl{\\overline{X}_n > \u03b5} \u2264 - \\inf_{x \u2208 F} \u039b^*(x) . \\] ( lower bound ) For every open set \\( G \\) , we have \\[ \\liminf_{n \u2192 \u221e} \\frac1n \\log \u2119\\bcrl{\\overline{X}_n > \u03b5} \u2265 - \\inf_{x \u2208 G} \u039b^*(x) . \\] Why \\( \\inf \\) of the rate function? In large deviation statements, the bounds are taken over sets rather than intervals. Therefore, we need to understand how the rate depends on the points in the set. Since we want the worst estimate , we take the infimum of the rate function over the set to get the slowest rate . To point out the the exponential decay explicitly, we informally write \\( \u2119\\bcrl{\\overline{X}_n \u2208 \\d x} \u224d e^{-n \u039b^*(x)} \\d x \\) for \\( x \u2208 \u211d \\) , where \\( \u224d \\) denotes the asympototic behavior as \\( n \u2192 \u221e \\) . This means that the probability of the sample mean lying in a small interval \\( \\d x \\) around \\( x \\) decreases exponentially on the value of the rate function at \\( x \\) . Finally, let us look at an example to confirm our intuitions. Cram\u00e9r's theorem for Gaussian measures For Gaussian random variables with mean \\( 0 \\) and variance \\( \u03c3^2 \\) , we have \\( M(\u03bb) = e^{\\frac12 \u03bb^2 \u03c3^2} \\) . If \\( f(\u03bb) = \u03bb \u03b5 - \\log M(\u03bb) \\) , then using calculus, we see that \\( f \\) attains its maximum at \\( \u03bb = \\frac{\u03b5}{\u03c3^2} \\) , and therefore \\( \u039b^*(\u03b5) = f\\brnd{\\frac{\u03b5}{\u03c3^2}} = \\frac{\u03b5^2}{2 \u03c3^2} \\) . Intuitively, this makes sense. If we have a larger deviation \\( \u03b5 \\) , we expect the rate of probability falling to zero to be faster. Moreover, if the variance of the original random variables \\( \u03c3^2 \\) is large, it is more likely that we can have a deviant result (slower rate). We see that the actual rate function is directly proportional to (the square of) the deviation and inversely proportional to (the square of) the variance. On the usage of the words large and small Note that we did not use small deviation to mean a small value of the deviation, but to signify deviations that asymptotically go to zero. Similarly, we did not use large deviation to mean that the deviation is itself a large value, rather we use it to indicate that there is no requirement for the deviations to asymptotically tend to zero. References \u00b6 Sham Kakade's notes Djalil Chafa\u00ef's tutorial Dominic Yeo's article series Tim van Erven: Cram\u00e9r vs Sanov Frank den Hollander's lectures in ISI, Bangalore","title":"Motivating large deviations"},{"location":"stochastic-analysis/motivating-large-deviations/#motivating-large-deviations","text":"Abstract We would like to understand why we need large deviation results. We shall first attempt to get such a result from the central limit theorem, see why it is not enough, and then go on to motivate Cram\u00e9r's theorem using the Markov inequality. Prerequisites I expect you to know elementary probability theory. Knowledge of law of large numbers, central limit theorem, moment generating function, and Markov inequality is recommended, but can be looked up in the provided Wikipedia links.","title":"Motivating large deviations"},{"location":"stochastic-analysis/motivating-large-deviations/#problem-setup-and-the-law-of-large-numbers","text":"Suppose we have a sequence of independent and identically distributed real-valued random variables, \\( \\bcrl{X_i: i \u2208 \u2115} \\) , with mean \\( \ud835\udd3c(X_1) < \u221e \\) and variance \\( \ud835\udd4d(X_1) = \u03c3^2 < \u221e \\) . Since we can always subtract the mean from the original random variables to get a new set of random variables with \\( 0 \\) mean, we henceforth assume that \\( \ud835\udd3c(X_1) = 0 \\) without any loss of generality. Denote the sample mean by \\( \\overline{X}_n = \\frac1n \u2211_{i = 1}^n X_i \\) . Our goal is to find the probability of deviation of \\( \\overline{X}_n \\) from \\( \\overline{X} \\) as \\( n \u2192 \u221e \\) . In particular, for some \\( \u03b5 > 0 \\) , we would like to calculate rate of convergence of the limit \\[\\begin{equation} \\label{eq:goal} \\lim_{n \u2192 \u221e} \u2119\\bcrl{\\overline{X}_n > \u03b5} . \\end{equation}\\] For a fixed \\( \u03b5 \\) , the weak law of large numbers gives us \\( \\lim_{n \u2192 \u221e} \u2119\\bcrl{\\abs{\\overline{X}_n} > \u03b5} = 0 \\) . But it does not say how fast the probability converges to zero as a function of \\( \u03b5 \\) . Our intuition should suggest that the rate of convergence should be much faster when \\( \u03b5 = 2 \\) as compared to \\( \u03b5 = 1 \\) , which should in turn be faster as compared to when \\( \u03b5 = \\frac12 \\) . In fact, it is natural to expect the rate to be slower as \\( \u03b5 \\) gets closer to \\( 0 \\) , and faster as \\( \u03b5 \\) gets farther away from \\( 0 \\) . So the question is, can we get a more informative estimate? It might be beneficial to look at some real-life examples at this point. Measuring length using a ruler Suppose we want to measure a physical quantity. If we perform one measurement, there is a good possibility that our observation is incorrect to some degree. Instead, if we repeat the process a number of times and average the measured values, we intuitively understand that our measurement is more accurate. The law of large numbers gives a mathematical foundation for this intuition, and tells us why we must repeat our observations a number of times and average the values in order to get good estimates. Now, suppose we are measuring a thread which has a true length of 39mm. Consider the following situations. We get a mean observed length of 40mm after 8 observations. We get a mean observed length of 50mm after 8 observations. It is intuitively clear to us that situation 1 is much more probable as compared to situation 2. But the law of large numbers does not give us any idea of this. Convergence rate in computing Suppose \\( X_i \\) denotes the number of iterations required for a machine learning routine to converge with a certain degree of accuracy for the \\( i \\) th cross-validation dataset. If we want to get a good estimate of the distribution of the \\( X_i \\) s, we should look at the average values. Suppose the true mean for particular algorithm is 40 iterations. It would be more likely for us to observe a mean of 50 as compared to 100 if we run a lot of simulations. Again, the law of large numbers does not give us any indications in this direction.","title":"Problem setup and the law of large numbers"},{"location":"stochastic-analysis/motivating-large-deviations/#small-deviations-and-the-central-limit-theorem","text":"Our first attempt would be to try use the central limit theorem . This theorem tells us how the limit \\eqref{eq:goal} behaves for a certain class of deviations. In particular the theorem says that we can estimate the probability of deviations from the mean when the deviations scale as an order of \\( n^{-\\frac12} \\) , that is, \\( \u03b5 \u223c \\frac{1}{\\sqrt{n}} \\) . To keep matters simple, let us see a stunted version of the central limit theorem. This version requires the existence of the moment generating function of \\( X_1 \\) . Central limit theorem In the problem setup described above, \\[ \\lim_{n \u2192 \u221e} \u2119\\bcrl{\\sqrt{n} \\overline{X}_n \u2264 z} = \ud835\udca9_{\u03c3^2}(z) , \\] where \\( \ud835\udca9_{\u03c3^2} \\) denotes the distribution function of the Gaussian measure with mean 0 and variance \\( \u03c3^2 \\) . Proof Let \\( Z = \\sqrt{n} \\overline{X}_n \\) and \\( M(\u03bb) = \ud835\udd3c\\brnd{e^{\u03bb X_1}} \\) . Then, expanding the Taylor series of \\( M \\) around \\( 0 \\) , we get \\[ M(\u03bb) = 1 + M'(0) \u03bb + \\frac12 M''(0) \u03bb^2 + o(\u03bb^2) . \\] Now, \\( M'(0) = \ud835\udd3c(X_1) = 0 \\) and \\( M''(0) = \ud835\udd3c(X_1)^2 = \u03c3^2 \\) , we have \\[ M(\u03bb) = 1 + \\frac12 \u03c3^2 \u03bb^2 + o(\u03bb^2) . \\] Now, we calculate the moment generating function of \\( \\overline{X}_n \\) . \\[\\begin{align*} M_{\\overline{X}_n}(\u03bb) & = \ud835\udd3c \\brnd{e^{\u03bb \\overline{X}_n}} \\\\ & = \ud835\udd3c \\brnd{e^{\u2211_{i = 1}^n \\frac\u03bbn X_i}} \\\\ & = \ud835\udd3c \\brnd{\u220f_{i = 1}^n e^{\\frac\u03bbn X_i}} \\\\ & = \u220f_{i = 1}^n \ud835\udd3c \\brnd{e^{\\frac\u03bbn X_i}} \\\\ & = \u220f_{i = 1}^n \ud835\udd3c \\brnd{e^{\\frac\u03bbn X_1}} = \\brnd{M\\brnd{\\frac\u03bbn}}^n , \\\\ \\end{align*}\\] where we used the independence of \\( X_i \\) s to interchange the expectation and the product, and used the indentical distribution assumption to get the same moment generating function for each. Using the above, we get \\( M_Z(\u03bb) = \ud835\udd3c\\brnd{e^{\u03bb Z}} = \ud835\udd3c\\brnd{e^{\\sqrt{n} \u03bb \\overline{X}_n}} = M_{\\overline{X}_n}(\\sqrt{n} \u03bb) = \\brnd{M\\brnd{\\frac{\u03bb}{\\sqrt{n}}}}^n \\) . Finally, putting it all together, we get \\[ M_Z(\u03bb) = \\brnd{1 + \\frac12 \\frac{\u03c3^2 \u03bb^2}{n} + o\\brnd{\\frac{\u03bb^2}{n}}}^n \u2192 e^{\\frac12 \u03bb^2 \u03c3^2} . \\] Now since \\( e^{\\frac12 \u03bb^2 \u03c3^2} \\) is the moment generating function of a Gaussian measure, and convergence of moment generating functions imply convergence of distribution, our proof is complete. On the word stunted We are calling the above version of the central limit theorem as stunted because we are stating and proving a strictly weaker version of the result. The general result can be written for any distribution, that is, there is no requirement for the moment generating function to exist. The proof of the general version uses a complex analytic version of the moment generating function called the characteristic function or Fourier transform . Using the central limit theorem, we can write \\[ \\lim_{n \u2192 \u221e} \u2119\\bcrl{\\overline{X}_n \u2265 \\frac{z}{\\sqrt{n}}} = 1 - \ud835\udca9_{\u03c3^2}\\brnd{\\frac{z}{\\sqrt{n}}} , \\qquad z \u2208 \u211d . \\] But can we use the central limit theorem to get the result we were looking for in the first place? The answer is no, because the central limit theorem only talks about the asymptotics when the deviations are of the order of \\( n^{-\\frac12} \\) , which go to \\( 0 \\) as \\( n \u2192 \u221e \\) . Therefore, this is not going to be helpful when we have a constant deviation. In this sense, the central limit theorem only works for small deviations .","title":"Small deviations and the central limit theorem"},{"location":"stochastic-analysis/motivating-large-deviations/#large-deviations","text":"What we can do, instead, is to use Markov's inequality to obtain exponential tail bounds. Let us see how. For an arbitrary tuning parameter \\( \u03bb > 0 \\) , we have \\[\\begin{align*} \u2119\\bcrl{\\overline{X}_n > \u03b5} & = \u2119\\bcrl{e^{n \u03bb \\overline{X}_n} > e^{n \u03bb \u03b5}} \\\\ & \u2264 e^{-n \u03bb \u03b5} \ud835\udd3c\\brnd{e^{n \u03bb \\overline{X}_n}} \\\\ & = e^{-n \u03bb \u03b5} M_{\\overline{X}_n}(n \u03bb) \\\\ & = \\brnd{e^{-\u03bb \u03b5} M(\u03bb)}^n , \\\\ \\end{align*}\\] so \\[ \\frac1n \\log \u2119\\bcrl{\\overline{X}_n > \u03b5} \u2264 -\u03bb \u03b5 + \\log M(\u03bb) . \\] Now, since \\( \u03bb > 0 \\) was arbitrary, it is true that \\[\\begin{align*} \\frac1n \\log \u2119\\bcrl{\\overline{X}_n > \u03b5} & \u2264 \\inf_{\u03bb > 0} \\bcrl{-\u03bb \u03b5 + \\log M(\u03bb)} \\\\ & = -\\sup_{\u03bb > 0} \\bcrl{\u03bb \u03b5 - \\log M(\u03bb)} . \\\\ \\end{align*}\\] Infimum and supremum If you do not know what \\( \\inf \\) and \\( \\sup \\) is, think of them as \\( \\min \\) and \\( \\max \\) , respectively. Therefore, we obtained bounds of the form of an exponential decay in probabilities as a function of the deviation \\( \u03b5 \\) . We essentially derived an intuition behind the famous Cram\u00e9r's theorem , which states the following. Cram\u00e9r (1938) The stochastic process \\( (\\overline{X}_n) \\) follows a large deviation principle with rate function \\( \u039b^*(\u03b5) := \\sup_{\u03bb > 0} \\bcrl{\u03bb \u03b5 - \\log M(\u03bb)} \\) . That is, the following hold. ( upper bound ) For every closed set \\( F \\) , we have \\[ \\limsup_{n \u2192 \u221e} \\frac1n \\log \u2119\\bcrl{\\overline{X}_n > \u03b5} \u2264 - \\inf_{x \u2208 F} \u039b^*(x) . \\] ( lower bound ) For every open set \\( G \\) , we have \\[ \\liminf_{n \u2192 \u221e} \\frac1n \\log \u2119\\bcrl{\\overline{X}_n > \u03b5} \u2265 - \\inf_{x \u2208 G} \u039b^*(x) . \\] Why \\( \\inf \\) of the rate function? In large deviation statements, the bounds are taken over sets rather than intervals. Therefore, we need to understand how the rate depends on the points in the set. Since we want the worst estimate , we take the infimum of the rate function over the set to get the slowest rate . To point out the the exponential decay explicitly, we informally write \\( \u2119\\bcrl{\\overline{X}_n \u2208 \\d x} \u224d e^{-n \u039b^*(x)} \\d x \\) for \\( x \u2208 \u211d \\) , where \\( \u224d \\) denotes the asympototic behavior as \\( n \u2192 \u221e \\) . This means that the probability of the sample mean lying in a small interval \\( \\d x \\) around \\( x \\) decreases exponentially on the value of the rate function at \\( x \\) . Finally, let us look at an example to confirm our intuitions. Cram\u00e9r's theorem for Gaussian measures For Gaussian random variables with mean \\( 0 \\) and variance \\( \u03c3^2 \\) , we have \\( M(\u03bb) = e^{\\frac12 \u03bb^2 \u03c3^2} \\) . If \\( f(\u03bb) = \u03bb \u03b5 - \\log M(\u03bb) \\) , then using calculus, we see that \\( f \\) attains its maximum at \\( \u03bb = \\frac{\u03b5}{\u03c3^2} \\) , and therefore \\( \u039b^*(\u03b5) = f\\brnd{\\frac{\u03b5}{\u03c3^2}} = \\frac{\u03b5^2}{2 \u03c3^2} \\) . Intuitively, this makes sense. If we have a larger deviation \\( \u03b5 \\) , we expect the rate of probability falling to zero to be faster. Moreover, if the variance of the original random variables \\( \u03c3^2 \\) is large, it is more likely that we can have a deviant result (slower rate). We see that the actual rate function is directly proportional to (the square of) the deviation and inversely proportional to (the square of) the variance. On the usage of the words large and small Note that we did not use small deviation to mean a small value of the deviation, but to signify deviations that asymptotically go to zero. Similarly, we did not use large deviation to mean that the deviation is itself a large value, rather we use it to indicate that there is no requirement for the deviations to asymptotically tend to zero.","title":"Large deviations"},{"location":"stochastic-analysis/motivating-large-deviations/#references","text":"Sham Kakade's notes Djalil Chafa\u00ef's tutorial Dominic Yeo's article series Tim van Erven: Cram\u00e9r vs Sanov Frank den Hollander's lectures in ISI, Bangalore","title":"References"},{"location":"technical/chromebook-setup/","text":"Setting up my Chromebook \u00b6 Necessities \u00b6 External clipboard: sudo apt install xclip . File transfer: sudo apt install rsync . Shell: zsh and oh-my-zsh . sudo apt install zsh sh -c \" $( curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh ) \" chsh -s $( which zsh ) Containers snapd did not work for me. docker : the official instructions here gave me the following error. E: The repository 'https://download.docker.com/linux/ubuntu buster Release' does not have a Release file. N: Updating from such a repository cannot be done securely, and is therefore disabled by default. Editors \u00b6 micro Install using curl https://getmic.ro | zsh . Snap ( snap install micro --classic ) did not work for me. Open micro , type Ctrl+E , and type set colorscheme simple . Set default editor: open ~/.zshrc and edit the following lines to look like this. (Not sure if this works.) # Preferred editor for local and remote sessions if [[ -n $SSH_CONNECTION ]] ; then export EDITOR = nano export VISUAL = nano else export EDITOR = micro export VISUAL = micro fi Sublime Text 3 Install the following packages: Package Control Terminus with theme brackets-light SendCode GitSavvy Markdown Editing BracketHighlighter simple_ConTeXt UnicodeMath UnicodeCompletion Unicode Character Insert A File Icon Base16 Color Schemes with color-scheme base16-one-light Visual Studio Code . The Snap package did not work for me. Install from .deb worked. Computation \u00b6 miniconda Jupyter Lab Julia : Extract to /opt/julia and update the $PATH in .zshrc . In julia , install the following ( using Pkg; Pkg.add([pkgname]) ). IJulia.jl Plots.jl DifferentialEquations.jl Documentation \u00b6 ConTeXt ConTeXt LMTK : tikz did not work for me, so sticking to ConTeXt Mark VI . Document viewer: sudo apt install evince . This is required for simple_ConTeXt to automatically show the PDF after building.","title":"Setting up my Chromebook"},{"location":"technical/chromebook-setup/#setting-up-my-chromebook","text":"","title":"Setting up my Chromebook"},{"location":"technical/chromebook-setup/#necessities","text":"External clipboard: sudo apt install xclip . File transfer: sudo apt install rsync . Shell: zsh and oh-my-zsh . sudo apt install zsh sh -c \" $( curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh ) \" chsh -s $( which zsh ) Containers snapd did not work for me. docker : the official instructions here gave me the following error. E: The repository 'https://download.docker.com/linux/ubuntu buster Release' does not have a Release file. N: Updating from such a repository cannot be done securely, and is therefore disabled by default.","title":"Necessities"},{"location":"technical/chromebook-setup/#editors","text":"micro Install using curl https://getmic.ro | zsh . Snap ( snap install micro --classic ) did not work for me. Open micro , type Ctrl+E , and type set colorscheme simple . Set default editor: open ~/.zshrc and edit the following lines to look like this. (Not sure if this works.) # Preferred editor for local and remote sessions if [[ -n $SSH_CONNECTION ]] ; then export EDITOR = nano export VISUAL = nano else export EDITOR = micro export VISUAL = micro fi Sublime Text 3 Install the following packages: Package Control Terminus with theme brackets-light SendCode GitSavvy Markdown Editing BracketHighlighter simple_ConTeXt UnicodeMath UnicodeCompletion Unicode Character Insert A File Icon Base16 Color Schemes with color-scheme base16-one-light Visual Studio Code . The Snap package did not work for me. Install from .deb worked.","title":"Editors"},{"location":"technical/chromebook-setup/#computation","text":"miniconda Jupyter Lab Julia : Extract to /opt/julia and update the $PATH in .zshrc . In julia , install the following ( using Pkg; Pkg.add([pkgname]) ). IJulia.jl Plots.jl DifferentialEquations.jl","title":"Computation"},{"location":"technical/chromebook-setup/#documentation","text":"ConTeXt ConTeXt LMTK : tikz did not work for me, so sticking to ConTeXt Mark VI . Document viewer: sudo apt install evince . This is required for simple_ConTeXt to automatically show the PDF after building.","title":"Documentation"},{"location":"technical/math-blog-setup/","text":"Recipe for a markdown math blog \u00b6 The goal here is to set up a blog which can process math written in the standard \\( \\LaTeX \\) notation within markdown. In particular, the end product should be able to process inline math using \\( \\) tags, display math using \\[ \\] , and be able to process begin..end blocks. If you are not looking for that, there are much simpler ways to set up a blog. I would recommend you look at Blogger or Wordpress if you are looking for a simpler setup. In this tutorial, I will assume that you have some familiarity with with git and with installing software. Ingredients \u00b6 git for source control. GitHub (or your favorite source control repository service) for an online home of the source code. A Python distribution (I use miniconda , but feel free to use Anaconda or a bare bones Python setup). If you use any other method, please replace conda ... with pip ... or whatever is appropriate for the purpose. MkDocs as the static site generator. Pros: simple to deploy produces really pretty outputs built on top of Python allows live preview of changes easily customizable open-source Material for MkDocs for the material theme. Math (currently only MathJax works for begin..end blocks) For rendering mathematical formulas in \\( \\LaTeX \\) , we can use either of the following two JavaScript libraries. MathJax : The setup is way simpler. KaTeX : Much faster . ToDo : ask how to link Arithmatex and KaTeX for begin..end blocks. Directions \u00b6 Essentials \u00b6 Install git , the Python distribution, mkdocs and mkdocs-material . If you are using conda Install miniconda (or Python 3 directly). Add the conda-forge repository ( conda config --add channels conda-forge ). Install MkDocs : conda install mkdocs . Install Material for MkDocs : conda install mkdocs-material . Create a repository in GitHub. We shall call it <mathblog> from now on. To the .gitignore add the line site/ . Clone the repository ( git clone <repository-url> ) on your local machine. In the folder containing the repository, run mkdocs new <mathblog> . This generates all the required files for MkDocs. Now enter the <mathblog> directory ( cd <mathblog> ), and run mkdocs serve & . If you do not have any errors, go to http://127.0.0.1:8000/ in your web browser. You should see the home page of your (to be created) website. If you get the error pkg_resources.DistributionNotFound: The 'mkdocs-material-extensions>=1.0' distribution was not found and is required by the application , then install MkDocs Material Extensions using pip ( pip install mkdocs-material-extensions ) since there is not conda package for it yet (check!). To check if everything is in order, create a folder inside docs/ and create an markdown document within the folder. This file should automatically show in the website. Congratulation, we have set up the basic website. From now on, all modifications will be in the mkdocs.yml , so I will not mention this explicitly. Math \u00b6 We need either MathJax or KaTeX to process \\( \\LaTeX \\) . As I mentioned earlier, we shall use MathJax since I have yet to figure out how to process begin..end blocks in KaTeX. The Arithmatex pages do talk about using KaTeX, but these did not work for me. First, we need to enable the Arithmatex extension. markdown_extensions : - pymdownx.arithmatex : generic : true Now we need to add relevant scripts. MathJax mkdocs.yml extra_javascript : - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js KaTeX mkdocs.yml extra_javascript : - js/arithmatex2katex.js - https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js - https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js extra_css : - css/katex.my.css - https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css docs/js/arithmatex2katex.js ( function () { 'use strict' ; var katexMath = ( function () { var maths = document . querySelectorAll ( '.arithmatex' ), tex ; for ( var i = 0 ; i < maths . length ; i ++ ) { tex = maths [ i ]. textContent || maths [ i ]. innerText ; if ( tex . startsWith ( '\\\\(' ) && tex . endsWith ( '\\\\)' )) { katex . render ( tex . slice ( 2 , - 2 ), maths [ i ], { 'displayMode' : false }); } else if ( tex . startsWith ( '\\\\[' ) && tex . endsWith ( '\\\\]' )) { katex . render ( tex . slice ( 2 , - 2 ), maths [ i ], { 'displayMode' : true }); } } }); ( function () { var onReady = function onReady ( fn ) { if ( document . addEventListener ) { document . addEventListener ( \"DOMContentLoaded\" , fn ); } else { document . attachEvent ( \"onreadystatechange\" , function () { if ( document . readyState === \"interactive\" ) { fn (); } }); } }; onReady ( function () { if ( typeof katex !== \"undefined\" ) { katexMath (); } }); })(); }()); docs/css/katex.my.css . katex { font-size : 1.1 em !important ; /* Smaller fonts for inline math */ } . katex-display > . katex { font-size : 1.21 em !important ; /* Larger fonts for display math */ } . katex-html { overflow-y : hidden ; } Now write some math in your markdown files and test them out. They should render normally. markdown-katex This package can only handle syntaxes in a particular format, namely $``\u2026``$ (not two backticks but one) and ```math \u2026 ``` . There are specific advantages to this, but it means I cannot copy-paste code between my website and \\( \\LaTeX \\) documents, which is not what I want. Local installation We do not need to install MathJax or KaTeX locally. Both are obtained directly from a CDN. Todo Writing macros: See docs.mathjax.org/en/latest/input/tex/macros.html for MathJax and katex.org/docs/options.html for KaTeX. Write a CSS to customize Admonition for theorems and proofs. latex.now.sh/ drz.ac/2013/01/17/latex-theorem-like-environments-for-the-web/ squidfunk.github.io/mkdocs-material/extensions/admonition/ python-markdown.github.io/extensions/admonition/ codepen.io/haishanh/pen/zqqbmq/?editors=1100 Modify github.com/Python-Markdown/markdown/blob/master/markdown/extensions/admonition.py www.w3schools.com/cssref/pr_gen_counter-increment.asp Extensions and plugins \u00b6 ToDo For graphs, we use the MkDocs integration for mermaid . I have not been able to get this running. For an example of what it should look like, see here . For each of the following plugins, install the plugin, restart the server , and add the necessary entry under plugins in mkdocs.yml . Further description of each plugin can be found in the respective pages. Search Minification : minifies all *.html files generated by mkdocs build in a post-processing step, stripping all unnecessary characters to reduce the payload served to the client. Revision date : adds the date on which a Markdown file was last updated at the bottom of each page. Awesome pages : omits the need to specify all pages in the nav entry of mkdocs.yml . For options, see github.com/lukasgeiter/mkdocs-awesome-pages-plugin/ and lukasgeiter/mkdocs-awesome-pages-plugin . Presentation \u00b6 Now that we are happy with our creation, it is time for us to show our work to the world. Before we go ahead, we commit to our changes using git commit -a and push the commit to the origin using git push . Now run mkdocs gh-deploy to create a separate branch called gh-pages for our website. Finally, go to the GitHub Pages settings of your repository and choose the source as gh-pages branch . Now our website is live! Check this by visiting the link to your website as shown in your GitHub Pages settings. Garnishing \u00b6 Extensions \u00b6 The Python Markdown extensions are a set of extrememly useful extensions. For more extensions, see the Extensions pages of SquidFunk's website for Material for MkDocs . Mermaid Note In features under theme , do not use * instant , because it stops math from rendering without reloading, and * tabs , because it just looks bad. Tip For social , the icons can be found here . Analytics \u00b6 If you do not measure, you will not know. In order to measure traffic to our website, I am going to use Google Analytics . In Google Analytics, set up a property for your website. Go to analytics.google.com/ and click Set up for free . Give an account name and go to the next page. Select Web in the next page Give the name and address of your website. It will create a Tracking ID, which we need to include. google_analytics : - UA-XXXXXXXX-X - auto User interaction: \u00b6 For comments, we can set up a Disqus ion board. The first step is to set up a Disqus account. If you do not have one, go to Disqus signup , and create a new account. If you have one, simply sign in. The second step is to create a Disqus website . Go to Disqus signup , and click on I want to install Disqus on my site , and fill up the form. Now include your Disqus Website Name in the project. extra : disqus : the-website-shortname And we are done! References \u00b6 The links throughout the recipe were immensely helpful for me to set up the website (and create this document). I highly recommend you visit these sources for a better understanding of the processes and to customize the blog according to your tastes. MathML considered harmful","title":"Recipe for a markdown math blog"},{"location":"technical/math-blog-setup/#recipe-for-a-markdown-math-blog","text":"The goal here is to set up a blog which can process math written in the standard \\( \\LaTeX \\) notation within markdown. In particular, the end product should be able to process inline math using \\( \\) tags, display math using \\[ \\] , and be able to process begin..end blocks. If you are not looking for that, there are much simpler ways to set up a blog. I would recommend you look at Blogger or Wordpress if you are looking for a simpler setup. In this tutorial, I will assume that you have some familiarity with with git and with installing software.","title":"Recipe for a markdown math blog"},{"location":"technical/math-blog-setup/#ingredients","text":"git for source control. GitHub (or your favorite source control repository service) for an online home of the source code. A Python distribution (I use miniconda , but feel free to use Anaconda or a bare bones Python setup). If you use any other method, please replace conda ... with pip ... or whatever is appropriate for the purpose. MkDocs as the static site generator. Pros: simple to deploy produces really pretty outputs built on top of Python allows live preview of changes easily customizable open-source Material for MkDocs for the material theme. Math (currently only MathJax works for begin..end blocks) For rendering mathematical formulas in \\( \\LaTeX \\) , we can use either of the following two JavaScript libraries. MathJax : The setup is way simpler. KaTeX : Much faster . ToDo : ask how to link Arithmatex and KaTeX for begin..end blocks.","title":"Ingredients"},{"location":"technical/math-blog-setup/#directions","text":"","title":"Directions"},{"location":"technical/math-blog-setup/#essentials","text":"Install git , the Python distribution, mkdocs and mkdocs-material . If you are using conda Install miniconda (or Python 3 directly). Add the conda-forge repository ( conda config --add channels conda-forge ). Install MkDocs : conda install mkdocs . Install Material for MkDocs : conda install mkdocs-material . Create a repository in GitHub. We shall call it <mathblog> from now on. To the .gitignore add the line site/ . Clone the repository ( git clone <repository-url> ) on your local machine. In the folder containing the repository, run mkdocs new <mathblog> . This generates all the required files for MkDocs. Now enter the <mathblog> directory ( cd <mathblog> ), and run mkdocs serve & . If you do not have any errors, go to http://127.0.0.1:8000/ in your web browser. You should see the home page of your (to be created) website. If you get the error pkg_resources.DistributionNotFound: The 'mkdocs-material-extensions>=1.0' distribution was not found and is required by the application , then install MkDocs Material Extensions using pip ( pip install mkdocs-material-extensions ) since there is not conda package for it yet (check!). To check if everything is in order, create a folder inside docs/ and create an markdown document within the folder. This file should automatically show in the website. Congratulation, we have set up the basic website. From now on, all modifications will be in the mkdocs.yml , so I will not mention this explicitly.","title":"Essentials"},{"location":"technical/math-blog-setup/#math","text":"We need either MathJax or KaTeX to process \\( \\LaTeX \\) . As I mentioned earlier, we shall use MathJax since I have yet to figure out how to process begin..end blocks in KaTeX. The Arithmatex pages do talk about using KaTeX, but these did not work for me. First, we need to enable the Arithmatex extension. markdown_extensions : - pymdownx.arithmatex : generic : true Now we need to add relevant scripts. MathJax mkdocs.yml extra_javascript : - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js KaTeX mkdocs.yml extra_javascript : - js/arithmatex2katex.js - https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js - https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js extra_css : - css/katex.my.css - https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css docs/js/arithmatex2katex.js ( function () { 'use strict' ; var katexMath = ( function () { var maths = document . querySelectorAll ( '.arithmatex' ), tex ; for ( var i = 0 ; i < maths . length ; i ++ ) { tex = maths [ i ]. textContent || maths [ i ]. innerText ; if ( tex . startsWith ( '\\\\(' ) && tex . endsWith ( '\\\\)' )) { katex . render ( tex . slice ( 2 , - 2 ), maths [ i ], { 'displayMode' : false }); } else if ( tex . startsWith ( '\\\\[' ) && tex . endsWith ( '\\\\]' )) { katex . render ( tex . slice ( 2 , - 2 ), maths [ i ], { 'displayMode' : true }); } } }); ( function () { var onReady = function onReady ( fn ) { if ( document . addEventListener ) { document . addEventListener ( \"DOMContentLoaded\" , fn ); } else { document . attachEvent ( \"onreadystatechange\" , function () { if ( document . readyState === \"interactive\" ) { fn (); } }); } }; onReady ( function () { if ( typeof katex !== \"undefined\" ) { katexMath (); } }); })(); }()); docs/css/katex.my.css . katex { font-size : 1.1 em !important ; /* Smaller fonts for inline math */ } . katex-display > . katex { font-size : 1.21 em !important ; /* Larger fonts for display math */ } . katex-html { overflow-y : hidden ; } Now write some math in your markdown files and test them out. They should render normally. markdown-katex This package can only handle syntaxes in a particular format, namely $``\u2026``$ (not two backticks but one) and ```math \u2026 ``` . There are specific advantages to this, but it means I cannot copy-paste code between my website and \\( \\LaTeX \\) documents, which is not what I want. Local installation We do not need to install MathJax or KaTeX locally. Both are obtained directly from a CDN. Todo Writing macros: See docs.mathjax.org/en/latest/input/tex/macros.html for MathJax and katex.org/docs/options.html for KaTeX. Write a CSS to customize Admonition for theorems and proofs. latex.now.sh/ drz.ac/2013/01/17/latex-theorem-like-environments-for-the-web/ squidfunk.github.io/mkdocs-material/extensions/admonition/ python-markdown.github.io/extensions/admonition/ codepen.io/haishanh/pen/zqqbmq/?editors=1100 Modify github.com/Python-Markdown/markdown/blob/master/markdown/extensions/admonition.py www.w3schools.com/cssref/pr_gen_counter-increment.asp","title":"Math"},{"location":"technical/math-blog-setup/#extensions-and-plugins","text":"ToDo For graphs, we use the MkDocs integration for mermaid . I have not been able to get this running. For an example of what it should look like, see here . For each of the following plugins, install the plugin, restart the server , and add the necessary entry under plugins in mkdocs.yml . Further description of each plugin can be found in the respective pages. Search Minification : minifies all *.html files generated by mkdocs build in a post-processing step, stripping all unnecessary characters to reduce the payload served to the client. Revision date : adds the date on which a Markdown file was last updated at the bottom of each page. Awesome pages : omits the need to specify all pages in the nav entry of mkdocs.yml . For options, see github.com/lukasgeiter/mkdocs-awesome-pages-plugin/ and lukasgeiter/mkdocs-awesome-pages-plugin .","title":"Extensions and plugins"},{"location":"technical/math-blog-setup/#presentation","text":"Now that we are happy with our creation, it is time for us to show our work to the world. Before we go ahead, we commit to our changes using git commit -a and push the commit to the origin using git push . Now run mkdocs gh-deploy to create a separate branch called gh-pages for our website. Finally, go to the GitHub Pages settings of your repository and choose the source as gh-pages branch . Now our website is live! Check this by visiting the link to your website as shown in your GitHub Pages settings.","title":"Presentation"},{"location":"technical/math-blog-setup/#garnishing","text":"","title":"Garnishing"},{"location":"technical/math-blog-setup/#extensions","text":"The Python Markdown extensions are a set of extrememly useful extensions. For more extensions, see the Extensions pages of SquidFunk's website for Material for MkDocs . Mermaid Note In features under theme , do not use * instant , because it stops math from rendering without reloading, and * tabs , because it just looks bad. Tip For social , the icons can be found here .","title":"Extensions"},{"location":"technical/math-blog-setup/#analytics","text":"If you do not measure, you will not know. In order to measure traffic to our website, I am going to use Google Analytics . In Google Analytics, set up a property for your website. Go to analytics.google.com/ and click Set up for free . Give an account name and go to the next page. Select Web in the next page Give the name and address of your website. It will create a Tracking ID, which we need to include. google_analytics : - UA-XXXXXXXX-X - auto","title":"Analytics"},{"location":"technical/math-blog-setup/#user-interaction","text":"For comments, we can set up a Disqus ion board. The first step is to set up a Disqus account. If you do not have one, go to Disqus signup , and create a new account. If you have one, simply sign in. The second step is to create a Disqus website . Go to Disqus signup , and click on I want to install Disqus on my site , and fill up the form. Now include your Disqus Website Name in the project. extra : disqus : the-website-shortname And we are done!","title":"User interaction:"},{"location":"technical/math-blog-setup/#references","text":"The links throughout the recipe were immensely helpful for me to set up the website (and create this document). I highly recommend you visit these sources for a better understanding of the processes and to customize the blog according to your tastes. MathML considered harmful","title":"References"},{"location":"zero/a-story-of-numbers/","text":"A story of numbers \u00b6 Map of the journey ahead \u00b6 Set theoretic construction of numbers How numbers relate to the physical world Sets of numbers Comparing the \"size\" of these sets of numbers Notations \u00b6 As we go along, we will \"invent\" some objects, so we shall \"create\" words to talk about those objects. The following is a list of all the words we shall see. You should definitely skip this list in your first reading. Note \\( \u2115 = \\{0, 1, 2, \u2026 \\} \\) \\( \u2124 = \\{\u2026, -2, -1, 0, 1, 2, \u2026 \\} \\) What is a number? \u00b6 prime A prime number is an natural number which has only \\( 1 \\) and itself as divisors. Theorem A number is even iff its square is even. even A number \\( n \\) is called even if it can be written as \\( n = 2k \\) for some integer \\( k \\) . Euclid's theorem \\( \\sqrt2 \\) is not rational. Proof We prove this by contradiction. Suppose \\( \\sqrt2 \\) is rational. Then it can be written in the form \\( \\frac{p}{q} \\) , where \\( p, q \\) are integers with \\( q \u2260 0 \\) . Assume that \\( p \\) and \\( q \\) have no common factors, for if they do, we can reduce the fraction to its lowest terms and then call the numerator \\( p \\) and the denominator \\( q \\) . Squaring and simplifying, we get \\begin{equation} \\label{eq:sqrt2-notin-Q} p^2 = 2 q^2 . \\end{equation} This means \\( p^2 \\) is even. By the previous lemma, \\( p \\) is also even. Therefore, there exists an integer \\( r \\) such that \\( p = 2 r \\) , and so \\( p^2 = 4 r^2 \\) . Putting this in equation \\eqref{eq:sqrt2-notin-Q}, we get \\( 4 r^2 = 2 q^2 \\) , which is the same as \\( 2 r^2 = q^2 \\) . This means that \\( q^2 \\) , and thus \\( q \\) , is even. But we had assumed that \\( p \\) and \\( q \\) have no common factors. Thus we have a contradiction. Therefore, our supposition must be wrong, and it must be that \\( \\sqrt2 \\) is not rational. \\( \\sqrt2 \\) is not rational. We prove this by contradiction. Suppose \\( \\sqrt2 \\) is rational. Then it can be written in the form \\( \\frac{p}{q} \\), where \\( p, q \\) are integers with \\( q \u2260 0 \\). Assume that \\( p \\) and \\( q \\) have no common factors, for if they do, we can reduce the fraction to its lowest terms and then call the numerator \\( p \\) and the denominator \\( q \\). Squaring and simplifying, we get \\begin{equation} \\label{eq:sqrt2-notin-Q-v1} p^2 = 2 q^2 . \\end{equation} This means \\( p^2 \\) is even. By the previous lemma, \\( p \\) is also even. Therefore, there exists an integer \\( r \\) such that \\( p = 2 r \\), and so \\( p^2 = 4 r^2 \\). Putting this in equation \\eqref{eq:sqrt2-notin-Q-v1}, we get \\( 4 r^2 = 2 q^2 \\), which is the same as \\( 2 r^2 = q^2 \\). This means that \\( q^2 \\), and thus \\( q \\), is even. But we had assumed that \\( p \\) and \\( q \\) have no common factors. Thus we have a contradiction. Therefore, our supposition must be wrong, and it must be that \\( \\sqrt2 \\) is not rational.","title":"A story of numbers"},{"location":"zero/a-story-of-numbers/#a-story-of-numbers","text":"","title":"A story of numbers"},{"location":"zero/a-story-of-numbers/#map-of-the-journey-ahead","text":"Set theoretic construction of numbers How numbers relate to the physical world Sets of numbers Comparing the \"size\" of these sets of numbers","title":"Map of the journey ahead"},{"location":"zero/a-story-of-numbers/#notations","text":"As we go along, we will \"invent\" some objects, so we shall \"create\" words to talk about those objects. The following is a list of all the words we shall see. You should definitely skip this list in your first reading. Note \\( \u2115 = \\{0, 1, 2, \u2026 \\} \\) \\( \u2124 = \\{\u2026, -2, -1, 0, 1, 2, \u2026 \\} \\)","title":"Notations"},{"location":"zero/a-story-of-numbers/#what-is-a-number","text":"prime A prime number is an natural number which has only \\( 1 \\) and itself as divisors. Theorem A number is even iff its square is even. even A number \\( n \\) is called even if it can be written as \\( n = 2k \\) for some integer \\( k \\) . Euclid's theorem \\( \\sqrt2 \\) is not rational. Proof We prove this by contradiction. Suppose \\( \\sqrt2 \\) is rational. Then it can be written in the form \\( \\frac{p}{q} \\) , where \\( p, q \\) are integers with \\( q \u2260 0 \\) . Assume that \\( p \\) and \\( q \\) have no common factors, for if they do, we can reduce the fraction to its lowest terms and then call the numerator \\( p \\) and the denominator \\( q \\) . Squaring and simplifying, we get \\begin{equation} \\label{eq:sqrt2-notin-Q} p^2 = 2 q^2 . \\end{equation} This means \\( p^2 \\) is even. By the previous lemma, \\( p \\) is also even. Therefore, there exists an integer \\( r \\) such that \\( p = 2 r \\) , and so \\( p^2 = 4 r^2 \\) . Putting this in equation \\eqref{eq:sqrt2-notin-Q}, we get \\( 4 r^2 = 2 q^2 \\) , which is the same as \\( 2 r^2 = q^2 \\) . This means that \\( q^2 \\) , and thus \\( q \\) , is even. But we had assumed that \\( p \\) and \\( q \\) have no common factors. Thus we have a contradiction. Therefore, our supposition must be wrong, and it must be that \\( \\sqrt2 \\) is not rational. \\( \\sqrt2 \\) is not rational. We prove this by contradiction. Suppose \\( \\sqrt2 \\) is rational. Then it can be written in the form \\( \\frac{p}{q} \\), where \\( p, q \\) are integers with \\( q \u2260 0 \\). Assume that \\( p \\) and \\( q \\) have no common factors, for if they do, we can reduce the fraction to its lowest terms and then call the numerator \\( p \\) and the denominator \\( q \\). Squaring and simplifying, we get \\begin{equation} \\label{eq:sqrt2-notin-Q-v1} p^2 = 2 q^2 . \\end{equation} This means \\( p^2 \\) is even. By the previous lemma, \\( p \\) is also even. Therefore, there exists an integer \\( r \\) such that \\( p = 2 r \\), and so \\( p^2 = 4 r^2 \\). Putting this in equation \\eqref{eq:sqrt2-notin-Q-v1}, we get \\( 4 r^2 = 2 q^2 \\), which is the same as \\( 2 r^2 = q^2 \\). This means that \\( q^2 \\), and thus \\( q \\), is even. But we had assumed that \\( p \\) and \\( q \\) have no common factors. Thus we have a contradiction. Therefore, our supposition must be wrong, and it must be that \\( \\sqrt2 \\) is not rational.","title":"What is a number?"}]}