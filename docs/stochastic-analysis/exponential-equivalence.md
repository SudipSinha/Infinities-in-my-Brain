#   Exponential equivalence

The idea of exponential equivalence characterizes the idea that two indexed families of random variables (or processes) get closer asympotically at an exponential rate.

!!! definition "exponential equivalence"

    Let \( (𝒳, d) \) be a metric space. Two families of \( 𝒳 \)-valued random variables \( (X_n)_{n ∈ ℕ} \) and \( (Y_n)_{n ∈ ℕ} \) are said to be exponentially equivalent if there exist a one-parameter family of probability spaces \( (Ω, ℱ_n, ℙ_n)_{n ∈ ℕ} \) such that for all \( δ > 0 \), the event “\( X_n \) and \( Y_n \) are further than \( δ \) apart” is \( ℱ_n \)-measurable, that is, \( \bcrl{d(X_n, Y_n) > δ} ∈ ℱ_n \), and

    \[ \limsup_{n → ∞} \frac1n \log ℙ_n \bcrl{d(X_n, Y_n) > δ} = -∞ . \]

    The two families of probability measures generated by the pushforward of \( ℙ_n \) by \( (X_n)_{n ∈ ℕ} \) and \( (Y_n)_{n ∈ ℕ} \) — \( μ_n = ℙ_n ∘ X_n^{-1} \) and \( ν_n = ℙ_n ∘ Y_n^{-1} \) — are also said to be exponentially equivalent.


!!! proposition "Exponential equivalence is an equivalence relation"

!!! proof
    Reflexivity and symmetry are trivially satisfied. For transivity, suppose \( (X_n)_{n ∈ ℕ} \) and \( (Y_n)_{n ∈ ℕ} \) are exponentially equivalent, and \( (Y_n)_{n ∈ ℕ} \) and \( (Z_n)_{n ∈ ℕ} \) are exponentially equivalent. Fix \( n ∈ ℕ \). Since \( d(X_n, Z_n) ≤ d(X_n, Y_n) + d(Y_n, Z_n) \), for any \( δ > 0 \), if \( d(X_n, Z_n) > δ \), then we must have \( d(X_n, Y_n) > \fracδ2 \) or \( d(Y_n, Z_n) > \fracδ2 \). This gives us

    \[ \bcrl{d(X_n, Z_n) > δ} ⊆ \bcrl{d(X_n, Y_n) > \fracδ2} ∪ \bcrl{d(Y_n, Z_n) > \fracδ2} , \]

    and so

    \[ ℙ_n \bcrl{d(X_n, Z_n) > δ}  ≤  ℙ_n \bcrl{d(X_n, Y_n) > \fracδ2} + ℙ_n \bcrl{d(Y_n, Z_n) > \fracδ2} . \]

    Finally, taking \( \log \), dividing by \( n \), taking \( \limsup \), and using the assumed exponential equivalences, we get

    \[ \limsup_{n → ∞} \frac1n \log ℙ_n \bcrl{d(X_n, Z_n) > δ}  ≤  -∞ , \]

    showing that \( (X_n)_{n ∈ ℕ} \) and \( (Z_n)_{n ∈ ℕ} \) are exponentially equivalent.


Exponentially equivalent measures are indistinguishable for large deviation principles, which makes them extremely useful. This is formalized in the following theorem (Theorem 1.3.3 of Dupuis–Ellis[^DupuisEllis1997]). Note that this statement is coded in terms of Laplace principle, which is equivalent to a large deviation principle (Theorem 1.2.3 and Corollary 1.2.5 of Dupuis–Ellis[^DupuisEllis1997]).

!!! theorem
    For all \( n ∈ ℕ \), let \( X_n \) and \( Y_n \) be random variables defined on the same probability space \( (Ω, ℱ, ℙ) \) that take values in \( 𝒳 \). Suppose \( (X_n)_{n ∈ ℕ} \) satisfies the Laplace principle on \( 𝒳 \) with the rate function \( I \), and \( (X_n)_{n ∈ ℕ} \) and \( (Y_n)_{n ∈ ℕ} \) are exponentially equivalent. Then \( (X_n)_{n ∈ ℕ} \) satisfies the Laplace principle on \( 𝒳 \) with the same rate function \( I \).

!!! proof
    We need to verify the Laplace limit

    \[ \lim_{n → ∞} \frac1n \log 𝔼 e^{-n h(Y_n)} = - \inf_{x ∈ 𝒳} \bcrl{h(x) + I(x)} \]

    for all bounded, Lipschitz functions \( h: 𝒳 → ℝ \). Let \( h \) be such a function with Lipschitz constant \( L \).

[^DupuisEllis1997]: [Paul Dupuis and Richard S. Ellis, A Weak Convergence Approach to the Theory of Large Deviations, 1997](https://doi.org/10.1002/9781118165904)